{
    "algorithms.Duplicated.time_duplicated": {
        "code": "class Duplicated:\n    def time_duplicated(self, unique, keep, dtype):\n        self.idx.duplicated(keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self, unique, keep, dtype):\n        N = 10 ** 5\n        data = {\n            \"int\": pd.Index(np.arange(N), dtype=\"int64\"),\n            \"uint\": pd.Index(np.arange(N), dtype=\"uint64\"),\n            \"float\": pd.Index(np.random.randn(N), dtype=\"float64\"),\n            \"string\": tm.makeStringIndex(N),\n            \"datetime64[ns]\": pd.date_range(\"2011-01-01\", freq=\"H\", periods=N),\n            \"datetime64[ns, tz]\": pd.date_range(\n                \"2011-01-01\", freq=\"H\", periods=N, tz=\"Asia/Tokyo\"\n            ),\n        }[dtype]\n        if not unique:\n            data = data.repeat(5)\n        self.idx = data\n        # cache is_unique\n        self.idx.is_unique",
        "min_run_count": 2,
        "name": "algorithms.Duplicated.time_duplicated",
        "number": 0,
        "param_names": [
            "unique",
            "keep",
            "dtype"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'first'",
                "'last'",
                "False"
            ],
            [
                "'int'",
                "'uint'",
                "'float'",
                "'string'",
                "'datetime64[ns]'",
                "'datetime64[ns, tz]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "51bedc1b41018bb5feead7b43496a521aaaf1c6f28993009ab44c3df7f324058",
        "warmup_time": -1
    },
    "algorithms.Factorize.time_factorize": {
        "code": "class Factorize:\n    def time_factorize(self, unique, sort, dtype):\n        pd.factorize(self.data, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Factorize:\n    def setup(self, unique, sort, dtype):\n        N = 10 ** 5\n        string_index = tm.makeStringIndex(N)\n        string_arrow = None\n        if dtype == \"string[pyarrow]\":\n            try:\n                string_arrow = pd.array(string_index, dtype=\"string[pyarrow]\")\n            except ImportError:\n                raise NotImplementedError\n    \n        data = {\n            \"int\": pd.Index(np.arange(N), dtype=\"int64\"),\n            \"uint\": pd.Index(np.arange(N), dtype=\"uint64\"),\n            \"float\": pd.Index(np.random.randn(N), dtype=\"float64\"),\n            \"object\": string_index,\n            \"datetime64[ns]\": pd.date_range(\"2011-01-01\", freq=\"H\", periods=N),\n            \"datetime64[ns, tz]\": pd.date_range(\n                \"2011-01-01\", freq=\"H\", periods=N, tz=\"Asia/Tokyo\"\n            ),\n            \"Int64\": pd.array(np.arange(N), dtype=\"Int64\"),\n            \"boolean\": pd.array(np.random.randint(0, 2, N), dtype=\"boolean\"),\n            \"string[pyarrow]\": string_arrow,\n        }[dtype]\n        if not unique:\n            data = data.repeat(5)\n        self.data = data",
        "min_run_count": 2,
        "name": "algorithms.Factorize.time_factorize",
        "number": 0,
        "param_names": [
            "unique",
            "sort",
            "dtype"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "True",
                "False"
            ],
            [
                "'int'",
                "'uint'",
                "'float'",
                "'object'",
                "'datetime64[ns]'",
                "'datetime64[ns, tz]'",
                "'Int64'",
                "'boolean'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "016e8dd853c2030085393658c20dfce0b159d14d4e2f21c79fe796be0104335c",
        "warmup_time": -1
    },
    "algorithms.Hashing.time_frame": {
        "code": "class Hashing:\n    def time_frame(self, df):\n        hashing.hash_pandas_object(df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df",
        "min_run_count": 2,
        "name": "algorithms.Hashing.time_frame",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "algorithms:99",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9159e8d043d6701e008b31d17cc0c85afc799586dbbcdd55198b2d0bdcd3e7f7",
        "warmup_time": -1
    },
    "algorithms.Hashing.time_series_categorical": {
        "code": "class Hashing:\n    def time_series_categorical(self, df):\n        hashing.hash_pandas_object(df[\"categories\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df",
        "min_run_count": 2,
        "name": "algorithms.Hashing.time_series_categorical",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "algorithms:99",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6d0ff89f628ae7c8e656e87b1c50cc64e572435598a26639de4fbf2df76e0616",
        "warmup_time": -1
    },
    "algorithms.Hashing.time_series_dates": {
        "code": "class Hashing:\n    def time_series_dates(self, df):\n        hashing.hash_pandas_object(df[\"dates\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df",
        "min_run_count": 2,
        "name": "algorithms.Hashing.time_series_dates",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "algorithms:99",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "30223d4c2fbcd78a686c719457ec545e43e164736227c36c47f509d41429728b",
        "warmup_time": -1
    },
    "algorithms.Hashing.time_series_float": {
        "code": "class Hashing:\n    def time_series_float(self, df):\n        hashing.hash_pandas_object(df[\"floats\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df",
        "min_run_count": 2,
        "name": "algorithms.Hashing.time_series_float",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "algorithms:99",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cf6392954ed1011495371e0c153d1b0311f58f879ea4a62d9f1e4aaa29a9f13b",
        "warmup_time": -1
    },
    "algorithms.Hashing.time_series_int": {
        "code": "class Hashing:\n    def time_series_int(self, df):\n        hashing.hash_pandas_object(df[\"ints\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df",
        "min_run_count": 2,
        "name": "algorithms.Hashing.time_series_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "algorithms:99",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f208ab36f7179f9cb03656c208a22ec344421f4c58a42a6af475da28f78a128e",
        "warmup_time": -1
    },
    "algorithms.Hashing.time_series_string": {
        "code": "class Hashing:\n    def time_series_string(self, df):\n        hashing.hash_pandas_object(df[\"strings\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df",
        "min_run_count": 2,
        "name": "algorithms.Hashing.time_series_string",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "algorithms:99",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1534356f0112f5ad9ff4135d061caa82cdde9c694391e061f34b32bfc8626ce2",
        "warmup_time": -1
    },
    "algorithms.Hashing.time_series_timedeltas": {
        "code": "class Hashing:\n    def time_series_timedeltas(self, df):\n        hashing.hash_pandas_object(df[\"timedeltas\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Hashing:\n    def setup_cache(self):\n        N = 10 ** 5\n    \n        df = pd.DataFrame(\n            {\n                \"strings\": pd.Series(\n                    tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=N))\n                ),\n                \"floats\": np.random.randn(N),\n                \"ints\": np.arange(N),\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\n            }\n        )\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\n        df.iloc[10:20] = np.nan\n        return df",
        "min_run_count": 2,
        "name": "algorithms.Hashing.time_series_timedeltas",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "algorithms:99",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "29dc59d5544ade4b2c8bf6dec1b03604cc3bccaaa2f5c5e2536a4334db76a839",
        "warmup_time": -1
    },
    "algorithms.Quantile.time_quantile": {
        "code": "class Quantile:\n    def time_quantile(self, quantile, interpolation, dtype):\n        self.idx.quantile(quantile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, quantile, interpolation, dtype):\n        N = 10 ** 5\n        data = {\n            \"int\": np.arange(N),\n            \"uint\": np.arange(N).astype(np.uint64),\n            \"float\": np.random.randn(N),\n        }\n        self.idx = pd.Series(data[dtype].repeat(5))",
        "min_run_count": 2,
        "name": "algorithms.Quantile.time_quantile",
        "number": 0,
        "param_names": [
            "quantile",
            "interpolation",
            "dtype"
        ],
        "params": [
            [
                "0",
                "0.5",
                "1"
            ],
            [
                "'linear'",
                "'nearest'",
                "'lower'",
                "'higher'",
                "'midpoint'"
            ],
            [
                "'float'",
                "'int'",
                "'uint'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0852e8f7c68c33cef062aee5c17e3fc01dfa7ad56b2a3c704311646f49aa894f",
        "warmup_time": -1
    },
    "algorithms.SortIntegerArray.time_argsort": {
        "code": "class SortIntegerArray:\n    def time_argsort(self, N):\n        self.array.argsort()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIntegerArray:\n    def setup(self, N):\n        data = np.arange(N, dtype=float)\n        data[40] = np.nan\n        self.array = pd.array(data, dtype=\"Int64\")",
        "min_run_count": 2,
        "name": "algorithms.SortIntegerArray.time_argsort",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "1000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "712d4e0ba6b3b003618d30611818ce2c36c039fe0900eafca3896d3863ebbc51",
        "warmup_time": -1
    },
    "algos.isin.IsIn.time_isin": {
        "code": "class IsIn:\n    def time_isin(self, dtype):\n        self.series.isin(self.values)\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10 ** 5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(tm.makeStringIndex(N), dtype=dtype)\n            except ImportError:\n                raise NotImplementedError\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)",
        "min_run_count": 2,
        "name": "algos.isin.IsIn.time_isin",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int64'",
                "'uint64'",
                "'object'",
                "'Int64'",
                "'boolean'",
                "'bool'",
                "'datetime64[ns]'",
                "'category[object]'",
                "'category[int]'",
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bf52d16638fbfbf16906754075f99c3db94b057ef9f8bad429137499c1f8c1a4",
        "warmup_time": -1
    },
    "algos.isin.IsIn.time_isin_categorical": {
        "code": "class IsIn:\n    def time_isin_categorical(self, dtype):\n        self.series.isin(self.cat_values)\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10 ** 5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(tm.makeStringIndex(N), dtype=dtype)\n            except ImportError:\n                raise NotImplementedError\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)",
        "min_run_count": 2,
        "name": "algos.isin.IsIn.time_isin_categorical",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int64'",
                "'uint64'",
                "'object'",
                "'Int64'",
                "'boolean'",
                "'bool'",
                "'datetime64[ns]'",
                "'category[object]'",
                "'category[int]'",
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fb4ed856d40cc48b2aeed8b75e416fc3967dc4e6b1e343e2a23f1819de15e238",
        "warmup_time": -1
    },
    "algos.isin.IsIn.time_isin_empty": {
        "code": "class IsIn:\n    def time_isin_empty(self, dtype):\n        self.series.isin([])\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10 ** 5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(tm.makeStringIndex(N), dtype=dtype)\n            except ImportError:\n                raise NotImplementedError\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)",
        "min_run_count": 2,
        "name": "algos.isin.IsIn.time_isin_empty",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int64'",
                "'uint64'",
                "'object'",
                "'Int64'",
                "'boolean'",
                "'bool'",
                "'datetime64[ns]'",
                "'category[object]'",
                "'category[int]'",
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7a5bb309464b34a368d60f06e05c4fa73793464388a1ee251eff75835197dcc3",
        "warmup_time": -1
    },
    "algos.isin.IsIn.time_isin_mismatched_dtype": {
        "code": "class IsIn:\n    def time_isin_mismatched_dtype(self, dtype):\n        self.series.isin(self.mismatched)\n\n    def setup(self, dtype):\n        N = 10000\n    \n        self.mismatched = [NaT.to_datetime64()] * 2\n    \n        if dtype in [\"boolean\", \"bool\"]:\n            self.series = Series(np.random.randint(0, 2, N)).astype(dtype)\n            self.values = [True, False]\n    \n        elif dtype == \"datetime64[ns]\":\n            # Note: values here is much larger than non-dt64ns cases\n    \n            # dti has length=115777\n            dti = date_range(start=\"2015-10-26\", end=\"2016-01-01\", freq=\"50s\")\n            self.series = Series(dti)\n            self.values = self.series._values[::3]\n            self.mismatched = [1, 2]\n    \n        elif dtype in [\"category[object]\", \"category[int]\"]:\n            # Note: sizes are different in this case than others\n            n = 5 * 10 ** 5\n            sample_size = 100\n    \n            arr = list(np.random.randint(0, n // 10, size=n))\n            if dtype == \"category[object]\":\n                arr = [f\"s{i:04d}\" for i in arr]\n    \n            self.values = np.random.choice(arr, sample_size)\n            self.series = Series(arr).astype(\"category\")\n    \n        elif dtype in [\"str\", \"string[python]\", \"string[pyarrow]\"]:\n            try:\n                self.series = Series(tm.makeStringIndex(N), dtype=dtype)\n            except ImportError:\n                raise NotImplementedError\n            self.values = list(self.series[:2])\n    \n        else:\n            self.series = Series(np.random.randint(1, 10, N)).astype(dtype)\n            self.values = [1, 2]\n    \n        self.cat_values = Categorical(self.values)",
        "min_run_count": 2,
        "name": "algos.isin.IsIn.time_isin_mismatched_dtype",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int64'",
                "'uint64'",
                "'object'",
                "'Int64'",
                "'boolean'",
                "'bool'",
                "'datetime64[ns]'",
                "'category[object]'",
                "'category[int]'",
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b7177867a1e2c283a20e77657f24533a1312d41cee4401d52f15054c078bdbe7",
        "warmup_time": -1
    },
    "algos.isin.IsInFloat64.time_isin": {
        "code": "class IsInFloat64:\n    def time_isin(self, dtype, title):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, title):\n        N_many = 10 ** 5\n        N_few = 10 ** 6\n        self.series = Series([1, 2], dtype=dtype)\n    \n        if title == \"many_different_values\":\n            # runtime is dominated by creation of the lookup-table\n            self.values = np.arange(N_many, dtype=np.float64)\n        elif title == \"few_different_values\":\n            # runtime is dominated by creation of the lookup-table\n            self.values = np.zeros(N_few, dtype=np.float64)\n        elif title == \"only_nans_values\":\n            # runtime is dominated by creation of the lookup-table\n            self.values = np.full(N_few, np.nan, dtype=np.float64)\n        else:\n            raise ValueError(title)",
        "min_run_count": 2,
        "name": "algos.isin.IsInFloat64.time_isin",
        "number": 0,
        "param_names": [
            "dtype",
            "title"
        ],
        "params": [
            [
                "<class 'numpy.float64'>",
                "'Float64'"
            ],
            [
                "'many_different_values'",
                "'few_different_values'",
                "'only_nans_values'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9f541784bde88b44678e12fa583affcd042d38f314584bb72055915a73c9ff51",
        "warmup_time": -1
    },
    "algos.isin.IsInForObjects.time_isin": {
        "code": "class IsInForObjects:\n    def time_isin(self, series_type, vals_type):\n        self.series.isin(self.values)\n\n    def setup(self, series_type, vals_type):\n        N_many = 10 ** 5\n    \n        if series_type == \"nans\":\n            ser_vals = np.full(10 ** 4, np.nan)\n        elif series_type == \"short\":\n            ser_vals = np.arange(2)\n        elif series_type == \"long\":\n            ser_vals = np.arange(N_many)\n        elif series_type == \"long_floats\":\n            ser_vals = np.arange(N_many, dtype=np.float_)\n    \n        self.series = Series(ser_vals).astype(object)\n    \n        if vals_type == \"nans\":\n            values = np.full(10 ** 4, np.nan)\n        elif vals_type == \"short\":\n            values = np.arange(2)\n        elif vals_type == \"long\":\n            values = np.arange(N_many)\n        elif vals_type == \"long_floats\":\n            values = np.arange(N_many, dtype=np.float_)\n    \n        self.values = values.astype(object)",
        "min_run_count": 2,
        "name": "algos.isin.IsInForObjects.time_isin",
        "number": 0,
        "param_names": [
            "series_type",
            "vals_type"
        ],
        "params": [
            [
                "'nans'",
                "'short'",
                "'long'",
                "'long_floats'"
            ],
            [
                "'nans'",
                "'short'",
                "'long'",
                "'long_floats'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "687d0974a1783a695255bf33c8369f2e87674c6170216de480d22e526bc0c8c9",
        "warmup_time": -1
    },
    "algos.isin.IsInLongSeriesLookUpDominates.time_isin": {
        "code": "class IsInLongSeriesLookUpDominates:\n    def time_isin(self, dtypes, MaxNumber, series_type):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, MaxNumber, series_type):\n        N = 10 ** 7\n    \n        if series_type == \"random_hits\":\n            array = np.random.randint(0, MaxNumber, N)\n        if series_type == \"random_misses\":\n            array = np.random.randint(0, MaxNumber, N) + MaxNumber\n        if series_type == \"monotone_hits\":\n            array = np.repeat(np.arange(MaxNumber), N // MaxNumber)\n        if series_type == \"monotone_misses\":\n            array = np.arange(N) + MaxNumber\n    \n        self.series = Series(array).astype(dtype)\n    \n        self.values = np.arange(MaxNumber).astype(dtype.lower())",
        "min_run_count": 2,
        "name": "algos.isin.IsInLongSeriesLookUpDominates.time_isin",
        "number": 0,
        "param_names": [
            "dtype",
            "MaxNumber",
            "series_type"
        ],
        "params": [
            [
                "'int64'",
                "'int32'",
                "'float64'",
                "'float32'",
                "'object'",
                "'Int64'",
                "'Float64'"
            ],
            [
                "5",
                "1000"
            ],
            [
                "'random_hits'",
                "'random_misses'",
                "'monotone_hits'",
                "'monotone_misses'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9d97381ba0e16c55a86d4457e8ed4ff975726db70c8c5311bc807c4e590d6e47",
        "warmup_time": -1
    },
    "algos.isin.IsInLongSeriesValuesDominate.time_isin": {
        "code": "class IsInLongSeriesValuesDominate:\n    def time_isin(self, dtypes, series_type):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, series_type):\n        N = 10 ** 7\n    \n        if series_type == \"random\":\n            vals = np.random.randint(0, 10 * N, N)\n        if series_type == \"monotone\":\n            vals = np.arange(N)\n    \n        self.values = vals.astype(dtype.lower())\n        M = 10 ** 6 + 1\n        self.series = Series(np.arange(M)).astype(dtype)",
        "min_run_count": 2,
        "name": "algos.isin.IsInLongSeriesValuesDominate.time_isin",
        "number": 0,
        "param_names": [
            "dtype",
            "series_type"
        ],
        "params": [
            [
                "'int64'",
                "'int32'",
                "'float64'",
                "'float32'",
                "'object'",
                "'Int64'",
                "'Float64'"
            ],
            [
                "'random'",
                "'monotone'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1f357e3eb5d99277dc34379c10f86786823fa6545a54663886dd2247a7a5d98a",
        "warmup_time": -1
    },
    "algos.isin.IsInWithLongTupples.time_isin": {
        "code": "class IsInWithLongTupples:\n    def time_isin(self):\n        self.series.isin(self.values)\n\n    def setup(self):\n        t = tuple(range(1000))\n        self.series = Series([t] * 1000)\n        self.values = [t]",
        "min_run_count": 2,
        "name": "algos.isin.IsInWithLongTupples.time_isin",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "55c634e065a928f8f1e9146932290a0b894f6f9f6f25b0d57ab2597ce60972ad",
        "warmup_time": -1
    },
    "algos.isin.IsinAlmostFullWithRandomInt.time_isin": {
        "code": "class IsinAlmostFullWithRandomInt:\n    def time_isin(self, dtype, exponent, title):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, exponent, title):\n        M = 3 * 2 ** (exponent - 2)\n        # 0.77-the maximal share of occupied buckets\n        self.series = Series(np.random.randint(0, M, M)).astype(dtype)\n    \n        values = np.random.randint(0, M, M).astype(dtype)\n        if title == \"inside\":\n            self.values = values\n        elif title == \"outside\":\n            self.values = values + M\n        else:\n            raise ValueError(title)",
        "min_run_count": 2,
        "name": "algos.isin.IsinAlmostFullWithRandomInt.time_isin",
        "number": 0,
        "param_names": [
            "dtype",
            "exponent",
            "title"
        ],
        "params": [
            [
                "<class 'numpy.float64'>",
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.object_'>"
            ],
            [
                "10",
                "11",
                "12",
                "13",
                "14",
                "15",
                "16",
                "17",
                "18",
                "19",
                "20"
            ],
            [
                "'inside'",
                "'outside'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4511839e6a4402d9c6a3c41e95fbfd6c61eb07d38c9d0069b10c837a5dfb0bb4",
        "warmup_time": -1
    },
    "algos.isin.IsinWithArange.time_isin": {
        "code": "class IsinWithArange:\n    def time_isin(self, dtype, M, offset_factor):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, M, offset_factor):\n        offset = int(M * offset_factor)\n        tmp = Series(np.random.randint(offset, M + offset, 10 ** 6))\n        self.series = tmp.astype(dtype)\n        self.values = np.arange(M).astype(dtype)",
        "min_run_count": 2,
        "name": "algos.isin.IsinWithArange.time_isin",
        "number": 0,
        "param_names": [
            "dtype",
            "M",
            "offset_factor"
        ],
        "params": [
            [
                "<class 'numpy.float64'>",
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.object_'>"
            ],
            [
                "1000",
                "2000",
                "8000"
            ],
            [
                "-2",
                "0",
                "2"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3bdbc220596aabea1853b2ae39c239b66d30867092f00d8b6528caa6ee450a08",
        "warmup_time": -1
    },
    "algos.isin.IsinWithArangeSorted.time_isin": {
        "code": "class IsinWithArangeSorted:\n    def time_isin(self, dtype, size):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, size):\n        self.series = Series(np.arange(size)).astype(dtype)\n        self.values = np.arange(size).astype(dtype)",
        "min_run_count": 2,
        "name": "algos.isin.IsinWithArangeSorted.time_isin",
        "number": 0,
        "param_names": [
            "dtype",
            "size"
        ],
        "params": [
            [
                "<class 'numpy.float64'>",
                "<class 'numpy.int64'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.object_'>"
            ],
            [
                "1000",
                "2000",
                "8000",
                "100000",
                "1000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b3b173cabf5fb2d94e06a9a5bce98458bf646cecae54b0966cfe66adcded0fdf",
        "warmup_time": -1
    },
    "algos.isin.IsinWithRandomFloat.time_isin": {
        "code": "class IsinWithRandomFloat:\n    def time_isin(self, dtype, size, title):\n        self.series.isin(self.values)\n\n    def setup(self, dtype, size, title):\n        self.values = np.random.rand(size)\n        self.series = Series(self.values).astype(dtype)\n        np.random.shuffle(self.values)\n    \n        if title == \"outside\":\n            self.values = self.values + 0.1",
        "min_run_count": 2,
        "name": "algos.isin.IsinWithRandomFloat.time_isin",
        "number": 0,
        "param_names": [
            "dtype",
            "size",
            "title"
        ],
        "params": [
            [
                "<class 'numpy.float64'>",
                "<class 'numpy.object_'>"
            ],
            [
                "1300",
                "2000",
                "7000",
                "8000",
                "70000",
                "80000",
                "750000",
                "900000"
            ],
            [
                "'inside'",
                "'outside'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "15f9f9bb41efd706d95b1a43ff72e5572dedbb074050cd2b857e7a91213c60a8",
        "warmup_time": -1
    },
    "arithmetic.AddOverflowArray.time_add_overflow_arr_mask_nan": {
        "code": "class AddOverflowArray:\n    def time_add_overflow_arr_mask_nan(self):\n        checked_add_with_arr(self.arr, self.arr_mixed, arr_mask=self.arr_nan_1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10 ** 6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)",
        "min_run_count": 2,
        "name": "arithmetic.AddOverflowArray.time_add_overflow_arr_mask_nan",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b8bdccfe9100c86b61b21e9182588fd33955a146004ac6d03602d6aa3c0154f4",
        "warmup_time": -1
    },
    "arithmetic.AddOverflowArray.time_add_overflow_arr_rev": {
        "code": "class AddOverflowArray:\n    def time_add_overflow_arr_rev(self):\n        checked_add_with_arr(self.arr, self.arr_rev)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10 ** 6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)",
        "min_run_count": 2,
        "name": "arithmetic.AddOverflowArray.time_add_overflow_arr_rev",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9dca87d7b61542e39c27dc817007ce48f4dc21585e11cb19ebba9936789f38a9",
        "warmup_time": -1
    },
    "arithmetic.AddOverflowArray.time_add_overflow_b_mask_nan": {
        "code": "class AddOverflowArray:\n    def time_add_overflow_b_mask_nan(self):\n        checked_add_with_arr(self.arr, self.arr_mixed, b_mask=self.arr_nan_1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10 ** 6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)",
        "min_run_count": 2,
        "name": "arithmetic.AddOverflowArray.time_add_overflow_b_mask_nan",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "337bf672d2dd7b6a618d1a5684d7c352afabfeada0fdf0b1b62c707a5bd51906",
        "warmup_time": -1
    },
    "arithmetic.AddOverflowArray.time_add_overflow_both_arg_nan": {
        "code": "class AddOverflowArray:\n    def time_add_overflow_both_arg_nan(self):\n        checked_add_with_arr(\n            self.arr, self.arr_mixed, arr_mask=self.arr_nan_1, b_mask=self.arr_nan_2\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowArray:\n    def setup(self):\n        N = 10 ** 6\n        self.arr = np.arange(N)\n        self.arr_rev = np.arange(-N, 0)\n        self.arr_mixed = np.array([1, -1]).repeat(N / 2)\n        self.arr_nan_1 = np.random.choice([True, False], size=N)\n        self.arr_nan_2 = np.random.choice([True, False], size=N)",
        "min_run_count": 2,
        "name": "arithmetic.AddOverflowArray.time_add_overflow_both_arg_nan",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "84b28d805722b5dcba1999a89b9d20fa68273042f485660bb3e9eb92bb20aa98",
        "warmup_time": -1
    },
    "arithmetic.AddOverflowScalar.time_add_overflow_scalar": {
        "code": "class AddOverflowScalar:\n    def time_add_overflow_scalar(self, scalar):\n        checked_add_with_arr(self.arr, scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AddOverflowScalar:\n    def setup(self, scalar):\n        N = 10 ** 6\n        self.arr = np.arange(N)",
        "min_run_count": 2,
        "name": "arithmetic.AddOverflowScalar.time_add_overflow_scalar",
        "number": 0,
        "param_names": [
            "scalar"
        ],
        "params": [
            [
                "1",
                "-1",
                "0"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "34ed67bf8c9312afcf2bb5b54354b8742e9cd872a2a361260578e1eec4fa60ef",
        "warmup_time": -1
    },
    "arithmetic.ApplyIndex.time_apply_index": {
        "code": "class ApplyIndex:\n    def time_apply_index(self, offset):\n        self.rng + offset\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyIndex:\n    def setup(self, offset):\n        N = 10000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"T\")\n        self.rng = rng",
        "min_run_count": 2,
        "name": "arithmetic.ApplyIndex.time_apply_index",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a6729281b396d4c9142d8d7bf9895744ae38a81ae5043ffc0c87c5a9db183a49",
        "warmup_time": -1
    },
    "arithmetic.BinaryOpsMultiIndex.time_binary_op_multiindex": {
        "code": "class BinaryOpsMultiIndex:\n    def time_binary_op_multiindex(self, func):\n        getattr(self.df, func)(self.arg_df, level=0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass BinaryOpsMultiIndex:\n    def setup(self, func):\n        array = date_range(\"20200101 00:00\", \"20200102 0:00\", freq=\"S\")\n        level_0_names = [str(i) for i in range(30)]\n    \n        index = pd.MultiIndex.from_product([level_0_names, array])\n        column_names = [\"col_1\", \"col_2\"]\n    \n        self.df = DataFrame(\n            np.random.rand(len(index), 2), index=index, columns=column_names\n        )\n    \n        self.arg_df = DataFrame(\n            np.random.randint(1, 10, (len(level_0_names), 2)),\n            index=level_0_names,\n            columns=column_names,\n        )",
        "min_run_count": 2,
        "name": "arithmetic.BinaryOpsMultiIndex.time_binary_op_multiindex",
        "number": 0,
        "param_names": [
            "func"
        ],
        "params": [
            [
                "'sub'",
                "'add'",
                "'mul'",
                "'div'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "dd1b12ce1ffea7a16927ee5c6f080ab8565b7a68ff05e1e4a40c2508ff1e660e",
        "warmup_time": -1
    },
    "arithmetic.CategoricalComparisons.time_categorical_op": {
        "code": "class CategoricalComparisons:\n    def time_categorical_op(self, op):\n        getattr(self.cat, op)(\"b\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalComparisons:\n    def setup(self, op):\n        N = 10 ** 5\n        self.cat = pd.Categorical(list(\"aabbcd\") * N, ordered=True)",
        "min_run_count": 2,
        "name": "arithmetic.CategoricalComparisons.time_categorical_op",
        "number": 0,
        "param_names": [
            "op"
        ],
        "params": [
            [
                "'__lt__'",
                "'__le__'",
                "'__eq__'",
                "'__ne__'",
                "'__ge__'",
                "'__gt__'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "34518aa0daa9573fc90c6c3361fb81ce24654894ecd45826e280bf68f41429fb",
        "warmup_time": -1
    },
    "arithmetic.DateInferOps.time_add_timedeltas": {
        "code": "class DateInferOps:\n    def time_add_timedeltas(self, df):\n        df[\"timedelta\"] + df[\"timedelta\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10 ** 5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df",
        "min_run_count": 2,
        "name": "arithmetic.DateInferOps.time_add_timedeltas",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "arithmetic:369",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9b653b7ac4578cb77c382bbc79ad32405f3153d968ae5851d4d69778eed29b04",
        "warmup_time": -1
    },
    "arithmetic.DateInferOps.time_subtract_datetimes": {
        "code": "class DateInferOps:\n    def time_subtract_datetimes(self, df):\n        df[\"datetime64\"] - df[\"datetime64\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10 ** 5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df",
        "min_run_count": 2,
        "name": "arithmetic.DateInferOps.time_subtract_datetimes",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "arithmetic:369",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "18cc1b886b317cb6bab1f567ba5db36aeca5a369003feeaede9359773003f841",
        "warmup_time": -1
    },
    "arithmetic.DateInferOps.time_timedelta_plus_datetime": {
        "code": "class DateInferOps:\n    def time_timedelta_plus_datetime(self, df):\n        df[\"timedelta\"] + df[\"datetime64\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateInferOps:\n    def setup_cache(self):\n        N = 5 * 10 ** 5\n        df = DataFrame({\"datetime64\": np.arange(N).astype(\"datetime64[ms]\")})\n        df[\"timedelta\"] = df[\"datetime64\"] - df[\"datetime64\"]\n        return df",
        "min_run_count": 2,
        "name": "arithmetic.DateInferOps.time_timedelta_plus_datetime",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "arithmetic:369",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6a87b192531508496be25c41ddd843e324aed474b64821a555e2cd23da53e8d1",
        "warmup_time": -1
    },
    "arithmetic.FrameWithFrameWide.time_op_different_blocks": {
        "code": "class FrameWithFrameWide:\n    def time_op_different_blocks(self, op, shape):\n        # blocks (and dtypes) are not aligned\n        op(self.left, self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameWithFrameWide:\n    def setup(self, op, shape):\n        # we choose dtypes so as to make the blocks\n        #  a) not perfectly match between right and left\n        #  b) appreciably bigger than single columns\n        n_rows, n_cols = shape\n    \n        if op is operator.floordiv:\n            # floordiv is much slower than the other operations -> use less data\n            n_rows = n_rows // 10\n    \n        # construct dataframe with 2 blocks\n        arr1 = np.random.randn(n_rows, n_cols // 2).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"f4\")\n        df = pd.concat([DataFrame(arr1), DataFrame(arr2)], axis=1, ignore_index=True)\n        # should already be the case, but just to be sure\n        df._consolidate_inplace()\n    \n        # TODO: GH#33198 the setting here shoudlnt need two steps\n        arr1 = np.random.randn(n_rows, max(n_cols // 4, 3)).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"i8\")\n        arr3 = np.random.randn(n_rows, n_cols // 4).astype(\"f8\")\n        df2 = pd.concat(\n            [DataFrame(arr1), DataFrame(arr2), DataFrame(arr3)],\n            axis=1,\n            ignore_index=True,\n        )\n        # should already be the case, but just to be sure\n        df2._consolidate_inplace()\n    \n        self.left = df\n        self.right = df2",
        "min_run_count": 2,
        "name": "arithmetic.FrameWithFrameWide.time_op_different_blocks",
        "number": 0,
        "param_names": [
            "op",
            "shape"
        ],
        "params": [
            [
                "<built-in function add>",
                "<built-in function floordiv>",
                "<built-in function gt>"
            ],
            [
                "(1000000, 10)",
                "(100000, 100)",
                "(10000, 1000)",
                "(1000, 10000)"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "96ae2587daccaf30caf62c4441ce43fbd67b2dd8280db30346b564aa42881717",
        "warmup_time": -1
    },
    "arithmetic.FrameWithFrameWide.time_op_same_blocks": {
        "code": "class FrameWithFrameWide:\n    def time_op_same_blocks(self, op, shape):\n        # blocks (and dtypes) are aligned\n        op(self.left, self.left)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameWithFrameWide:\n    def setup(self, op, shape):\n        # we choose dtypes so as to make the blocks\n        #  a) not perfectly match between right and left\n        #  b) appreciably bigger than single columns\n        n_rows, n_cols = shape\n    \n        if op is operator.floordiv:\n            # floordiv is much slower than the other operations -> use less data\n            n_rows = n_rows // 10\n    \n        # construct dataframe with 2 blocks\n        arr1 = np.random.randn(n_rows, n_cols // 2).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"f4\")\n        df = pd.concat([DataFrame(arr1), DataFrame(arr2)], axis=1, ignore_index=True)\n        # should already be the case, but just to be sure\n        df._consolidate_inplace()\n    \n        # TODO: GH#33198 the setting here shoudlnt need two steps\n        arr1 = np.random.randn(n_rows, max(n_cols // 4, 3)).astype(\"f8\")\n        arr2 = np.random.randn(n_rows, n_cols // 2).astype(\"i8\")\n        arr3 = np.random.randn(n_rows, n_cols // 4).astype(\"f8\")\n        df2 = pd.concat(\n            [DataFrame(arr1), DataFrame(arr2), DataFrame(arr3)],\n            axis=1,\n            ignore_index=True,\n        )\n        # should already be the case, but just to be sure\n        df2._consolidate_inplace()\n    \n        self.left = df\n        self.right = df2",
        "min_run_count": 2,
        "name": "arithmetic.FrameWithFrameWide.time_op_same_blocks",
        "number": 0,
        "param_names": [
            "op",
            "shape"
        ],
        "params": [
            [
                "<built-in function add>",
                "<built-in function floordiv>",
                "<built-in function gt>"
            ],
            [
                "(1000000, 10)",
                "(100000, 100)",
                "(10000, 1000)",
                "(1000, 10000)"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "310f489e643b1cad082d54ece57fb98a226a9eef939228059d1ce639f605a540",
        "warmup_time": -1
    },
    "arithmetic.IndexArithmetic.time_add": {
        "code": "class IndexArithmetic:\n    def time_add(self, dtype):\n        self.index + 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10 ** 6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)",
        "min_run_count": 2,
        "name": "arithmetic.IndexArithmetic.time_add",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "60f8497a366e39f013db86b176364baf7a86c46d8018598ddde81bd3acbee597",
        "warmup_time": -1
    },
    "arithmetic.IndexArithmetic.time_divide": {
        "code": "class IndexArithmetic:\n    def time_divide(self, dtype):\n        self.index / 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10 ** 6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)",
        "min_run_count": 2,
        "name": "arithmetic.IndexArithmetic.time_divide",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "72e5dff37dd9f6fc888febd7ca2bfe89204ab5f4a10452d37e62749fafbaaa86",
        "warmup_time": -1
    },
    "arithmetic.IndexArithmetic.time_modulo": {
        "code": "class IndexArithmetic:\n    def time_modulo(self, dtype):\n        self.index % 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10 ** 6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)",
        "min_run_count": 2,
        "name": "arithmetic.IndexArithmetic.time_modulo",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "11feeaca5c3b8376e30cef75c74fbc7039aea8b64d386d1a6590c76cc0789bc9",
        "warmup_time": -1
    },
    "arithmetic.IndexArithmetic.time_multiply": {
        "code": "class IndexArithmetic:\n    def time_multiply(self, dtype):\n        self.index * 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10 ** 6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)",
        "min_run_count": 2,
        "name": "arithmetic.IndexArithmetic.time_multiply",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "48bfc99389f5c6a9f59b662c254e5f19537c346ea77cc94cf944dc4cc2dab626",
        "warmup_time": -1
    },
    "arithmetic.IndexArithmetic.time_subtract": {
        "code": "class IndexArithmetic:\n    def time_subtract(self, dtype):\n        self.index - 2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexArithmetic:\n    def setup(self, dtype):\n        N = 10 ** 6\n        indexes = {\"int\": \"makeIntIndex\", \"float\": \"makeFloatIndex\"}\n        self.index = getattr(tm, indexes[dtype])(N)",
        "min_run_count": 2,
        "name": "arithmetic.IndexArithmetic.time_subtract",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c3c0d7d99d76711097f92b57081d4f99e15eab403028134bcc12e797d0db21bc",
        "warmup_time": -1
    },
    "arithmetic.IntFrameWithScalar.time_frame_op_with_scalar": {
        "code": "class IntFrameWithScalar:\n    def time_frame_op_with_scalar(self, dtype, scalar, op):\n        op(self.df, scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntFrameWithScalar:\n    def setup(self, dtype, scalar, op):\n        arr = np.random.randn(20000, 100)\n        self.df = DataFrame(arr.astype(dtype))",
        "min_run_count": 2,
        "name": "arithmetic.IntFrameWithScalar.time_frame_op_with_scalar",
        "number": 0,
        "param_names": [
            "dtype",
            "scalar",
            "op"
        ],
        "params": [
            [
                "<class 'numpy.float64'>",
                "<class 'numpy.int64'>"
            ],
            [
                "2",
                "3.0",
                "4",
                "5.0"
            ],
            [
                "<built-in function add>",
                "<built-in function sub>",
                "<built-in function mul>",
                "<built-in function truediv>",
                "<built-in function floordiv>",
                "<built-in function pow>",
                "<built-in function mod>",
                "<built-in function eq>",
                "<built-in function ne>",
                "<built-in function gt>",
                "<built-in function ge>",
                "<built-in function lt>",
                "<built-in function le>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "17cc3015c45764be50024cbe52247cfe2100d4020bdf03e0b04bea2f932fe975",
        "warmup_time": -1
    },
    "arithmetic.IrregularOps.time_add": {
        "code": "class IrregularOps:\n    def time_add(self):\n        self.left + self.right\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IrregularOps:\n    def setup(self):\n        N = 10 ** 5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        s = Series(np.random.randn(N), index=idx)\n        self.left = s.sample(frac=1)\n        self.right = s.sample(frac=1)",
        "min_run_count": 2,
        "name": "arithmetic.IrregularOps.time_add",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "53bbd618fcae9bd5619956a26c42f845e8469861d5d14a008418a05622e7fdc2",
        "warmup_time": -1
    },
    "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis0": {
        "code": "class MixedFrameWithSeriesAxis:\n    def time_frame_op_with_series_axis0(self, opname):\n        getattr(self.df, opname)(self.ser, axis=0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MixedFrameWithSeriesAxis:\n    def setup(self, opname):\n        arr = np.arange(10 ** 6).reshape(1000, -1)\n        df = DataFrame(arr)\n        df[\"C\"] = 1.0\n        self.df = df\n        self.ser = df[0]\n        self.row = df.iloc[0]",
        "min_run_count": 2,
        "name": "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis0",
        "number": 0,
        "param_names": [
            "opname"
        ],
        "params": [
            [
                "'eq'",
                "'ne'",
                "'lt'",
                "'le'",
                "'ge'",
                "'gt'",
                "'add'",
                "'sub'",
                "'truediv'",
                "'floordiv'",
                "'mul'",
                "'pow'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "98c7c8d42cb9f6c9bae69d71ccfdcb2e413ac740f694c9336aa8905075b60b02",
        "warmup_time": -1
    },
    "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis1": {
        "code": "class MixedFrameWithSeriesAxis:\n    def time_frame_op_with_series_axis1(self, opname):\n        getattr(operator, opname)(self.df, self.ser)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MixedFrameWithSeriesAxis:\n    def setup(self, opname):\n        arr = np.arange(10 ** 6).reshape(1000, -1)\n        df = DataFrame(arr)\n        df[\"C\"] = 1.0\n        self.df = df\n        self.ser = df[0]\n        self.row = df.iloc[0]",
        "min_run_count": 2,
        "name": "arithmetic.MixedFrameWithSeriesAxis.time_frame_op_with_series_axis1",
        "number": 0,
        "param_names": [
            "opname"
        ],
        "params": [
            [
                "'eq'",
                "'ne'",
                "'lt'",
                "'le'",
                "'ge'",
                "'gt'",
                "'add'",
                "'sub'",
                "'truediv'",
                "'floordiv'",
                "'mul'",
                "'pow'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fcdd41f763d01cdbb84bf2a6adba1cfcce4603ed140a7ac784ac8b86affa204d",
        "warmup_time": -1
    },
    "arithmetic.NumericInferOps.time_add": {
        "code": "class NumericInferOps:\n    def time_add(self, dtype):\n        self.df[\"A\"] + self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10 ** 5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )",
        "min_run_count": 2,
        "name": "arithmetic.NumericInferOps.time_add",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.int32'>",
                "<class 'numpy.uint32'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float32'>",
                "<class 'numpy.float64'>",
                "<class 'numpy.int16'>",
                "<class 'numpy.int8'>",
                "<class 'numpy.uint16'>",
                "<class 'numpy.uint8'>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f033b8548bcff62afe356eb72ea1ae93d917e456fc59abb0ef7ea5abacc72cab",
        "warmup_time": -1
    },
    "arithmetic.NumericInferOps.time_divide": {
        "code": "class NumericInferOps:\n    def time_divide(self, dtype):\n        self.df[\"A\"] / self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10 ** 5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )",
        "min_run_count": 2,
        "name": "arithmetic.NumericInferOps.time_divide",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.int32'>",
                "<class 'numpy.uint32'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float32'>",
                "<class 'numpy.float64'>",
                "<class 'numpy.int16'>",
                "<class 'numpy.int8'>",
                "<class 'numpy.uint16'>",
                "<class 'numpy.uint8'>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c6fde755f0370df47890e53c815fe08818d200ced358b1a988140141918237b2",
        "warmup_time": -1
    },
    "arithmetic.NumericInferOps.time_modulo": {
        "code": "class NumericInferOps:\n    def time_modulo(self, dtype):\n        self.df[\"A\"] % self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10 ** 5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )",
        "min_run_count": 2,
        "name": "arithmetic.NumericInferOps.time_modulo",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.int32'>",
                "<class 'numpy.uint32'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float32'>",
                "<class 'numpy.float64'>",
                "<class 'numpy.int16'>",
                "<class 'numpy.int8'>",
                "<class 'numpy.uint16'>",
                "<class 'numpy.uint8'>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "310df75d671ab91fe10dacf1cd5678500c935153032ee8e74c776a929e77139a",
        "warmup_time": -1
    },
    "arithmetic.NumericInferOps.time_multiply": {
        "code": "class NumericInferOps:\n    def time_multiply(self, dtype):\n        self.df[\"A\"] * self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10 ** 5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )",
        "min_run_count": 2,
        "name": "arithmetic.NumericInferOps.time_multiply",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.int32'>",
                "<class 'numpy.uint32'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float32'>",
                "<class 'numpy.float64'>",
                "<class 'numpy.int16'>",
                "<class 'numpy.int8'>",
                "<class 'numpy.uint16'>",
                "<class 'numpy.uint8'>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "31f710543dc8777e8bd65b3e2aff9ed06cd7b5ba4158c6c661676d6c125111ad",
        "warmup_time": -1
    },
    "arithmetic.NumericInferOps.time_subtract": {
        "code": "class NumericInferOps:\n    def time_subtract(self, dtype):\n        self.df[\"A\"] - self.df[\"B\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericInferOps:\n    def setup(self, dtype):\n        N = 5 * 10 ** 5\n        self.df = DataFrame(\n            {\"A\": np.arange(N).astype(dtype), \"B\": np.arange(N).astype(dtype)}\n        )",
        "min_run_count": 2,
        "name": "arithmetic.NumericInferOps.time_subtract",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.int32'>",
                "<class 'numpy.uint32'>",
                "<class 'numpy.uint64'>",
                "<class 'numpy.float32'>",
                "<class 'numpy.float64'>",
                "<class 'numpy.int16'>",
                "<class 'numpy.int8'>",
                "<class 'numpy.uint16'>",
                "<class 'numpy.uint8'>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "05e0d2043fb5ecc3304fcaffc554373dc9f88fac279652243d99973440ef2d8c",
        "warmup_time": -1
    },
    "arithmetic.OffsetArrayArithmetic.time_add_dti_offset": {
        "code": "class OffsetArrayArithmetic:\n    def time_add_dti_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.rng + offset\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OffsetArrayArithmetic:\n    def setup(self, offset):\n        N = 10000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"T\")\n        self.rng = rng\n        self.ser = Series(rng)",
        "min_run_count": 2,
        "name": "arithmetic.OffsetArrayArithmetic.time_add_dti_offset",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1ba2a2ca36b167967741333eb7366ad1b1e4c8b9ee5db0ddbd9632e934f16e8e",
        "warmup_time": -1
    },
    "arithmetic.OffsetArrayArithmetic.time_add_series_offset": {
        "code": "class OffsetArrayArithmetic:\n    def time_add_series_offset(self, offset):\n        with warnings.catch_warnings(record=True):\n            self.ser + offset\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OffsetArrayArithmetic:\n    def setup(self, offset):\n        N = 10000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"T\")\n        self.rng = rng\n        self.ser = Series(rng)",
        "min_run_count": 2,
        "name": "arithmetic.OffsetArrayArithmetic.time_add_series_offset",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9e3db5d52584da2030628a2b3dfc64d1cffd727b1978f718616940ebb40403bb",
        "warmup_time": -1
    },
    "arithmetic.OpWithFillValue.time_frame_op_with_fill_value_no_nas": {
        "code": "class OpWithFillValue:\n    def time_frame_op_with_fill_value_no_nas(self):\n        self.df.add(self.df, fill_value=4)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OpWithFillValue:\n    def setup(self):\n        # GH#31300\n        arr = np.arange(10 ** 6)\n        df = DataFrame({\"A\": arr})\n        ser = df[\"A\"]\n    \n        self.df = df\n        self.ser = ser",
        "min_run_count": 2,
        "name": "arithmetic.OpWithFillValue.time_frame_op_with_fill_value_no_nas",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "33c6a41c1e2f1bac1505178257e48a1c9a358f31bb5db2f8e5b8357cdc31ff7b",
        "warmup_time": -1
    },
    "arithmetic.OpWithFillValue.time_series_op_with_fill_value_no_nas": {
        "code": "class OpWithFillValue:\n    def time_series_op_with_fill_value_no_nas(self):\n        self.ser.add(self.ser, fill_value=4)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass OpWithFillValue:\n    def setup(self):\n        # GH#31300\n        arr = np.arange(10 ** 6)\n        df = DataFrame({\"A\": arr})\n        ser = df[\"A\"]\n    \n        self.df = df\n        self.ser = ser",
        "min_run_count": 2,
        "name": "arithmetic.OpWithFillValue.time_series_op_with_fill_value_no_nas",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3f3bc6cd4a1c112767583f9641ba3e062762235378684d7497495191dfa00bae",
        "warmup_time": -1
    },
    "arithmetic.Ops.time_frame_add": {
        "code": "class Ops:\n    def time_frame_add(self, use_numexpr, threads):\n        self.df + self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)",
        "min_run_count": 2,
        "name": "arithmetic.Ops.time_frame_add",
        "number": 0,
        "param_names": [
            "use_numexpr",
            "threads"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'default'",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "173dfb8c14d4f1e45058ae77d74a28966785fc801b28902fd8448d30ac4ff7d8",
        "warmup_time": -1
    },
    "arithmetic.Ops.time_frame_comparison": {
        "code": "class Ops:\n    def time_frame_comparison(self, use_numexpr, threads):\n        self.df > self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)",
        "min_run_count": 2,
        "name": "arithmetic.Ops.time_frame_comparison",
        "number": 0,
        "param_names": [
            "use_numexpr",
            "threads"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'default'",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b9edf1afa79c0a69d8e9647b98beb73e32760b78ff938a190dc6b42ccac38b11",
        "warmup_time": -1
    },
    "arithmetic.Ops.time_frame_mult": {
        "code": "class Ops:\n    def time_frame_mult(self, use_numexpr, threads):\n        self.df * self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)",
        "min_run_count": 2,
        "name": "arithmetic.Ops.time_frame_mult",
        "number": 0,
        "param_names": [
            "use_numexpr",
            "threads"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'default'",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "911cfaa0ecf7737245490bf8a69723a5301ce60c296a33915a8eb9c09d7cd279",
        "warmup_time": -1
    },
    "arithmetic.Ops.time_frame_multi_and": {
        "code": "class Ops:\n    def time_frame_multi_and(self, use_numexpr, threads):\n        self.df[(self.df > 0) & (self.df2 > 0)]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops:\n    def setup(self, use_numexpr, threads):\n        self.df = DataFrame(np.random.randn(20000, 100))\n        self.df2 = DataFrame(np.random.randn(20000, 100))\n    \n        if threads != \"default\":\n            expr.set_numexpr_threads(threads)\n        if not use_numexpr:\n            expr.set_use_numexpr(False)",
        "min_run_count": 2,
        "name": "arithmetic.Ops.time_frame_multi_and",
        "number": 0,
        "param_names": [
            "use_numexpr",
            "threads"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'default'",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "27fe96278213fdc7fe35ca52941a5bf4e3def23517666891d790d2d443a98ef2",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_dot": {
        "code": "class Ops2:\n    def time_frame_dot(self):\n        self.df.dot(self.df2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_dot",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "888b824411553b458741d3b22564b57ab9fb1dd7dd3d242ef517a01a0737756e",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_float_div": {
        "code": "class Ops2:\n    def time_frame_float_div(self):\n        self.df // self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_float_div",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "855c7378c2f326f722eee54b7e4c9ccf64b189fe31f38fb056ee5145a7d5d555",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_float_div_by_zero": {
        "code": "class Ops2:\n    def time_frame_float_div_by_zero(self):\n        self.df / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_float_div_by_zero",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f65235e23e1c4a221cbf614fbe233b19a15259b886382073bd98e5c44c9a6e06",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_float_floor_by_zero": {
        "code": "class Ops2:\n    def time_frame_float_floor_by_zero(self):\n        self.df // 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_float_floor_by_zero",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8c28cd2f291084e6bf6d3984891883ce05a2dd9e7df8e7323cec2f2d85b40d8e",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_float_mod": {
        "code": "class Ops2:\n    def time_frame_float_mod(self):\n        self.df % self.df2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_float_mod",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "19f1a69ade614cbf00acacccec937fc80ddfa5bd54e4d28db03291e49e17e585",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_int_div_by_zero": {
        "code": "class Ops2:\n    def time_frame_int_div_by_zero(self):\n        self.df_int / 0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_int_div_by_zero",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "75a7633f774d067643352f32f3f761e97e58355672bf9b7e62016df2acddbb87",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_int_mod": {
        "code": "class Ops2:\n    def time_frame_int_mod(self):\n        self.df_int % self.df2_int\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_int_mod",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e9f6def33ffd3b668b60586bf02e605f18d68f5d80c41d2ab0788c46288422d9",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_frame_series_dot": {
        "code": "class Ops2:\n    def time_frame_series_dot(self):\n        self.df.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_frame_series_dot",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8be22ce70f313dd1786d21e8c4f779b63f03f67169929451d2e311a54d6211b2",
        "warmup_time": -1
    },
    "arithmetic.Ops2.time_series_dot": {
        "code": "class Ops2:\n    def time_series_dot(self):\n        self.s.dot(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Ops2:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N, N))\n        self.df2 = DataFrame(np.random.randn(N, N))\n    \n        self.df_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n        self.df2_int = DataFrame(\n            np.random.randint(\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\n            )\n        )\n    \n        self.s = Series(np.random.randn(N))",
        "min_run_count": 2,
        "name": "arithmetic.Ops2.time_series_dot",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "28bfa3c9533ad9b69f10488554394ff902cca270fab5488e71a2102290daba44",
        "warmup_time": -1
    },
    "arithmetic.TimedeltaOps.time_add_td_ts": {
        "code": "class TimedeltaOps:\n    def time_add_td_ts(self):\n        self.td + self.ts\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimedeltaOps:\n    def setup(self):\n        self.td = to_timedelta(np.arange(1000000))\n        self.ts = Timestamp(\"2000\")",
        "min_run_count": 2,
        "name": "arithmetic.TimedeltaOps.time_add_td_ts",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ee3abda2771a3808efc316e236cd6de15f8678b03e2a27e6f75792edbbe543ec",
        "warmup_time": -1
    },
    "arithmetic.Timeseries.time_series_timestamp_compare": {
        "code": "class Timeseries:\n    def time_series_timestamp_compare(self, tz):\n        self.s <= self.ts\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))",
        "min_run_count": 2,
        "name": "arithmetic.Timeseries.time_series_timestamp_compare",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "31f354e39fe3a2354bf81252410549289393fee546b1409ff54ccc861431f9a2",
        "warmup_time": -1
    },
    "arithmetic.Timeseries.time_timestamp_ops_diff": {
        "code": "class Timeseries:\n    def time_timestamp_ops_diff(self, tz):\n        self.s2.diff()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))",
        "min_run_count": 2,
        "name": "arithmetic.Timeseries.time_timestamp_ops_diff",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "16199b025d7a6ed99e73471e8bfd227a67b7c0b42de0c09ff53d667321ae501d",
        "warmup_time": -1
    },
    "arithmetic.Timeseries.time_timestamp_ops_diff_with_shift": {
        "code": "class Timeseries:\n    def time_timestamp_ops_diff_with_shift(self, tz):\n        self.s - self.s.shift()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))",
        "min_run_count": 2,
        "name": "arithmetic.Timeseries.time_timestamp_ops_diff_with_shift",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bc1e94aac9ba88b1a75be93efad731ab93783e6878b881d081ef7b2d83c71265",
        "warmup_time": -1
    },
    "arithmetic.Timeseries.time_timestamp_series_compare": {
        "code": "class Timeseries:\n    def time_timestamp_series_compare(self, tz):\n        self.ts >= self.s\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Timeseries:\n    def setup(self, tz):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"T\", tz=tz))\n        self.ts = self.s[halfway]\n    \n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))",
        "min_run_count": 2,
        "name": "arithmetic.Timeseries.time_timestamp_series_compare",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3ed0d51f10ad91aac37d8356948e2b4947bbeac92bcba4763f4ce410003829ba",
        "warmup_time": -1
    },
    "array.BooleanArray.time_constructor": {
        "code": "class BooleanArray:\n    def time_constructor(self):\n        pd.arrays.BooleanArray(self.data, self.mask)\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])",
        "min_run_count": 2,
        "name": "array.BooleanArray.time_constructor",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "31f0c0638e5908b3b2f79ec954e3e3c5f9b247f04708fe2a8ba53b4df1b161d5",
        "warmup_time": -1
    },
    "array.BooleanArray.time_from_bool_array": {
        "code": "class BooleanArray:\n    def time_from_bool_array(self):\n        pd.array(self.values_bool, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])",
        "min_run_count": 2,
        "name": "array.BooleanArray.time_from_bool_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "49de818c0d3213d4624b41ad1583ffa3da28d65f2dd89a30c9ed9ce4d8902300",
        "warmup_time": -1
    },
    "array.BooleanArray.time_from_float_array": {
        "code": "class BooleanArray:\n    def time_from_float_array(self):\n        pd.array(self.values_float, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])",
        "min_run_count": 2,
        "name": "array.BooleanArray.time_from_float_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "00f65facf261a9f506e825a7a84d17cc35d7f00ff17f090622cbbdb8e6a538dc",
        "warmup_time": -1
    },
    "array.BooleanArray.time_from_integer_array": {
        "code": "class BooleanArray:\n    def time_from_integer_array(self):\n        pd.array(self.values_integer, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])",
        "min_run_count": 2,
        "name": "array.BooleanArray.time_from_integer_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d27d54d2b7793c51154ffb049d0e1508e27dc0b3cdfa4f734789da01a48e0abf",
        "warmup_time": -1
    },
    "array.BooleanArray.time_from_integer_like": {
        "code": "class BooleanArray:\n    def time_from_integer_like(self):\n        pd.array(self.values_integer_like, dtype=\"boolean\")\n\n    def setup(self):\n        self.values_bool = np.array([True, False, True, False])\n        self.values_float = np.array([1.0, 0.0, 1.0, 0.0])\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.values_integer_like = [1, 0, 1, 0]\n        self.data = np.array([True, False, True, False])\n        self.mask = np.array([False, False, True, False])",
        "min_run_count": 2,
        "name": "array.BooleanArray.time_from_integer_like",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6c37947cc0814a4fabfcf5fc4ebcb76a3e8d231c4fb5ca15eb3d0f502617a17d",
        "warmup_time": -1
    },
    "array.IntegerArray.time_constructor": {
        "code": "class IntegerArray:\n    def time_constructor(self):\n        pd.arrays.IntegerArray(self.data, self.mask)\n\n    def setup(self):\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.data = np.array([1, 2, 3, 4], dtype=\"int64\")\n        self.mask = np.array([False, False, True, False])",
        "min_run_count": 2,
        "name": "array.IntegerArray.time_constructor",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b63a4215a3e2f6911380a59456a412ba4bea048dc5f70bf01902a3abe5547840",
        "warmup_time": -1
    },
    "array.IntegerArray.time_from_integer_array": {
        "code": "class IntegerArray:\n    def time_from_integer_array(self):\n        pd.array(self.values_integer, dtype=\"Int64\")\n\n    def setup(self):\n        self.values_integer = np.array([1, 0, 1, 0])\n        self.data = np.array([1, 2, 3, 4], dtype=\"int64\")\n        self.mask = np.array([False, False, True, False])",
        "min_run_count": 2,
        "name": "array.IntegerArray.time_from_integer_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5627a03feaf9f42a67af0aa3491199fc100c88da7d51ddec2a2cc209053e04f3",
        "warmup_time": -1
    },
    "attrs_caching.DataFrameAttributes.time_get_index": {
        "code": "class DataFrameAttributes:\n    def time_get_index(self):\n        self.foo = self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index",
        "min_run_count": 2,
        "name": "attrs_caching.DataFrameAttributes.time_get_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9783112df8bedac7893104cd6fd92598ef71962fe1774b08be418b99583d7fa7",
        "warmup_time": -1
    },
    "attrs_caching.DataFrameAttributes.time_set_index": {
        "code": "class DataFrameAttributes:\n    def time_set_index(self):\n        self.df.index = self.cur_index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameAttributes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 6))\n        self.cur_index = self.df.index",
        "min_run_count": 2,
        "name": "attrs_caching.DataFrameAttributes.time_set_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b34bb7eb8426bdd2eb9d8e0550ea2573475694ddc9f971fd9a29f15bf16732b0",
        "warmup_time": -1
    },
    "attrs_caching.SeriesArrayAttribute.time_array": {
        "code": "class SeriesArrayAttribute:\n    def time_array(self, dtype):\n        self.series.array\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesArrayAttribute:\n    def setup(self, dtype):\n        if dtype == \"numeric\":\n            self.series = pd.Series([1, 2, 3])\n        elif dtype == \"object\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=object)\n        elif dtype == \"category\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")\n        elif dtype == \"datetime64\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3))\n        elif dtype == \"datetime64tz\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3, tz=\"UTC\"))",
        "min_run_count": 2,
        "name": "attrs_caching.SeriesArrayAttribute.time_array",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'numeric'",
                "'object'",
                "'category'",
                "'datetime64'",
                "'datetime64tz'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "71871bee8b7f7a74c594352ad1177b3201818e5ffe6296b02844d93f2e74c57b",
        "warmup_time": -1
    },
    "attrs_caching.SeriesArrayAttribute.time_extract_array": {
        "code": "class SeriesArrayAttribute:\n    def time_extract_array(self, dtype):\n        extract_array(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesArrayAttribute:\n    def setup(self, dtype):\n        if dtype == \"numeric\":\n            self.series = pd.Series([1, 2, 3])\n        elif dtype == \"object\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=object)\n        elif dtype == \"category\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")\n        elif dtype == \"datetime64\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3))\n        elif dtype == \"datetime64tz\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3, tz=\"UTC\"))",
        "min_run_count": 2,
        "name": "attrs_caching.SeriesArrayAttribute.time_extract_array",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'numeric'",
                "'object'",
                "'category'",
                "'datetime64'",
                "'datetime64tz'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5c9e10a019a9c3c1a6f4016572eac561387c3cc14086cde81066ae5d495b6bae",
        "warmup_time": -1
    },
    "attrs_caching.SeriesArrayAttribute.time_extract_array_numpy": {
        "code": "class SeriesArrayAttribute:\n    def time_extract_array_numpy(self, dtype):\n        extract_array(self.series, extract_numpy=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesArrayAttribute:\n    def setup(self, dtype):\n        if dtype == \"numeric\":\n            self.series = pd.Series([1, 2, 3])\n        elif dtype == \"object\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=object)\n        elif dtype == \"category\":\n            self.series = pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")\n        elif dtype == \"datetime64\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3))\n        elif dtype == \"datetime64tz\":\n            self.series = pd.Series(pd.date_range(\"2013\", periods=3, tz=\"UTC\"))",
        "min_run_count": 2,
        "name": "attrs_caching.SeriesArrayAttribute.time_extract_array_numpy",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'numeric'",
                "'object'",
                "'category'",
                "'datetime64'",
                "'datetime64tz'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "34310e30090bb516b844f357295ebbe46f2980040632e1178dffc041a7635892",
        "warmup_time": -1
    },
    "boolean.TimeLogicalOps.time_and_array": {
        "code": "class TimeLogicalOps:\n    def time_and_array(self):\n        self.left & self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)",
        "min_run_count": 2,
        "name": "boolean.TimeLogicalOps.time_and_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6f948c075c42597b3abbe166b111d3f02c0aa11a2fd01b376b96547a7a0ece18",
        "warmup_time": -1
    },
    "boolean.TimeLogicalOps.time_and_scalar": {
        "code": "class TimeLogicalOps:\n    def time_and_scalar(self):\n        self.left & True\n        self.left & False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)",
        "min_run_count": 2,
        "name": "boolean.TimeLogicalOps.time_and_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "73483ccace6f6debdb2fd885f8fd8ffee9883f4e6dad1587a13239b8be135868",
        "warmup_time": -1
    },
    "boolean.TimeLogicalOps.time_or_array": {
        "code": "class TimeLogicalOps:\n    def time_or_array(self):\n        self.left | self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)",
        "min_run_count": 2,
        "name": "boolean.TimeLogicalOps.time_or_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "dc01bb9cbcdc979b4fbe050df208268a15ff5f328081a7fd09c41283c33bfa5d",
        "warmup_time": -1
    },
    "boolean.TimeLogicalOps.time_or_scalar": {
        "code": "class TimeLogicalOps:\n    def time_or_scalar(self):\n        self.left | True\n        self.left | False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)",
        "min_run_count": 2,
        "name": "boolean.TimeLogicalOps.time_or_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a9dcf90a110c0c703887ee44358e18a6930758987f7f1e9f921dd5ff4c84234e",
        "warmup_time": -1
    },
    "boolean.TimeLogicalOps.time_xor_array": {
        "code": "class TimeLogicalOps:\n    def time_xor_array(self):\n        self.left ^ self.right\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)",
        "min_run_count": 2,
        "name": "boolean.TimeLogicalOps.time_xor_array",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e093e59c2f51a4998acf114ad54d2ab5d62d38548aab71f3f5c6adbe6bc46792",
        "warmup_time": -1
    },
    "boolean.TimeLogicalOps.time_xor_scalar": {
        "code": "class TimeLogicalOps:\n    def time_xor_scalar(self):\n        self.left ^ True\n        self.left ^ False\n\n    def setup(self):\n        N = 10_000\n        left, right, lmask, rmask = np.random.randint(0, 2, size=(4, N)).astype(\"bool\")\n        self.left = pd.arrays.BooleanArray(left, lmask)\n        self.right = pd.arrays.BooleanArray(right, rmask)",
        "min_run_count": 2,
        "name": "boolean.TimeLogicalOps.time_xor_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eb50d9fee1d2beff8da51a2f128bb84bfa76379e9a699ae60dec8e82655bef3c",
        "warmup_time": -1
    },
    "categoricals.CategoricalSlicing.time_getitem_bool_array": {
        "code": "class CategoricalSlicing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10 ** 6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"",
        "min_run_count": 2,
        "name": "categoricals.CategoricalSlicing.time_getitem_bool_array",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2f24f3b3fe1a33d3eb3c8d08bf6b77d7d666e6128fceb55830f586e298ee6f36",
        "warmup_time": -1
    },
    "categoricals.CategoricalSlicing.time_getitem_list": {
        "code": "class CategoricalSlicing:\n    def time_getitem_list(self, index):\n        self.data[self.list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10 ** 6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"",
        "min_run_count": 2,
        "name": "categoricals.CategoricalSlicing.time_getitem_list",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7132ded7937da9d7f4e856da08de776295032e3b01ae284a1c9cba02870d1d3a",
        "warmup_time": -1
    },
    "categoricals.CategoricalSlicing.time_getitem_list_like": {
        "code": "class CategoricalSlicing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10 ** 6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"",
        "min_run_count": 2,
        "name": "categoricals.CategoricalSlicing.time_getitem_list_like",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "085ff63b5ba9212896fc0d538d1a468c74c1a4f5517ce7359f3b72f0a9050e1e",
        "warmup_time": -1
    },
    "categoricals.CategoricalSlicing.time_getitem_scalar": {
        "code": "class CategoricalSlicing:\n    def time_getitem_scalar(self, index):\n        self.data[self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10 ** 6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"",
        "min_run_count": 2,
        "name": "categoricals.CategoricalSlicing.time_getitem_scalar",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "dae82c5834bbedb2bd9322c62c8af54a648f6aec6ff7eba3a07bbf729c9c32b8",
        "warmup_time": -1
    },
    "categoricals.CategoricalSlicing.time_getitem_slice": {
        "code": "class CategoricalSlicing:\n    def time_getitem_slice(self, index):\n        self.data[: self.scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalSlicing:\n    def setup(self, index):\n        N = 10 ** 6\n        categories = [\"a\", \"b\", \"c\"]\n        values = [0] * N + [1] * N + [2] * N\n        if index == \"monotonic_incr\":\n            self.data = pd.Categorical.from_codes(values, categories=categories)\n        elif index == \"monotonic_decr\":\n            self.data = pd.Categorical.from_codes(\n                list(reversed(values)), categories=categories\n            )\n        elif index == \"non_monotonic\":\n            self.data = pd.Categorical.from_codes([0, 1, 2] * N, categories=categories)\n        else:\n            raise ValueError(f\"Invalid index param: {index}\")\n    \n        self.scalar = 10000\n        self.list = list(range(10000))\n        self.cat_scalar = \"b\"",
        "min_run_count": 2,
        "name": "categoricals.CategoricalSlicing.time_getitem_slice",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b3701f149af09e49874e176e62659e98e5b9d04aa52eace01ba9675f065b1d36",
        "warmup_time": -1
    },
    "categoricals.Concat.time_append_non_overlapping_index": {
        "code": "class Concat:\n    def time_append_non_overlapping_index(self):\n        self.idx_a.append(self.idx_b)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10 ** 5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)",
        "min_run_count": 2,
        "name": "categoricals.Concat.time_append_non_overlapping_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7192a23a5cc7a13c678d27e2b42b1710dcb8f51b4f9afabf4a5bdeca4395c3f8",
        "warmup_time": -1
    },
    "categoricals.Concat.time_append_overlapping_index": {
        "code": "class Concat:\n    def time_append_overlapping_index(self):\n        self.idx_a.append(self.idx_a)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10 ** 5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)",
        "min_run_count": 2,
        "name": "categoricals.Concat.time_append_overlapping_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f7d565261d35e648783747ad1679d807aa8e9a9dcda6a7a9c1df6d7f7b3f1775",
        "warmup_time": -1
    },
    "categoricals.Concat.time_concat": {
        "code": "class Concat:\n    def time_concat(self):\n        pd.concat([self.s, self.s])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10 ** 5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)",
        "min_run_count": 2,
        "name": "categoricals.Concat.time_concat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "58c2474ba277938619aa5b4783ad3b228fb95291264ccb8bf15ececd62eff367",
        "warmup_time": -1
    },
    "categoricals.Concat.time_concat_non_overlapping_index": {
        "code": "class Concat:\n    def time_concat_non_overlapping_index(self):\n        pd.concat([self.df_a, self.df_b])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10 ** 5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)",
        "min_run_count": 2,
        "name": "categoricals.Concat.time_concat_non_overlapping_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "37bd863ec926cb0efc264b7ee045fa99eee97ca35e788a5d4bd68ca2e50be5da",
        "warmup_time": -1
    },
    "categoricals.Concat.time_concat_overlapping_index": {
        "code": "class Concat:\n    def time_concat_overlapping_index(self):\n        pd.concat([self.df_a, self.df_a])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10 ** 5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)",
        "min_run_count": 2,
        "name": "categoricals.Concat.time_concat_overlapping_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b05a73c8f19ee2029277bdbfe805946079fba5dd2fceeaf2298c91b65f28c01a",
        "warmup_time": -1
    },
    "categoricals.Concat.time_union": {
        "code": "class Concat:\n    def time_union(self):\n        union_categoricals([self.a, self.b])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self):\n        N = 10 ** 5\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\n    \n        self.a = pd.Categorical(list(\"aabbcd\") * N)\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\n    \n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)",
        "min_run_count": 2,
        "name": "categoricals.Concat.time_union",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c66389cfa7ca672629f1a4bc20fed8e45701a931cd23d675df80d46cf364b672",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_all_nan": {
        "code": "class Constructor:\n    def time_all_nan(self):\n        pd.Categorical(self.values_all_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_all_nan",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d28091dc43a022c9e40746e31af0388a84286b13fe1ab06a09258739ff86f717",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_datetimes": {
        "code": "class Constructor:\n    def time_datetimes(self):\n        pd.Categorical(self.datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_datetimes",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "734fb607898460f0a13e4bffbfe43c786cbdd7ee96de7d79b239bcda0e5302db",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_datetimes_with_nat": {
        "code": "class Constructor:\n    def time_datetimes_with_nat(self):\n        pd.Categorical(self.datetimes_with_nat)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_datetimes_with_nat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6c30a23f73f17776a9f24029e9b778c12cc0388ce6361c6cc6f36c5e35e78d4a",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_existing_categorical": {
        "code": "class Constructor:\n    def time_existing_categorical(self):\n        pd.Categorical(self.categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_existing_categorical",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eb2be04ee9a0516ebeab4840e914e78272d8ab2feb4b591b6e58cd60d35171c1",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_existing_series": {
        "code": "class Constructor:\n    def time_existing_series(self):\n        pd.Categorical(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_existing_series",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9556f6f5c92895e4941665115cbde7f232353128004aa6a43e10ba6137bd154b",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_fastpath": {
        "code": "class Constructor:\n    def time_fastpath(self):\n        pd.Categorical(self.codes, self.cat_idx, fastpath=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_fastpath",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8d67405836dd8d1f326da00f39de73ca5ca84a7b06bae2527ecc4c87a27d0c61",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_from_codes_all_int8": {
        "code": "class Constructor:\n    def time_from_codes_all_int8(self):\n        pd.Categorical.from_codes(self.values_all_int8, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_from_codes_all_int8",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "12bf0819f3b8e68073c8e665b3e3569941857d68aa3b60edff22e7049f103d46",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_interval": {
        "code": "class Constructor:\n    def time_interval(self):\n        pd.Categorical(self.datetimes, categories=self.datetimes)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_interval",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "479f51de440a0d255056af0fedd7404ed5b0a8123b0450b24d420d2c4939be65",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_regular": {
        "code": "class Constructor:\n    def time_regular(self):\n        pd.Categorical(self.values, self.categories)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_regular",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5c118f3a1b5163764059e66a204abf93eddd7223a0d480adec9125e563347dd7",
        "warmup_time": -1
    },
    "categoricals.Constructor.time_with_nan": {
        "code": "class Constructor:\n    def time_with_nan(self):\n        pd.Categorical(self.values_some_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Constructor:\n    def setup(self):\n        N = 10 ** 5\n        self.categories = list(\"abcde\")\n        self.cat_idx = pd.Index(self.categories)\n        self.values = np.tile(self.categories, N)\n        self.codes = np.tile(range(len(self.categories)), N)\n    \n        self.datetimes = pd.Series(\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N / 10, freq=\"s\")\n        )\n        self.datetimes_with_nat = self.datetimes.copy()\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\n    \n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\n        self.values_all_nan = [np.nan] * len(self.values)\n        self.values_all_int8 = np.ones(N, \"int8\")\n        self.categorical = pd.Categorical(self.values, self.categories)\n        self.series = pd.Series(self.categorical)\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)",
        "min_run_count": 2,
        "name": "categoricals.Constructor.time_with_nan",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a4b928591167ed439d070966e03aad49cfddb109e84d3fd34ead0db56be4448d",
        "warmup_time": -1
    },
    "categoricals.Contains.time_categorical_contains": {
        "code": "class Contains:\n    def time_categorical_contains(self):\n        self.key in self.c\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10 ** 5\n        self.ci = tm.makeCategoricalIndex(N)\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]",
        "min_run_count": 2,
        "name": "categoricals.Contains.time_categorical_contains",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "15774a40e44d691c887ad53b9cdbd9ee727bfd7a4f277876ee826796fc3e79a1",
        "warmup_time": -1
    },
    "categoricals.Contains.time_categorical_index_contains": {
        "code": "class Contains:\n    def time_categorical_index_contains(self):\n        self.key in self.ci\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Contains:\n    def setup(self):\n        N = 10 ** 5\n        self.ci = tm.makeCategoricalIndex(N)\n        self.c = self.ci.values\n        self.key = self.ci.categories[0]",
        "min_run_count": 2,
        "name": "categoricals.Contains.time_categorical_index_contains",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "27f1c85431131211b9efdb195eaa53ca7ab42c4408771986d144aba6daa46193",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_align": {
        "code": "class Indexing:\n    def time_align(self):\n        pd.DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_align",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1ec13cef3e425653fdd82cfcc8bd1867a74ef554369d534dd08c1bcdfae7a6c7",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_get_loc": {
        "code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.category)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_get_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "49acc9035da99e60880f5b7791de3723cdd6d12674fda7e281f94a904a0619dd",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_intersection": {
        "code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_intersection",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "06416d81f1fa58ef42c5b22d601f8e02bd9dd0a3cf26abcb6f4c41fc18dd96de",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_reindex": {
        "code": "class Indexing:\n    def time_reindex(self):\n        self.index.reindex(self.index[:500])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_reindex",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0ee37828aa4835a22da7ca947f962d9d716283aa2f0772e64a85441eaa1c8149",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_reindex_missing": {
        "code": "class Indexing:\n    def time_reindex_missing(self):\n        self.index.reindex([\"a\", \"b\", \"c\", \"d\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_reindex_missing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "980b6ccedab11377337e11d9f2c5b56559b4334dd64a04ebe98f685dcfbbd2b0",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_shallow_copy": {
        "code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._view()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_shallow_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ceedb5922f47555f1c7f7fb0f03ae531adcf05df6d274affd93f79755fc65a0c",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_sort_values": {
        "code": "class Indexing:\n    def time_sort_values(self):\n        self.index.sort_values(ascending=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_sort_values",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2e1762a6a2c31564707f90a1324188704a5e55be680406f22ea3019c4f42176f",
        "warmup_time": -1
    },
    "categoricals.Indexing.time_unique": {
        "code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self):\n        N = 10 ** 5\n        self.index = pd.CategoricalIndex(range(N), range(N))\n        self.series = pd.Series(range(N), index=self.index).sort_index()\n        self.category = self.index[500]",
        "min_run_count": 2,
        "name": "categoricals.Indexing.time_unique",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "84924d57d7f29e0f2affddf008f34d31de2a5239346e359edffe00fdc625ea78",
        "warmup_time": -1
    },
    "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing": {
        "code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_decreasing(self):\n        self.c.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)",
        "min_run_count": 2,
        "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_decreasing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c4d103c6279f0b80ce554b92ebb3e5bc2c44dc1e40f2fa4ab07455ea280ab8cb",
        "warmup_time": -1
    },
    "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing": {
        "code": "class IsMonotonic:\n    def time_categorical_index_is_monotonic_increasing(self):\n        self.c.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)",
        "min_run_count": 2,
        "name": "categoricals.IsMonotonic.time_categorical_index_is_monotonic_increasing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fcebf885784c8e801b36cabd669598864a44b3d464eaef9eda7ca74df92105ad",
        "warmup_time": -1
    },
    "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing": {
        "code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_decreasing(self):\n        self.s.is_monotonic_decreasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)",
        "min_run_count": 2,
        "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_decreasing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fa8a5687d97343fae36bb22d0c776cfb090faec43b933d9f88facde7ba72c762",
        "warmup_time": -1
    },
    "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing": {
        "code": "class IsMonotonic:\n    def time_categorical_series_is_monotonic_increasing(self):\n        self.s.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IsMonotonic:\n    def setup(self):\n        N = 1000\n        self.c = pd.CategoricalIndex(list(\"a\" * N + \"b\" * N + \"c\" * N))\n        self.s = pd.Series(self.c)",
        "min_run_count": 2,
        "name": "categoricals.IsMonotonic.time_categorical_series_is_monotonic_increasing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "834fbde98d28981a9f726086c81fcfaed2914996bff27fdcdafe4769d95bb3d3",
        "warmup_time": -1
    },
    "categoricals.Rank.time_rank_int": {
        "code": "class Rank:\n    def time_rank_int(self):\n        self.s_int.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)",
        "min_run_count": 2,
        "name": "categoricals.Rank.time_rank_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e60b2c896f6f51d1c882cef02a890f1d84afe01f83cedcffa8a8b88f51b3fd73",
        "warmup_time": -1
    },
    "categoricals.Rank.time_rank_int_cat": {
        "code": "class Rank:\n    def time_rank_int_cat(self):\n        self.s_int_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)",
        "min_run_count": 2,
        "name": "categoricals.Rank.time_rank_int_cat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "08cae16d024738bfc73c49eef08c25b466c47243d6bebc99763435c332bc32be",
        "warmup_time": -1
    },
    "categoricals.Rank.time_rank_int_cat_ordered": {
        "code": "class Rank:\n    def time_rank_int_cat_ordered(self):\n        self.s_int_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)",
        "min_run_count": 2,
        "name": "categoricals.Rank.time_rank_int_cat_ordered",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6e4ac152d1791c2c653dc239b4c8186c16dd72049a00df43d3fe8411d65cfe31",
        "warmup_time": -1
    },
    "categoricals.Rank.time_rank_string": {
        "code": "class Rank:\n    def time_rank_string(self):\n        self.s_str.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)",
        "min_run_count": 2,
        "name": "categoricals.Rank.time_rank_string",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "15e98f8c81ca78e6ae078af3490c5425090e7d8c08806c2cb14ccf8913bd141e",
        "warmup_time": -1
    },
    "categoricals.Rank.time_rank_string_cat": {
        "code": "class Rank:\n    def time_rank_string_cat(self):\n        self.s_str_cat.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)",
        "min_run_count": 2,
        "name": "categoricals.Rank.time_rank_string_cat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e7e77b38962373116cfd128e01dafc8630402606065aa304f26055cb3dbc3fd3",
        "warmup_time": -1
    },
    "categoricals.Rank.time_rank_string_cat_ordered": {
        "code": "class Rank:\n    def time_rank_string_cat_ordered(self):\n        self.s_str_cat_ordered.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self):\n        N = 10 ** 5\n        ncats = 100\n    \n        self.s_str = pd.Series(tm.makeCategoricalIndex(N, ncats)).astype(str)\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\n    \n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\n        with warnings.catch_warnings(record=True):\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)",
        "min_run_count": 2,
        "name": "categoricals.Rank.time_rank_string_cat_ordered",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "30bfee01c43858743cb618d5b31470ac5a10f6069edd65ea33d77cf13f832503",
        "warmup_time": -1
    },
    "categoricals.RemoveCategories.time_remove_categories": {
        "code": "class RemoveCategories:\n    def time_remove_categories(self):\n        self.ts.cat.remove_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RemoveCategories:\n    def setup(self):\n        n = 5 * 10 ** 5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")",
        "min_run_count": 2,
        "name": "categoricals.RemoveCategories.time_remove_categories",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d5482581cd2aa8d7c153e60ce233463a0573aa46d2a1463858fd711efe6104ab",
        "warmup_time": -1
    },
    "categoricals.Repr.time_rendering": {
        "code": "class Repr:\n    def time_rendering(self):\n        str(self.sel)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        self.sel = pd.Series([\"s1234\"]).astype(\"category\")",
        "min_run_count": 2,
        "name": "categoricals.Repr.time_rendering",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8d10d682b8918c4fac813851a9bf9304346e145623189c433d8d75ac72c1e1e6",
        "warmup_time": -1
    },
    "categoricals.SearchSorted.time_categorical_contains": {
        "code": "class SearchSorted:\n    def time_categorical_contains(self):\n        self.c.searchsorted(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self):\n        N = 10 ** 5\n        self.ci = tm.makeCategoricalIndex(N).sort_values()\n        self.c = self.ci.values\n        self.key = self.ci.categories[1]",
        "min_run_count": 2,
        "name": "categoricals.SearchSorted.time_categorical_contains",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5e016d01ae15353560c9a98ef23df8fd70d6819ac978e7112451120c811e24c1",
        "warmup_time": -1
    },
    "categoricals.SearchSorted.time_categorical_index_contains": {
        "code": "class SearchSorted:\n    def time_categorical_index_contains(self):\n        self.ci.searchsorted(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self):\n        N = 10 ** 5\n        self.ci = tm.makeCategoricalIndex(N).sort_values()\n        self.c = self.ci.values\n        self.key = self.ci.categories[1]",
        "min_run_count": 2,
        "name": "categoricals.SearchSorted.time_categorical_index_contains",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "59ee1a5a2a08cfa09b0d8899d3b1ea821c5743432720d603c1e9c87ea6c77386",
        "warmup_time": -1
    },
    "categoricals.SetCategories.time_set_categories": {
        "code": "class SetCategories:\n    def time_set_categories(self):\n        self.ts.cat.set_categories(self.ts.cat.categories[::2])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetCategories:\n    def setup(self):\n        n = 5 * 10 ** 5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")",
        "min_run_count": 2,
        "name": "categoricals.SetCategories.time_set_categories",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d166a813f78eb7b464a6a17a20803823f56e47c89c73739028490364fa24e156",
        "warmup_time": -1
    },
    "categoricals.ValueCounts.time_value_counts": {
        "code": "class ValueCounts:\n    def time_value_counts(self, dropna):\n        self.ts.value_counts(dropna=dropna)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, dropna):\n        n = 5 * 10 ** 5\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\n        self.ts = pd.Series(arr).astype(\"category\")",
        "min_run_count": 2,
        "name": "categoricals.ValueCounts.time_value_counts",
        "number": 0,
        "param_names": [
            "dropna"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8e706d2e7a61a53d58304848042dcf844dd925f28a2ae14b68ec6a5426f5d245",
        "warmup_time": -1
    },
    "ctors.MultiIndexConstructor.time_multiindex_from_iterables": {
        "code": "class MultiIndexConstructor:\n    def time_multiindex_from_iterables(self):\n        MultiIndex.from_product(self.iterables)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexConstructor:\n    def setup(self):\n        N = 10 ** 4\n        self.iterables = [tm.makeStringIndex(N), range(20)]",
        "min_run_count": 2,
        "name": "ctors.MultiIndexConstructor.time_multiindex_from_iterables",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d5d70a80f85a86ede3069db75614629f9a909435eaf229854a81404307e743de",
        "warmup_time": -1
    },
    "ctors.SeriesConstructors.time_series_constructor": {
        "code": "class SeriesConstructors:\n    def time_series_constructor(self, data_fmt, with_index, dtype):\n        Series(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructors:\n    def setup(self, data_fmt, with_index, dtype):\n        if data_fmt in (gen_of_str, gen_of_tuples) and with_index:\n            raise NotImplementedError(\n                \"Series constructors do not support using generators with indexes\"\n            )\n        N = 10 ** 4\n        if dtype == \"float\":\n            arr = np.random.randn(N)\n        else:\n            arr = np.arange(N)\n        self.data = data_fmt(arr)\n        self.index = np.arange(N) if with_index else None",
        "min_run_count": 2,
        "name": "ctors.SeriesConstructors.time_series_constructor",
        "number": 1,
        "param_names": [
            "data_fmt",
            "with_index",
            "dtype"
        ],
        "params": [
            [
                "<function no_change>",
                "<class 'list'>",
                "<function list_of_str>",
                "<function gen_of_str>",
                "<function arr_dict>",
                "<function list_of_tuples>",
                "<function gen_of_tuples>",
                "<function list_of_lists>",
                "<function list_of_tuples_with_none>",
                "<function list_of_lists_with_none>"
            ],
            [
                "False",
                "True"
            ],
            [
                "'float'",
                "'int'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9be98d8d0719122c714a36dac877e3d4be808f1f8bc11d96a3791f906a66fba9",
        "warmup_time": -1
    },
    "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series": {
        "code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_index_with_series(self):\n        Index(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10 ** 4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )",
        "min_run_count": 2,
        "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_index_with_series",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b8bb9e833acdb96496dcf370c840d1e22740c13762e96254d5dd09c9ce9d08a7",
        "warmup_time": -1
    },
    "ctors.SeriesDtypesConstructors.time_dtindex_from_series": {
        "code": "class SeriesDtypesConstructors:\n    def time_dtindex_from_series(self):\n        DatetimeIndex(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10 ** 4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )",
        "min_run_count": 2,
        "name": "ctors.SeriesDtypesConstructors.time_dtindex_from_series",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4f2db185f26783eac16b517ff8ebd607b22da2ce7f33de764bc7598ba5b07c9e",
        "warmup_time": -1
    },
    "ctors.SeriesDtypesConstructors.time_index_from_array_floats": {
        "code": "class SeriesDtypesConstructors:\n    def time_index_from_array_floats(self):\n        Index(self.arr)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10 ** 4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )",
        "min_run_count": 2,
        "name": "ctors.SeriesDtypesConstructors.time_index_from_array_floats",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e15558575e47bf67fab6f24c47dbe1e2f206b2b62d6c80a842753455766ad472",
        "warmup_time": -1
    },
    "ctors.SeriesDtypesConstructors.time_index_from_array_string": {
        "code": "class SeriesDtypesConstructors:\n    def time_index_from_array_string(self):\n        Index(self.arr_str)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesDtypesConstructors:\n    def setup(self):\n        N = 10 ** 4\n        self.arr = np.random.randn(N)\n        self.arr_str = np.array([\"foo\", \"bar\", \"baz\"], dtype=object)\n        self.s = Series(\n            [Timestamp(\"20110101\"), Timestamp(\"20120101\"), Timestamp(\"20130101\")]\n            * N\n            * 10\n        )",
        "min_run_count": 2,
        "name": "ctors.SeriesDtypesConstructors.time_index_from_array_string",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "19036cacca9308b531ef518f20a8014624320bb849430596f181eb7988b766bd",
        "warmup_time": -1
    },
    "dtypes.CheckDtypes.time_is_extension_array_dtype_false": {
        "code": "class CheckDtypes:\n    def time_is_extension_array_dtype_false(self):\n        is_extension_array_dtype(self.np_dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CheckDtypes:\n    def setup(self):\n        self.ext_dtype = pd.Int64Dtype()\n        self.np_dtype = np.dtype(\"int64\")",
        "min_run_count": 2,
        "name": "dtypes.CheckDtypes.time_is_extension_array_dtype_false",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "81c7f57fc1b501fb5fe42b1928b850081d7fc62c6bda218e1faf99d2623a9dd7",
        "warmup_time": -1
    },
    "dtypes.CheckDtypes.time_is_extension_array_dtype_true": {
        "code": "class CheckDtypes:\n    def time_is_extension_array_dtype_true(self):\n        is_extension_array_dtype(self.ext_dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CheckDtypes:\n    def setup(self):\n        self.ext_dtype = pd.Int64Dtype()\n        self.np_dtype = np.dtype(\"int64\")",
        "min_run_count": 2,
        "name": "dtypes.CheckDtypes.time_is_extension_array_dtype_true",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "23b5bb2e01f5d1546ced81b111d6d84415d3945fe1392317283755c6205327cf",
        "warmup_time": -1
    },
    "dtypes.Dtypes.time_pandas_dtype": {
        "code": "class Dtypes:\n    def time_pandas_dtype(self, dtype):\n        pandas_dtype(dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)",
        "min_run_count": 2,
        "name": "dtypes.Dtypes.time_pandas_dtype",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "dtype('int64')",
                "dtype('int32')",
                "dtype('uint32')",
                "dtype('uint64')",
                "dtype('float32')",
                "dtype('float64')",
                "dtype('int16')",
                "dtype('int8')",
                "dtype('uint16')",
                "dtype('uint8')",
                "dtype('<M8')",
                "dtype('<m8')",
                "dtype('O')",
                "<class 'pandas.core.arrays.integer.Int8Dtype'>",
                "<class 'pandas.core.arrays.integer.Int16Dtype'>",
                "<class 'pandas.core.arrays.integer.Int32Dtype'>",
                "<class 'pandas.core.arrays.integer.Int64Dtype'>",
                "<class 'pandas.core.arrays.integer.UInt8Dtype'>",
                "<class 'pandas.core.arrays.integer.UInt16Dtype'>",
                "<class 'pandas.core.arrays.integer.UInt32Dtype'>",
                "<class 'pandas.core.arrays.integer.UInt64Dtype'>",
                "<class 'pandas.core.dtypes.dtypes.CategoricalDtype'>",
                "<class 'pandas.core.dtypes.dtypes.IntervalDtype'>",
                "datetime64[ns, UTC]",
                "period[D]",
                "'int64'",
                "'int32'",
                "'uint32'",
                "'uint64'",
                "'float32'",
                "'float64'",
                "'int16'",
                "'int8'",
                "'uint16'",
                "'uint8'",
                "'datetime64'",
                "'timedelta64'",
                "'object'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'category'",
                "'interval'",
                "'datetime64[ns, UTC]'",
                "'period[D]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fd9b99f460a442066f655fd285e96e7bc3a2fd5599a6e62433c98e0811c6d2ad",
        "warmup_time": -1
    },
    "dtypes.DtypesInvalid.time_pandas_dtype_invalid": {
        "code": "class DtypesInvalid:\n    def time_pandas_dtype_invalid(self, dtype):\n        try:\n            pandas_dtype(self.data_dict[dtype])\n        except TypeError:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)",
        "min_run_count": 2,
        "name": "dtypes.DtypesInvalid.time_pandas_dtype_invalid",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'scalar-string'",
                "'scalar-int'",
                "'list-string'",
                "'array-string'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7f3ba4b4c7fbd54b7a1820ab3b4dd151e482f73fe3403b9bc5250c8abb048f3b",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_bool_exclude": {
        "code": "class SelectDtypes:\n    def time_select_dtype_bool_exclude(self, dtype):\n        self.df_bool.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_bool_exclude",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a126b236c856d0f38d1511b5cb8add61b60a1345ecaa48c81144e3c0500b91d2",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_bool_include": {
        "code": "class SelectDtypes:\n    def time_select_dtype_bool_include(self, dtype):\n        self.df_bool.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_bool_include",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d7eb6b76e29e30340bd1522aed61c3bffbec125b995524b0f1735c57b1e2abe8",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_float_exclude": {
        "code": "class SelectDtypes:\n    def time_select_dtype_float_exclude(self, dtype):\n        self.df_float.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_float_exclude",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "98778f2a3b7961510ff9312ec0b9a5d48e6878572553ec2beefa443d3fa4fe03",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_float_include": {
        "code": "class SelectDtypes:\n    def time_select_dtype_float_include(self, dtype):\n        self.df_float.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_float_include",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "36a44f47f6cfd5df6c8dc4ae00f64951f2b7479eb2fd0fad09e8171212a77dff",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_int_exclude": {
        "code": "class SelectDtypes:\n    def time_select_dtype_int_exclude(self, dtype):\n        self.df_int.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_int_exclude",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6ac11a0d05d4ccc0fe72a34ad7bd247f211ef4822002464bf01f2b3d55660ea0",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_int_include": {
        "code": "class SelectDtypes:\n    def time_select_dtype_int_include(self, dtype):\n        self.df_int.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_int_include",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2c7425e1f54120813675e43e009cc1cf5daa37d008cec3de897a48522711bc16",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_string_exclude": {
        "code": "class SelectDtypes:\n    def time_select_dtype_string_exclude(self, dtype):\n        self.df_string.select_dtypes(exclude=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_string_exclude",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ae4e0ee446d7fcdf34fe0341cee6f367c65996d84da64f23414569849d34c93c",
        "warmup_time": -1
    },
    "dtypes.SelectDtypes.time_select_dtype_string_include": {
        "code": "class SelectDtypes:\n    def time_select_dtype_string_include(self, dtype):\n        self.df_string.select_dtypes(include=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, dtype):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n    \n        def create_df(data):\n            return DataFrame(data, index=self.index, columns=self.columns)\n    \n        self.df_int = create_df(np.random.randint(low=100, size=(N, K)))\n        self.df_float = create_df(np.random.randn(N, K))\n        self.df_bool = create_df(np.random.choice([True, False], size=(N, K)))\n        self.df_string = create_df(\n            np.random.choice(list(string.ascii_letters), size=(N, K))\n        )",
        "min_run_count": 2,
        "name": "dtypes.SelectDtypes.time_select_dtype_string_include",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "<class 'int'>",
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'UInt8'",
                "'UInt16'",
                "'UInt32'",
                "'UInt64'",
                "'Int8'",
                "'Int16'",
                "'Int32'",
                "'Int64'",
                "<class 'float'>",
                "'float32'",
                "'float64'",
                "<class 'complex'>",
                "'complex64'",
                "'complex128'",
                "'datetime64[ns]'",
                "'M8[ns]'",
                "'timedelta64[ns]'",
                "'m8[ns]'",
                "<class 'bool'>",
                "'bool'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "39dae1d8edd77b15d13397cb4c4f637c5aeac236b2f599aa7f42bdb9e57c8cd7",
        "warmup_time": -1
    },
    "eval.Eval.time_add": {
        "code": "class Eval:\n    def time_add(self, engine, threads):\n        pd.eval(\"self.df + self.df2 + self.df3 + self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)",
        "min_run_count": 2,
        "name": "eval.Eval.time_add",
        "number": 0,
        "param_names": [
            "engine",
            "threads"
        ],
        "params": [
            [
                "'numexpr'",
                "'python'"
            ],
            [
                "1",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3b50f88f4cebf64200f50ab348ee13f8589e7dfb5962f7176004d30730f99112",
        "warmup_time": -1
    },
    "eval.Eval.time_and": {
        "code": "class Eval:\n    def time_and(self, engine, threads):\n        pd.eval(\n            \"(self.df > 0) & (self.df2 > 0) & (self.df3 > 0) & (self.df4 > 0)\",\n            engine=engine,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)",
        "min_run_count": 2,
        "name": "eval.Eval.time_and",
        "number": 0,
        "param_names": [
            "engine",
            "threads"
        ],
        "params": [
            [
                "'numexpr'",
                "'python'"
            ],
            [
                "1",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e48d6e775f144cea8cd29b74723eb86f939c566bd1c688845dd864d16d60de1b",
        "warmup_time": -1
    },
    "eval.Eval.time_chained_cmp": {
        "code": "class Eval:\n    def time_chained_cmp(self, engine, threads):\n        pd.eval(\"self.df < self.df2 < self.df3 < self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)",
        "min_run_count": 2,
        "name": "eval.Eval.time_chained_cmp",
        "number": 0,
        "param_names": [
            "engine",
            "threads"
        ],
        "params": [
            [
                "'numexpr'",
                "'python'"
            ],
            [
                "1",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0fe4b18c6cfabf06e6e4cac4c651276743a49df6a947913f8cabba517ba91786",
        "warmup_time": -1
    },
    "eval.Eval.time_mult": {
        "code": "class Eval:\n    def time_mult(self, engine, threads):\n        pd.eval(\"self.df * self.df2 * self.df3 * self.df4\", engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Eval:\n    def setup(self, engine, threads):\n        self.df = pd.DataFrame(np.random.randn(20000, 100))\n        self.df2 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df3 = pd.DataFrame(np.random.randn(20000, 100))\n        self.df4 = pd.DataFrame(np.random.randn(20000, 100))\n    \n        if threads == 1:\n            expr.set_numexpr_threads(1)",
        "min_run_count": 2,
        "name": "eval.Eval.time_mult",
        "number": 0,
        "param_names": [
            "engine",
            "threads"
        ],
        "params": [
            [
                "'numexpr'",
                "'python'"
            ],
            [
                "1",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a2085f987e1ce9ac0c43a0fe2cba5ad5be060d477671017c4323e892a23899a2",
        "warmup_time": -1
    },
    "eval.Query.time_query_datetime_column": {
        "code": "class Query:\n    def time_query_datetime_column(self):\n        self.df.query(\"dates < @self.ts\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"T\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()",
        "min_run_count": 2,
        "name": "eval.Query.time_query_datetime_column",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d9e47f266f4172f936ad6ef4ab54f1534c1c3b981a7c77adbc79c1130ddcf4fa",
        "warmup_time": -1
    },
    "eval.Query.time_query_datetime_index": {
        "code": "class Query:\n    def time_query_datetime_index(self):\n        self.df.query(\"index < @self.ts\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"T\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()",
        "min_run_count": 2,
        "name": "eval.Query.time_query_datetime_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2902815bba0af650d0eb801bcec41285e9089c0266ed2d7c389a1b337ee7a664",
        "warmup_time": -1
    },
    "eval.Query.time_query_with_boolean_selection": {
        "code": "class Query:\n    def time_query_with_boolean_selection(self):\n        self.df.query(\"(a >= @self.min_val) & (a <= @self.max_val)\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Query:\n    def setup(self):\n        N = 10 ** 6\n        halfway = (N // 2) - 1\n        index = pd.date_range(\"20010101\", periods=N, freq=\"T\")\n        s = pd.Series(index)\n        self.ts = s.iloc[halfway]\n        self.df = pd.DataFrame({\"a\": np.random.randn(N), \"dates\": index}, index=index)\n        data = np.random.randn(N)\n        self.min_val = data.min()\n        self.max_val = data.max()",
        "min_run_count": 2,
        "name": "eval.Query.time_query_with_boolean_selection",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e955ab64fce717cc140d9db5a3ecd9a6ec8380f6bd5075da98db55da360a3995",
        "warmup_time": -1
    },
    "finalize.Finalize.time_finalize_micro": {
        "code": "class Finalize:\n    def time_finalize_micro(self, param):\n        self.obj.__finalize__(self.obj, method=\"__finalize__\")\n\n    def setup(self, param):\n        N = 1000\n        obj = param(dtype=float)\n        for i in range(N):\n            obj.attrs[i] = i\n        self.obj = obj",
        "min_run_count": 2,
        "name": "finalize.Finalize.time_finalize_micro",
        "number": 0,
        "param_names": [
            "series"
        ],
        "params": [
            [
                "<class 'pandas.core.series.Series'>",
                "<class 'pandas.core.frame.DataFrame'>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bd2eab1eb436d45e913e54877c33d964695d4ac5fd0e7fd575f97eb347240a13",
        "warmup_time": -1
    },
    "frame_ctor.FromArrays.time_frame_from_arrays_float": {
        "code": "class FromArrays:\n    def time_frame_from_arrays_float(self):\n        self.df = DataFrame._from_arrays(\n            self.float_arrays,\n            index=self.index,\n            columns=self.columns,\n            verify_integrity=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromArrays:\n    def setup(self):\n        N_rows = 1000\n        N_cols = 1000\n        self.float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]\n        self.sparse_arrays = [\n            pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=\"float64\")\n            for _ in range(N_cols)\n        ]\n        self.int_arrays = [\n            pd.array(np.random.randint(1000, size=N_rows), dtype=\"Int64\")\n            for _ in range(N_cols)\n        ]\n        self.index = pd.Index(range(N_rows))\n        self.columns = pd.Index(range(N_cols))",
        "min_run_count": 2,
        "name": "frame_ctor.FromArrays.time_frame_from_arrays_float",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "325f63d87ecbf9ad645d78740a1aa8328bbd4c29f349c5b13a9117e526ce3866",
        "warmup_time": -1
    },
    "frame_ctor.FromArrays.time_frame_from_arrays_int": {
        "code": "class FromArrays:\n    def time_frame_from_arrays_int(self):\n        self.df = DataFrame._from_arrays(\n            self.int_arrays,\n            index=self.index,\n            columns=self.columns,\n            verify_integrity=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromArrays:\n    def setup(self):\n        N_rows = 1000\n        N_cols = 1000\n        self.float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]\n        self.sparse_arrays = [\n            pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=\"float64\")\n            for _ in range(N_cols)\n        ]\n        self.int_arrays = [\n            pd.array(np.random.randint(1000, size=N_rows), dtype=\"Int64\")\n            for _ in range(N_cols)\n        ]\n        self.index = pd.Index(range(N_rows))\n        self.columns = pd.Index(range(N_cols))",
        "min_run_count": 2,
        "name": "frame_ctor.FromArrays.time_frame_from_arrays_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0ea63af2ba6a6bc03ab7882f007240ed2d5183ed6fa7b85d15c9eb6f3c6f67f7",
        "warmup_time": -1
    },
    "frame_ctor.FromArrays.time_frame_from_arrays_sparse": {
        "code": "class FromArrays:\n    def time_frame_from_arrays_sparse(self):\n        self.df = DataFrame._from_arrays(\n            self.sparse_arrays,\n            index=self.index,\n            columns=self.columns,\n            verify_integrity=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromArrays:\n    def setup(self):\n        N_rows = 1000\n        N_cols = 1000\n        self.float_arrays = [np.random.randn(N_rows) for _ in range(N_cols)]\n        self.sparse_arrays = [\n            pd.arrays.SparseArray(np.random.randint(0, 2, N_rows), dtype=\"float64\")\n            for _ in range(N_cols)\n        ]\n        self.int_arrays = [\n            pd.array(np.random.randint(1000, size=N_rows), dtype=\"Int64\")\n            for _ in range(N_cols)\n        ]\n        self.index = pd.Index(range(N_rows))\n        self.columns = pd.Index(range(N_cols))",
        "min_run_count": 2,
        "name": "frame_ctor.FromArrays.time_frame_from_arrays_sparse",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "225c22c0601994be668586bdb257030c2fd0d83e6dec0712bd820db812484318",
        "warmup_time": -1
    },
    "frame_ctor.FromDicts.time_dict_of_categoricals": {
        "code": "class FromDicts:\n    def time_dict_of_categoricals(self):\n        # dict of arrays that we wont consolidate\n        DataFrame(self.dict_of_categoricals)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we wont consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}",
        "min_run_count": 2,
        "name": "frame_ctor.FromDicts.time_dict_of_categoricals",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d01992efc85d7a9662ce1a58161e208f88df81334987a941b69447164a2f384f",
        "warmup_time": -1
    },
    "frame_ctor.FromDicts.time_list_of_dict": {
        "code": "class FromDicts:\n    def time_list_of_dict(self):\n        DataFrame(self.dict_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we wont consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}",
        "min_run_count": 2,
        "name": "frame_ctor.FromDicts.time_list_of_dict",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "dcaf083da69bfda97c9dd913d9c0df2926d7aa4b3f4c781f0600eaa2d2519e7f",
        "warmup_time": -1
    },
    "frame_ctor.FromDicts.time_nested_dict": {
        "code": "class FromDicts:\n    def time_nested_dict(self):\n        DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we wont consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}",
        "min_run_count": 2,
        "name": "frame_ctor.FromDicts.time_nested_dict",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "add19204a6c10f08c630c4e64d888bc97ec4f42e45059f2abb2f9e42f53ff9df",
        "warmup_time": -1
    },
    "frame_ctor.FromDicts.time_nested_dict_columns": {
        "code": "class FromDicts:\n    def time_nested_dict_columns(self):\n        DataFrame(self.data, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we wont consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}",
        "min_run_count": 2,
        "name": "frame_ctor.FromDicts.time_nested_dict_columns",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5d026b31065518c4a5edf7a7df0533ed14f15a275fcfb9fe3427b1b37bcf28fb",
        "warmup_time": -1
    },
    "frame_ctor.FromDicts.time_nested_dict_index": {
        "code": "class FromDicts:\n    def time_nested_dict_index(self):\n        DataFrame(self.data, index=self.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we wont consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}",
        "min_run_count": 2,
        "name": "frame_ctor.FromDicts.time_nested_dict_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0334c078a76266740420bbe2d4f06d42c8d354ce222c047d8e889c7782f1d0fb",
        "warmup_time": -1
    },
    "frame_ctor.FromDicts.time_nested_dict_index_columns": {
        "code": "class FromDicts:\n    def time_nested_dict_index_columns(self):\n        DataFrame(self.data, index=self.index, columns=self.columns)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we wont consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}",
        "min_run_count": 2,
        "name": "frame_ctor.FromDicts.time_nested_dict_index_columns",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "97b59f84808d3276d1488dee6b4d3f8feba11d796df6eddc2ff63e3338d08f6e",
        "warmup_time": -1
    },
    "frame_ctor.FromDicts.time_nested_dict_int64": {
        "code": "class FromDicts:\n    def time_nested_dict_int64(self):\n        # nested dict, integer indexes, regression described in #621\n        DataFrame(self.data2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDicts:\n    def setup(self):\n        N, K = 5000, 50\n        self.index = tm.makeStringIndex(N)\n        self.columns = tm.makeStringIndex(K)\n        frame = DataFrame(np.random.randn(N, K), index=self.index, columns=self.columns)\n        self.data = frame.to_dict()\n        self.dict_list = frame.to_dict(orient=\"records\")\n        self.data2 = {i: {j: float(j) for j in range(100)} for i in range(2000)}\n    \n        # arrays which we wont consolidate\n        self.dict_of_categoricals = {i: Categorical(np.arange(N)) for i in range(K)}",
        "min_run_count": 2,
        "name": "frame_ctor.FromDicts.time_nested_dict_int64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ee2910c901abc0fb56b4210fd59f762830b4a53fea3918a1807e65d6dbd12112",
        "warmup_time": -1
    },
    "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets": {
        "code": "class FromDictwithTimestamp:\n    def time_dict_with_timestamp_offsets(self, offset):\n        DataFrame(self.d)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromDictwithTimestamp:\n    def setup(self, offset):\n        N = 10 ** 3\n        idx = date_range(Timestamp(\"1/1/1900\"), freq=offset, periods=N)\n        df = DataFrame(np.random.randn(N, 10), index=idx)\n        self.d = df.to_dict()",
        "min_run_count": 2,
        "name": "frame_ctor.FromDictwithTimestamp.time_dict_with_timestamp_offsets",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Nano>",
                "<Hour>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e8f3e3a2e35776ac10a405ccc70f3713ccb878e48f0a431d553945acd8ff713e",
        "warmup_time": -1
    },
    "frame_ctor.FromLists.time_frame_from_lists": {
        "code": "class FromLists:\n    def time_frame_from_lists(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromLists:\n    def setup(self):\n        N = 1000\n        M = 100\n        self.data = [list(range(M)) for i in range(N)]",
        "min_run_count": 2,
        "name": "frame_ctor.FromLists.time_frame_from_lists",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "31e3e4ee69561a2f18687d4fe38117db21e57a6862eba4174561ab425ca7791a",
        "warmup_time": -1
    },
    "frame_ctor.FromNDArray.time_frame_from_ndarray": {
        "code": "class FromNDArray:\n    def time_frame_from_ndarray(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromNDArray:\n    def setup(self):\n        N = 100000\n        self.data = np.random.randn(N)",
        "min_run_count": 2,
        "name": "frame_ctor.FromNDArray.time_frame_from_ndarray",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "42412f191926bccd17fde73d100476018ba3e35421ee311ca6a8d71ef8817e04",
        "warmup_time": -1
    },
    "frame_ctor.FromRange.time_frame_from_range": {
        "code": "class FromRange:\n    def time_frame_from_range(self):\n        self.df = DataFrame(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromRange:\n    def setup(self):\n        N = 1_000_000\n        self.data = range(N)",
        "min_run_count": 2,
        "name": "frame_ctor.FromRange.time_frame_from_range",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8eac1f82a2a2f08e5f9e50dfcf68b362211c18712ce5adbbc12bc772d7d7f156",
        "warmup_time": -1
    },
    "frame_ctor.FromRecords.time_frame_from_records_generator": {
        "code": "class FromRecords:\n    def time_frame_from_records_generator(self, nrows):\n        # issue-6700\n        self.df = DataFrame.from_records(self.gen, nrows=nrows)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromRecords:\n    def setup(self, nrows):\n        N = 100000\n        self.gen = ((x, (x * 20), (x * 100)) for x in range(N))",
        "min_run_count": 2,
        "name": "frame_ctor.FromRecords.time_frame_from_records_generator",
        "number": 1,
        "param_names": [
            "nrows"
        ],
        "params": [
            [
                "None",
                "1000"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "37ac2364875f70b5e255d9371c8fd77229fbb2bb221090c4004cce2af1f510b4",
        "warmup_time": -1
    },
    "frame_ctor.FromSeries.time_mi_series": {
        "code": "class FromSeries:\n    def time_mi_series(self):\n        DataFrame(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromSeries:\n    def setup(self):\n        mi = MultiIndex.from_product([range(100), range(100)])\n        self.s = Series(np.random.randn(10000), index=mi)",
        "min_run_count": 2,
        "name": "frame_ctor.FromSeries.time_mi_series",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "00d66d6b3fb76fd4030a0096f492a7b2040615acbd38000c2317b116f3156fa2",
        "warmup_time": -1
    },
    "frame_methods.Apply.time_apply_axis_1": {
        "code": "class Apply:\n    def time_apply_axis_1(self):\n        self.df.apply(lambda x: x + 1, axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.Apply.time_apply_axis_1",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1abb619fc583026b4a26e477881f01094dbeb880dded525e7cbea1815b8c3c7b",
        "warmup_time": -1
    },
    "frame_methods.Apply.time_apply_lambda_mean": {
        "code": "class Apply:\n    def time_apply_lambda_mean(self):\n        self.df.apply(lambda x: x.mean())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.Apply.time_apply_lambda_mean",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e070e421516f44eee71e66e3fbf7ef0021872ca7eb578f4d11231ed83d441a64",
        "warmup_time": -1
    },
    "frame_methods.Apply.time_apply_np_mean": {
        "code": "class Apply:\n    def time_apply_np_mean(self):\n        self.df.apply(np.mean)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.Apply.time_apply_np_mean",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "12564ba656f7bfdd2a8512fdf104ec41ceeefa22d3d678027728b15df26038a9",
        "warmup_time": -1
    },
    "frame_methods.Apply.time_apply_pass_thru": {
        "code": "class Apply:\n    def time_apply_pass_thru(self):\n        self.df.apply(lambda x: x)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.Apply.time_apply_pass_thru",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7ab6875c70f560ff825c524d780a53db1cad1e43c32e17fe6707f66113694e4c",
        "warmup_time": -1
    },
    "frame_methods.Apply.time_apply_ref_by_name": {
        "code": "class Apply:\n    def time_apply_ref_by_name(self):\n        self.df3.apply(lambda x: x[\"A\"] + x[\"B\"], axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.Apply.time_apply_ref_by_name",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2195dd01ad2f3a289b3754239166687e0753c2a9d5efc0d8be4978c886628236",
        "warmup_time": -1
    },
    "frame_methods.Apply.time_apply_user_func": {
        "code": "class Apply:\n    def time_apply_user_func(self):\n        self.df2.apply(lambda x: np.corrcoef(x, self.s)[(0, 1)])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 100))\n    \n        self.s = Series(np.arange(1028.0))\n        self.df2 = DataFrame({i: self.s for i in range(1028)})\n        self.df3 = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.Apply.time_apply_user_func",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f52de9d070093a84321a5d00e1ff6810b8c4b83e274a1daabf52699c0244b257",
        "warmup_time": -1
    },
    "frame_methods.Count.time_count_level_mixed_dtypes_multi": {
        "code": "class Count:\n    def time_count_level_mixed_dtypes_multi(self, axis):\n        self.df_mixed.count(axis=axis, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"\n    \n        self.df.index = MultiIndex.from_arrays([self.df.index, self.df.index])\n        self.df.columns = MultiIndex.from_arrays([self.df.columns, self.df.columns])\n        self.df_mixed.index = MultiIndex.from_arrays(\n            [self.df_mixed.index, self.df_mixed.index]\n        )\n        self.df_mixed.columns = MultiIndex.from_arrays(\n            [self.df_mixed.columns, self.df_mixed.columns]\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Count.time_count_level_mixed_dtypes_multi",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9d9911c1fb3d4b313481263d00124a2deaef55cedf344ce204e12ed06c2cd7d1",
        "warmup_time": -1
    },
    "frame_methods.Count.time_count_level_multi": {
        "code": "class Count:\n    def time_count_level_multi(self, axis):\n        self.df.count(axis=axis, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Count:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"\n    \n        self.df.index = MultiIndex.from_arrays([self.df.index, self.df.index])\n        self.df.columns = MultiIndex.from_arrays([self.df.columns, self.df.columns])\n        self.df_mixed.index = MultiIndex.from_arrays(\n            [self.df_mixed.index, self.df_mixed.index]\n        )\n        self.df_mixed.columns = MultiIndex.from_arrays(\n            [self.df_mixed.columns, self.df_mixed.columns]\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Count.time_count_level_multi",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "df478bb465a1c9cbd8b5c8251782780d9ea7f96c74761b4ace7e81ca21681d6c",
        "warmup_time": -1
    },
    "frame_methods.Describe.time_dataframe_describe": {
        "code": "class Describe:\n    def time_dataframe_describe(self):\n        self.df.describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(0, 100, 10 ** 6),\n                \"b\": np.random.randint(0, 100, 10 ** 6),\n                \"c\": np.random.randint(0, 100, 10 ** 6),\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Describe.time_dataframe_describe",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b5d4fd616e8a86eaa405dd2acc7760cacb450935cbf23747b4ab0262ecd82d49",
        "warmup_time": -1
    },
    "frame_methods.Describe.time_series_describe": {
        "code": "class Describe:\n    def time_series_describe(self):\n        self.df[\"a\"].describe()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Describe:\n    def setup(self):\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(0, 100, 10 ** 6),\n                \"b\": np.random.randint(0, 100, 10 ** 6),\n                \"c\": np.random.randint(0, 100, 10 ** 6),\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Describe.time_series_describe",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d9b7bdecd3efd07c2a911e177d8a22871cefe742450d3765ab2b85d8e50cae1b",
        "warmup_time": -1
    },
    "frame_methods.Dropna.time_dropna": {
        "code": "class Dropna:\n    def time_dropna(self, how, axis):\n        self.df.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"",
        "min_run_count": 2,
        "name": "frame_methods.Dropna.time_dropna",
        "number": 0,
        "param_names": [
            "how",
            "axis"
        ],
        "params": [
            [
                "'all'",
                "'any'"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0ae9be10365366634edb6b6490363a365b53e5bb30376f429aa6cd8501e99f60",
        "warmup_time": -1
    },
    "frame_methods.Dropna.time_dropna_axis_mixed_dtypes": {
        "code": "class Dropna:\n    def time_dropna_axis_mixed_dtypes(self, how, axis):\n        self.df_mixed.dropna(how=how, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, how, axis):\n        self.df = DataFrame(np.random.randn(10000, 1000))\n        self.df.iloc[50:1000, 20:50] = np.nan\n        self.df.iloc[2000:3000] = np.nan\n        self.df.iloc[:, 60:70] = np.nan\n        self.df_mixed = self.df.copy()\n        self.df_mixed[\"foo\"] = \"bar\"",
        "min_run_count": 2,
        "name": "frame_methods.Dropna.time_dropna_axis_mixed_dtypes",
        "number": 0,
        "param_names": [
            "how",
            "axis"
        ],
        "params": [
            [
                "'all'",
                "'any'"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "211ec5d6bd6568e1ab93ad31c07d7ea015f9540b948fa60ae1ce9846c9d0aaf8",
        "warmup_time": -1
    },
    "frame_methods.Dtypes.time_frame_dtypes": {
        "code": "class Dtypes:\n    def time_frame_dtypes(self):\n        self.df.dtypes\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dtypes:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(1000, 1000))",
        "min_run_count": 2,
        "name": "frame_methods.Dtypes.time_frame_dtypes",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a32eaac056e26349ac255f6354f2a8916b634a88bcf2fd8439b28dc9a21e4ff4",
        "warmup_time": -1
    },
    "frame_methods.Duplicated.time_frame_duplicated": {
        "code": "class Duplicated:\n    def time_frame_duplicated(self):\n        self.df.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"S\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T",
        "min_run_count": 2,
        "name": "frame_methods.Duplicated.time_frame_duplicated",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "99bba024a25c09ca8f6eeb24a51d6e635c2eed9ae4e5b8a21bd29a094f8c2b3e",
        "warmup_time": -1
    },
    "frame_methods.Duplicated.time_frame_duplicated_wide": {
        "code": "class Duplicated:\n    def time_frame_duplicated_wide(self):\n        self.df2.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n = 1 << 20\n        t = date_range(\"2015-01-01\", freq=\"S\", periods=(n // 64))\n        xs = np.random.randn(n // 64).round(2)\n        self.df = DataFrame(\n            {\n                \"a\": np.random.randint(-1 << 8, 1 << 8, n),\n                \"b\": np.random.choice(t, n),\n                \"c\": np.random.choice(xs, n),\n            }\n        )\n        self.df2 = DataFrame(np.random.randn(1000, 100).astype(str)).T",
        "min_run_count": 2,
        "name": "frame_methods.Duplicated.time_frame_duplicated_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "073055405e57cdf74471451142dc08fb4fa449f9e29e1f95a52cb97825d9de14",
        "warmup_time": -1
    },
    "frame_methods.Equals.time_frame_float_equal": {
        "code": "class Equals:\n    def time_frame_float_equal(self):\n        self.float_df.equals(self.float_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Equals.time_frame_float_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bf5c8984995d9583e178e9c1a23c56616d47ec01ef7aaa14c0fc0e698317e2b2",
        "warmup_time": -1
    },
    "frame_methods.Equals.time_frame_float_unequal": {
        "code": "class Equals:\n    def time_frame_float_unequal(self):\n        self.float_df.equals(self.float_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Equals.time_frame_float_unequal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5bf3b03f7bfb5c3a96c74f11937cf83b0724313192875b1d08ad4a85613f162c",
        "warmup_time": -1
    },
    "frame_methods.Equals.time_frame_nonunique_equal": {
        "code": "class Equals:\n    def time_frame_nonunique_equal(self):\n        self.nonunique_cols.equals(self.nonunique_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Equals.time_frame_nonunique_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "67edb29eebf22ccd019c691d929df69bf4f5160e409d854e347a45b3c53c4049",
        "warmup_time": -1
    },
    "frame_methods.Equals.time_frame_nonunique_unequal": {
        "code": "class Equals:\n    def time_frame_nonunique_unequal(self):\n        self.nonunique_cols.equals(self.nonunique_cols_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Equals.time_frame_nonunique_unequal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4d7d2e7a82be1c61c44d43ac685062d2e9a893788995579a29945585a60f7fa4",
        "warmup_time": -1
    },
    "frame_methods.Equals.time_frame_object_equal": {
        "code": "class Equals:\n    def time_frame_object_equal(self):\n        self.object_df.equals(self.object_df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Equals.time_frame_object_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "89ddef11bce1dc72ef38b9f4550e5224f57e582d74143f6814ec8e1a97fefbaf",
        "warmup_time": -1
    },
    "frame_methods.Equals.time_frame_object_unequal": {
        "code": "class Equals:\n    def time_frame_object_unequal(self):\n        self.object_df.equals(self.object_df_nan)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        N = 10 ** 3\n        self.float_df = DataFrame(np.random.randn(N, N))\n        self.float_df_nan = self.float_df.copy()\n        self.float_df_nan.iloc[-1, -1] = np.nan\n    \n        self.object_df = DataFrame(\"foo\", index=range(N), columns=range(N))\n        self.object_df_nan = self.object_df.copy()\n        self.object_df_nan.iloc[-1, -1] = np.nan\n    \n        self.nonunique_cols = self.object_df.copy()\n        self.nonunique_cols.columns = [\"A\"] * len(self.nonunique_cols.columns)\n        self.nonunique_cols_nan = self.nonunique_cols.copy()\n        self.nonunique_cols_nan.iloc[-1, -1] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Equals.time_frame_object_unequal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3f75a6c65633f37af796c08e486818ef71e49cef7273d07c7063ca3dcd91c0ee",
        "warmup_time": -1
    },
    "frame_methods.Fillna.time_frame_fillna": {
        "code": "class Fillna:\n    def time_frame_fillna(self, inplace, method, dtype):\n        self.df.fillna(inplace=inplace, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, inplace, method, dtype):\n        N, M = 10000, 100\n        if dtype in (\"datetime64[ns]\", \"datetime64[ns, tz]\", \"timedelta64[ns]\"):\n            data = {\n                \"datetime64[ns]\": date_range(\"2011-01-01\", freq=\"H\", periods=N),\n                \"datetime64[ns, tz]\": date_range(\n                    \"2011-01-01\", freq=\"H\", periods=N, tz=\"Asia/Tokyo\"\n                ),\n                \"timedelta64[ns]\": timedelta_range(start=\"1 day\", periods=N, freq=\"1D\"),\n            }\n            self.df = DataFrame({f\"col_{i}\": data[dtype] for i in range(M)})\n            self.df[::2] = None\n        else:\n            values = np.random.randn(N, M)\n            values[::2] = np.nan\n            if dtype == \"Int64\":\n                values = values.round()\n            self.df = DataFrame(values, dtype=dtype)",
        "min_run_count": 2,
        "name": "frame_methods.Fillna.time_frame_fillna",
        "number": 0,
        "param_names": [
            "inplace",
            "method",
            "dtype"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'pad'",
                "'bfill'"
            ],
            [
                "'float64'",
                "'float32'",
                "'object'",
                "'Int64'",
                "'Float64'",
                "'datetime64[ns]'",
                "'datetime64[ns, tz]'",
                "'timedelta64[ns]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b79dc8788fab8b156f8613739c351a00636c8a3baa37c1bd67d2b6f3b61a22b7",
        "warmup_time": -1
    },
    "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts": {
        "code": "class GetDtypeCounts:\n    def time_frame_get_dtype_counts(self):\n        with warnings.catch_warnings(record=True):\n            self.df.dtypes.value_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))",
        "min_run_count": 2,
        "name": "frame_methods.GetDtypeCounts.time_frame_get_dtype_counts",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d1e0466afc9058166debec31e7ff688df837d407655e8faf0621969115aee0dd",
        "warmup_time": -1
    },
    "frame_methods.GetDtypeCounts.time_info": {
        "code": "class GetDtypeCounts:\n    def time_info(self):\n        self.df.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDtypeCounts:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10, 10000))",
        "min_run_count": 2,
        "name": "frame_methods.GetDtypeCounts.time_info",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e08ed8e2402f26a376b2c946606fe2bc255214bd7eebee091fe34b3aa4df80db",
        "warmup_time": -1
    },
    "frame_methods.GetNumericData.time_frame_get_numeric_data": {
        "code": "class GetNumericData:\n    def time_frame_get_numeric_data(self):\n        self.df._get_numeric_data()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetNumericData:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 25))\n        self.df[\"foo\"] = \"bar\"\n        self.df[\"bar\"] = \"baz\"\n        self.df = self.df._consolidate()",
        "min_run_count": 2,
        "name": "frame_methods.GetNumericData.time_frame_get_numeric_data",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a6f6ccd03d2a3e6a5b9533bf09fd1f3d852fb8c066e10da43dee6c5b1b958b16",
        "warmup_time": -1
    },
    "frame_methods.Interpolate.time_interpolate": {
        "code": "class Interpolate:\n    def time_interpolate(self, downcast):\n        self.df.interpolate(downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self, downcast):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        arr = np.random.randn(N, 100)\n        # NB: we need to set values in array, not in df.values, otherwise\n        #  the benchmark will be misleading for ArrayManager\n        arr[::2] = np.nan\n    \n        self.df = DataFrame(arr)\n    \n        self.df2 = DataFrame(\n            {\n                \"A\": np.arange(0, N),\n                \"B\": np.random.randint(0, 100, N),\n                \"C\": np.random.randn(N),\n                \"D\": np.random.randn(N),\n            }\n        )\n        self.df2.loc[1::5, \"A\"] = np.nan\n        self.df2.loc[1::5, \"C\"] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Interpolate.time_interpolate",
        "number": 0,
        "param_names": [
            "downcast"
        ],
        "params": [
            [
                "None",
                "'infer'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "772e1716ebd0b46c5a1414657afc3917f5a8ea0f258df3ea3261ce0eaf02ee55",
        "warmup_time": -1
    },
    "frame_methods.Interpolate.time_interpolate_some_good": {
        "code": "class Interpolate:\n    def time_interpolate_some_good(self, downcast):\n        self.df2.interpolate(downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Interpolate:\n    def setup(self, downcast):\n        N = 10000\n        # this is the worst case, where every column has NaNs.\n        arr = np.random.randn(N, 100)\n        # NB: we need to set values in array, not in df.values, otherwise\n        #  the benchmark will be misleading for ArrayManager\n        arr[::2] = np.nan\n    \n        self.df = DataFrame(arr)\n    \n        self.df2 = DataFrame(\n            {\n                \"A\": np.arange(0, N),\n                \"B\": np.random.randint(0, 100, N),\n                \"C\": np.random.randn(N),\n                \"D\": np.random.randn(N),\n            }\n        )\n        self.df2.loc[1::5, \"A\"] = np.nan\n        self.df2.loc[1::5, \"C\"] = np.nan",
        "min_run_count": 2,
        "name": "frame_methods.Interpolate.time_interpolate_some_good",
        "number": 0,
        "param_names": [
            "downcast"
        ],
        "params": [
            [
                "None",
                "'infer'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "815fbe5f668a27ab8708fc47157cc8edac28bf78e7cfc2776ef6a1c5c73832ae",
        "warmup_time": -1
    },
    "frame_methods.Isnull.time_isnull": {
        "code": "class Isnull:\n    def time_isnull(self):\n        isnull(self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10 ** 3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)",
        "min_run_count": 2,
        "name": "frame_methods.Isnull.time_isnull",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8849bad1cdad334e8dc1ece4ad9a6ce890925da5bde19de86785862c8631145d",
        "warmup_time": -1
    },
    "frame_methods.Isnull.time_isnull_floats_no_null": {
        "code": "class Isnull:\n    def time_isnull_floats_no_null(self):\n        isnull(self.df_no_null)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10 ** 3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)",
        "min_run_count": 2,
        "name": "frame_methods.Isnull.time_isnull_floats_no_null",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fbed372d74d5faea67ab9e3239e848150d6937a6da303f5dc7cfbca6d67b43f4",
        "warmup_time": -1
    },
    "frame_methods.Isnull.time_isnull_obj": {
        "code": "class Isnull:\n    def time_isnull_obj(self):\n        isnull(self.df_obj)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10 ** 3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)",
        "min_run_count": 2,
        "name": "frame_methods.Isnull.time_isnull_obj",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "22948e25eea94c88f7aea901eb670e0469b89ce6c6089788d1c4c5cbb4bae549",
        "warmup_time": -1
    },
    "frame_methods.Isnull.time_isnull_strngs": {
        "code": "class Isnull:\n    def time_isnull_strngs(self):\n        isnull(self.df_strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Isnull:\n    def setup(self):\n        N = 10 ** 3\n        self.df_no_null = DataFrame(np.random.randn(N, N))\n    \n        sample = np.array([np.nan, 1.0])\n        data = np.random.choice(sample, (N, N))\n        self.df = DataFrame(data)\n    \n        sample = np.array(list(string.ascii_letters + string.whitespace))\n        data = np.random.choice(sample, (N, N))\n        self.df_strings = DataFrame(data)\n    \n        sample = np.array(\n            [\n                NaT,\n                np.nan,\n                None,\n                np.datetime64(\"NaT\"),\n                np.timedelta64(\"NaT\"),\n                0,\n                1,\n                2.0,\n                \"\",\n                \"abcd\",\n            ]\n        )\n        data = np.random.choice(sample, (N, N))\n        self.df_obj = DataFrame(data)",
        "min_run_count": 2,
        "name": "frame_methods.Isnull.time_isnull_strngs",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2cc76e403db71d852978648782b7f8f924a62199bbc6d12a9f1576da0ae42ae1",
        "warmup_time": -1
    },
    "frame_methods.Iteration.mem_itertuples_raw_start": {
        "code": "class Iteration:\n    def mem_itertuples_raw_start(self):\n        return self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.mem_itertuples_raw_start",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "memory",
        "unit": "bytes",
        "version": "bde9d2373c7953bbf4a4d7fe73bd19e60eb7c15b50f8978637098fec3d837ed1"
    },
    "frame_methods.Iteration.mem_itertuples_raw_to_list": {
        "code": "class Iteration:\n    def mem_itertuples_raw_to_list(self):\n        return list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.mem_itertuples_raw_to_list",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "memory",
        "unit": "bytes",
        "version": "14959ad0e6b16ce24b2986d509e67eeccc6ad44f09ce481e44781dd903d37a04"
    },
    "frame_methods.Iteration.mem_itertuples_read_first": {
        "code": "class Iteration:\n    def mem_itertuples_read_first(self):\n        return next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.mem_itertuples_read_first",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "memory",
        "unit": "bytes",
        "version": "fa14a67958421e77045287ab0dfe58c2d22462f3b77070715024772201c64770"
    },
    "frame_methods.Iteration.mem_itertuples_start": {
        "code": "class Iteration:\n    def mem_itertuples_start(self):\n        return self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.mem_itertuples_start",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "memory",
        "unit": "bytes",
        "version": "cf2518d7a524f33405fe8b9f5e7dd8af1e52820e56cf14f92d6ff79ca33bbca9"
    },
    "frame_methods.Iteration.mem_itertuples_to_list": {
        "code": "class Iteration:\n    def mem_itertuples_to_list(self):\n        return list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.mem_itertuples_to_list",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "memory",
        "unit": "bytes",
        "version": "fc2c86822b2a65a5dd8df96b9003fe69eb2c82b3b8543140d1744b7d7fbc099f"
    },
    "frame_methods.Iteration.peakmem_itertuples": {
        "code": "class Iteration:\n    def peakmem_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.peakmem_itertuples",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "f8c4bb246773a09f62d6963200ac6dd08accf63f8701099b39f34450db0baa76"
    },
    "frame_methods.Iteration.peakmem_itertuples_raw": {
        "code": "class Iteration:\n    def peakmem_itertuples_raw(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.peakmem_itertuples_raw",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "51be24a7edeb484ceaa5e24c608c890c59c56b210c778564af1c40cde9c6582b"
    },
    "frame_methods.Iteration.peakmem_itertuples_raw_read_first": {
        "code": "class Iteration:\n    def peakmem_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.peakmem_itertuples_raw_read_first",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "3bcec70cbf3d3ea880425ba6e3a7a604504d19716e82dbbb4a70fb8351eda7f3"
    },
    "frame_methods.Iteration.peakmem_itertuples_raw_start": {
        "code": "class Iteration:\n    def peakmem_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.peakmem_itertuples_raw_start",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "8d85d7a2d0ceb456c1eae16a3f138a7ea0a13edf1bd76492d262b00cc32013cf"
    },
    "frame_methods.Iteration.peakmem_itertuples_raw_to_list": {
        "code": "class Iteration:\n    def peakmem_itertuples_raw_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.peakmem_itertuples_raw_to_list",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "702541458ae59bd0fa6a7654edf93ba6de30013419a4591073b4077ffaaa9ec1"
    },
    "frame_methods.Iteration.peakmem_itertuples_start": {
        "code": "class Iteration:\n    def peakmem_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.peakmem_itertuples_start",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "2e9870eb171bfbc3718dac5dc495cf2a5fc860a65acca33db4110a97d819f905"
    },
    "frame_methods.Iteration.peakmem_itertuples_to_list": {
        "code": "class Iteration:\n    def peakmem_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "name": "frame_methods.Iteration.peakmem_itertuples_to_list",
        "param_names": [],
        "params": [],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "3b1c891c821d3baa961e2ac7bbba794eaaa5fdde90643e15273782165349694d"
    },
    "frame_methods.Iteration.time_items": {
        "code": "class Iteration:\n    def time_items(self):\n        # (monitor no-copying behaviour)\n        if hasattr(self.df, \"_item_cache\"):\n            self.df._item_cache.clear()\n        for name, col in self.df.items():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_items",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "61a76eb1cc78a07500c444849ab0ff0f8e5db1091090d34b6a1cdaee55952a78",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_items_cached": {
        "code": "class Iteration:\n    def time_items_cached(self):\n        for name, col in self.df.items():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_items_cached",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "c306e5ac3eb89a326c9bc3a472c6040fc7e21e71d498483a3aa5263ed417b87a",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_iteritems_indexing": {
        "code": "class Iteration:\n    def time_iteritems_indexing(self):\n        for col in self.df3:\n            self.df3[col]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_iteritems_indexing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "32a0d9e470a05a943e062be7e53224b0a8d3c4753f3ea203564451fe73e00be6",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_iterrows": {
        "code": "class Iteration:\n    def time_iterrows(self):\n        for row in self.df.iterrows():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_iterrows",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "1872356d18d8d38838ccef4e38aea113cb033fcd589da146758d76d6aba725c1",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples": {
        "code": "class Iteration:\n    def time_itertuples(self):\n        for row in self.df4.itertuples():\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "bc1f6d845378bd6d1c53d1ef7b8e0f725f9a6ca74b0b1bfe928c5a21e6829fd9",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples_raw_read_first": {
        "code": "class Iteration:\n    def time_itertuples_raw_read_first(self):\n        next(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples_raw_read_first",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "78a787f4a6eb7dd27f3ac2434d4d26567eca763890c14bd2b86b54d88ade5db4",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples_raw_start": {
        "code": "class Iteration:\n    def time_itertuples_raw_start(self):\n        self.df4.itertuples(index=False, name=None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples_raw_start",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "e34eb99379456d0e4ff1da68c34d436747af447b5d80f49bca78a9095da18426",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples_raw_tuples": {
        "code": "class Iteration:\n    def time_itertuples_raw_tuples(self):\n        for row in self.df4.itertuples(index=False, name=None):\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples_raw_tuples",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "ef2cf1b3767b908e25cbd488502ea2b91b43cfcd491b12389acfbea37699cc95",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples_raw_tuples_to_list": {
        "code": "class Iteration:\n    def time_itertuples_raw_tuples_to_list(self):\n        list(self.df4.itertuples(index=False, name=None))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples_raw_tuples_to_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "f372d26bf89b90dd1e24ac2a01493a7435fdf11710e9e65324adc1d350725816",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples_read_first": {
        "code": "class Iteration:\n    def time_itertuples_read_first(self):\n        next(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples_read_first",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "9ed674f5820c7707be515d2f9a891d84a09efcf8f785fc428335dac028a682a6",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples_start": {
        "code": "class Iteration:\n    def time_itertuples_start(self):\n        self.df4.itertuples()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples_start",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "beae2a24376ed50a9a214101ac7828899ca3db4436d6f61cc38ac099202d2dfd",
        "warmup_time": -1
    },
    "frame_methods.Iteration.time_itertuples_to_list": {
        "code": "class Iteration:\n    def time_itertuples_to_list(self):\n        list(self.df4.itertuples())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self):\n        N = 1000\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\n        self.df3 = DataFrame(\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\n        )\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))",
        "min_run_count": 2,
        "name": "frame_methods.Iteration.time_itertuples_to_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "a5fc1a49acb90aa9c123ba866a88ff4f8c508c4cfef59faa117d0da770f63698",
        "warmup_time": -1
    },
    "frame_methods.Lookup.time_frame_fancy_lookup": {
        "code": "class Lookup:\n    def time_frame_fancy_lookup(self):\n        self.df.lookup(self.row_labels, self.col_labels)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 8), columns=list(\"abcdefgh\"))\n        self.df[\"foo\"] = \"bar\"\n        self.row_labels = list(self.df.index[::10])[:900]\n        self.col_labels = list(self.df.columns) * 100\n        self.row_labels_all = np.array(\n            list(self.df.index) * len(self.df.columns), dtype=\"object\"\n        )\n        self.col_labels_all = np.array(\n            list(self.df.columns) * len(self.df.index), dtype=\"object\"\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Lookup.time_frame_fancy_lookup",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "24015dfa58d8da16cc59ad4ca2d95f22b26fbb83ae4de05aef55a783fe8eefd2",
        "warmup_time": -1
    },
    "frame_methods.Lookup.time_frame_fancy_lookup_all": {
        "code": "class Lookup:\n    def time_frame_fancy_lookup_all(self):\n        self.df.lookup(self.row_labels_all, self.col_labels_all)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 8), columns=list(\"abcdefgh\"))\n        self.df[\"foo\"] = \"bar\"\n        self.row_labels = list(self.df.index[::10])[:900]\n        self.col_labels = list(self.df.columns) * 100\n        self.row_labels_all = np.array(\n            list(self.df.index) * len(self.df.columns), dtype=\"object\"\n        )\n        self.col_labels_all = np.array(\n            list(self.df.columns) * len(self.df.index), dtype=\"object\"\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Lookup.time_frame_fancy_lookup_all",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "37b3ee0abe9cfe0f03ac1057b6941ac808a194f793bddf34fbc59bbf59d4b5f3",
        "warmup_time": -1
    },
    "frame_methods.MaskBool.time_frame_mask_bools": {
        "code": "class MaskBool:\n    def time_frame_mask_bools(self):\n        self.bools.mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)",
        "min_run_count": 2,
        "name": "frame_methods.MaskBool.time_frame_mask_bools",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "75d26deea512c14af4e7569f5dc1e43324ed79283c789db2fb4999d0d7853441",
        "warmup_time": -1
    },
    "frame_methods.MaskBool.time_frame_mask_floats": {
        "code": "class MaskBool:\n    def time_frame_mask_floats(self):\n        self.bools.astype(float).mask(self.mask)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaskBool:\n    def setup(self):\n        data = np.random.randn(1000, 500)\n        df = DataFrame(data)\n        df = df.where(df > 0)\n        self.bools = df > 0\n        self.mask = isnull(df)",
        "min_run_count": 2,
        "name": "frame_methods.MaskBool.time_frame_mask_floats",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "77725b9d5309bb967bcd8a8abd4d5a8168f1759ac192d051fe68d191166e9b7e",
        "warmup_time": -1
    },
    "frame_methods.MemoryUsage.time_memory_usage": {
        "code": "class MemoryUsage:\n    def time_memory_usage(self):\n        self.df.memory_usage(deep=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MemoryUsage:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100000, 2), columns=list(\"AB\"))\n        self.df2 = self.df.copy()\n        self.df2[\"A\"] = self.df2[\"A\"].astype(\"object\")",
        "min_run_count": 2,
        "name": "frame_methods.MemoryUsage.time_memory_usage",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "abaa03ed61b94b958c09bee89d52d1b87d72796639ec7588559d5b158f8dede9",
        "warmup_time": -1
    },
    "frame_methods.MemoryUsage.time_memory_usage_object_dtype": {
        "code": "class MemoryUsage:\n    def time_memory_usage_object_dtype(self):\n        self.df2.memory_usage(deep=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MemoryUsage:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100000, 2), columns=list(\"AB\"))\n        self.df2 = self.df.copy()\n        self.df2[\"A\"] = self.df2[\"A\"].astype(\"object\")",
        "min_run_count": 2,
        "name": "frame_methods.MemoryUsage.time_memory_usage_object_dtype",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f25a399ce1ee970c20943c1c0c1d8359a80848bf10be1b7912eae51ee454231a",
        "warmup_time": -1
    },
    "frame_methods.NSort.time_nlargest_one_column": {
        "code": "class NSort:\n    def time_nlargest_one_column(self, keep):\n        self.df.nlargest(100, \"A\", keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.NSort.time_nlargest_one_column",
        "number": 0,
        "param_names": [
            "keep"
        ],
        "params": [
            [
                "'first'",
                "'last'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ae8ee646412a2720d7755ec64e5f1a787ddb6242469e44c8e3f548a93c55eb32",
        "warmup_time": -1
    },
    "frame_methods.NSort.time_nlargest_two_columns": {
        "code": "class NSort:\n    def time_nlargest_two_columns(self, keep):\n        self.df.nlargest(100, [\"A\", \"B\"], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.NSort.time_nlargest_two_columns",
        "number": 0,
        "param_names": [
            "keep"
        ],
        "params": [
            [
                "'first'",
                "'last'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fb06c1f8251bd2a6af6ab02b7dbf651402818b3898c88c5f634d4999eb180730",
        "warmup_time": -1
    },
    "frame_methods.NSort.time_nsmallest_one_column": {
        "code": "class NSort:\n    def time_nsmallest_one_column(self, keep):\n        self.df.nsmallest(100, \"A\", keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.NSort.time_nsmallest_one_column",
        "number": 0,
        "param_names": [
            "keep"
        ],
        "params": [
            [
                "'first'",
                "'last'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "602770ac5530f5b88477e395308b8146dcf5adb79187c8d34b0201ba44680a2e",
        "warmup_time": -1
    },
    "frame_methods.NSort.time_nsmallest_two_columns": {
        "code": "class NSort:\n    def time_nsmallest_two_columns(self, keep):\n        self.df.nsmallest(100, [\"A\", \"B\"], keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.df = DataFrame(np.random.randn(100000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.NSort.time_nsmallest_two_columns",
        "number": 0,
        "param_names": [
            "keep"
        ],
        "params": [
            [
                "'first'",
                "'last'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "27757c983389573bb278541de8a55e9ac92f47fc4c94a64054207953192b17d7",
        "warmup_time": -1
    },
    "frame_methods.Nunique.time_frame_nunique": {
        "code": "class Nunique:\n    def time_frame_nunique(self):\n        self.df.nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nunique:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 1000))",
        "min_run_count": 2,
        "name": "frame_methods.Nunique.time_frame_nunique",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7b4f1bb3132faa41cd11750a8882705594d2e2437af6d28e1c6648950e7d0c46",
        "warmup_time": -1
    },
    "frame_methods.Quantile.time_frame_quantile": {
        "code": "class Quantile:\n    def time_frame_quantile(self, axis):\n        self.df.quantile([0.1, 0.5], axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.randn(1000, 3), columns=list(\"ABC\"))",
        "min_run_count": 2,
        "name": "frame_methods.Quantile.time_frame_quantile",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e46972758e099994281698947a2e05eda1f226d307e25f58fb72796cedd8908f",
        "warmup_time": -1
    },
    "frame_methods.Rank.time_rank": {
        "code": "class Rank:\n    def time_rank(self, dtype):\n        self.df.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, dtype):\n        self.df = DataFrame(\n            np.random.randn(10000, 10).astype(dtype), columns=range(10), dtype=dtype\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Rank.time_rank",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int'",
                "'uint'",
                "'float'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4512f531d4398c0997ffb9c0b076476cab3bef280e5662032d20d3b76f2e26cb",
        "warmup_time": -1
    },
    "frame_methods.Reindex.time_reindex_axis0": {
        "code": "class Reindex:\n    def time_reindex_axis0(self):\n        self.df.reindex(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Reindex.time_reindex_axis0",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1e7b04774ff7600063f57e7274b7b3302b2fdf38e5917f0922644646628ccdad",
        "warmup_time": -1
    },
    "frame_methods.Reindex.time_reindex_axis1": {
        "code": "class Reindex:\n    def time_reindex_axis1(self):\n        self.df.reindex(columns=self.idx_cols)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Reindex.time_reindex_axis1",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9eccf9c79bba8a79b990e728bcd919de3abb9d40bc4a6ac6f9ae38ba40627621",
        "warmup_time": -1
    },
    "frame_methods.Reindex.time_reindex_axis1_missing": {
        "code": "class Reindex:\n    def time_reindex_axis1_missing(self):\n        self.df.reindex(columns=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Reindex.time_reindex_axis1_missing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0507ad48561e2e2fb6c7ba0ac71b0854824523a084b43b468eb22e43cb797590",
        "warmup_time": -1
    },
    "frame_methods.Reindex.time_reindex_both_axes": {
        "code": "class Reindex:\n    def time_reindex_both_axes(self):\n        self.df.reindex(index=self.idx, columns=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Reindex.time_reindex_both_axes",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f4905d69527caa533868b2711ba6256d69da2f2dc388f3f45659da39158d7c9b",
        "warmup_time": -1
    },
    "frame_methods.Reindex.time_reindex_upcast": {
        "code": "class Reindex:\n    def time_reindex_upcast(self):\n        self.df2.reindex(np.random.permutation(range(1200)))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.idx_cols = np.random.randint(0, N, N)\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Reindex.time_reindex_upcast",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cd3ae804e9999f08c57e082b3916ab1b1d7dad91f9cc01875029e08a9a9a81bb",
        "warmup_time": -1
    },
    "frame_methods.Rename.time_dict_rename_both_axes": {
        "code": "class Rename:\n    def time_dict_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Rename.time_dict_rename_both_axes",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c2e5aebfe4bd8a8e90f03245a447e660ab1470bfb1f2089153ac6b270130b25d",
        "warmup_time": -1
    },
    "frame_methods.Rename.time_rename_axis0": {
        "code": "class Rename:\n    def time_rename_axis0(self):\n        self.df.rename(self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Rename.time_rename_axis0",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a955f648cd16af7cf284d2a39cbdc4c415df601043c68bf65a2628c38ef8c2a8",
        "warmup_time": -1
    },
    "frame_methods.Rename.time_rename_axis1": {
        "code": "class Rename:\n    def time_rename_axis1(self):\n        self.df.rename(columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Rename.time_rename_axis1",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4ec58041af72a32195e098150aec4693af9ea13e6a729efd5f5a2e02079c86ff",
        "warmup_time": -1
    },
    "frame_methods.Rename.time_rename_both_axes": {
        "code": "class Rename:\n    def time_rename_both_axes(self):\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Rename.time_rename_both_axes",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fd91709baf89094f8cb67343243b7228ffacc81dc93eec5e539de1c9af0f3f6d",
        "warmup_time": -1
    },
    "frame_methods.Rename.time_rename_single": {
        "code": "class Rename:\n    def time_rename_single(self):\n        self.df.rename({0: 0})\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rename:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame(np.random.randn(N * 10, N))\n        self.idx = np.arange(4 * N, 7 * N)\n        self.dict_idx = {k: k for k in self.idx}\n        self.df2 = DataFrame(\n            {\n                c: {\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\n                    1: np.random.randint(0, N, N).astype(np.int16),\n                    2: np.random.randint(0, N, N).astype(np.int32),\n                    3: np.random.randint(0, N, N).astype(np.int64),\n                }[np.random.randint(0, 4)]\n                for c in range(N)\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.Rename.time_rename_single",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3d5e29b5a9f45322b95b5f99093cbba3ff8f6e57a2d324d6de4112cbbcc62443",
        "warmup_time": -1
    },
    "frame_methods.Repr.time_frame_repr_wide": {
        "code": "class Repr:\n    def time_frame_repr_wide(self):\n        repr(self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))",
        "min_run_count": 2,
        "name": "frame_methods.Repr.time_frame_repr_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b7c902cd0a2f02eebcb938f83eb0bc567c8bf80146ce7c09a335b559e8715a33",
        "warmup_time": -1
    },
    "frame_methods.Repr.time_html_repr_trunc_mi": {
        "code": "class Repr:\n    def time_html_repr_trunc_mi(self):\n        self.df3._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))",
        "min_run_count": 2,
        "name": "frame_methods.Repr.time_html_repr_trunc_mi",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c5988920e0b3d00d1ec74379b4576a53ad6b17e4c9b71625316958d163ed4164",
        "warmup_time": -1
    },
    "frame_methods.Repr.time_html_repr_trunc_si": {
        "code": "class Repr:\n    def time_html_repr_trunc_si(self):\n        self.df4._repr_html_()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))",
        "min_run_count": 2,
        "name": "frame_methods.Repr.time_html_repr_trunc_si",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8fd8968223faa897090a27941e475b84b23f11c40bb5c7541e6f71c9fb9376a3",
        "warmup_time": -1
    },
    "frame_methods.Repr.time_repr_tall": {
        "code": "class Repr:\n    def time_repr_tall(self):\n        repr(self.df_tall)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Repr:\n    def setup(self):\n        nrows = 10000\n        data = np.random.randn(nrows, 10)\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\n        idx = MultiIndex.from_arrays(arrays)\n        self.df3 = DataFrame(data, index=idx)\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\n        self.df_wide = DataFrame(np.random.randn(10, nrows))",
        "min_run_count": 2,
        "name": "frame_methods.Repr.time_repr_tall",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "57c3fcd319895e084cdc6f5e24084880d4817e72dd3fe35856b00b69e7ea1742",
        "warmup_time": -1
    },
    "frame_methods.SelectDtypes.time_select_dtypes": {
        "code": "class SelectDtypes:\n    def time_select_dtypes(self, n):\n        self.df.select_dtypes(include=\"int\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SelectDtypes:\n    def setup(self, n):\n        self.df = DataFrame(np.random.randn(10, n))",
        "min_run_count": 2,
        "name": "frame_methods.SelectDtypes.time_select_dtypes",
        "number": 0,
        "param_names": [
            "n"
        ],
        "params": [
            [
                "100",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "02ded66d44eabd4c65e6c9197ccec13ef51d6cf6c9c9eac84da72d793d3b0fee",
        "warmup_time": -1
    },
    "frame_methods.SeriesNuniqueWithNan.time_series_nunique_nan": {
        "code": "class SeriesNuniqueWithNan:\n    def time_series_nunique_nan(self):\n        self.ser.nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesNuniqueWithNan:\n    def setup(self):\n        self.ser = Series(100000 * (100 * [np.nan] + list(range(100)))).astype(float)",
        "min_run_count": 2,
        "name": "frame_methods.SeriesNuniqueWithNan.time_series_nunique_nan",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c540925505268ef2727fb50f58699d43a4df65305e01e31b05291f8568d4e742",
        "warmup_time": -1
    },
    "frame_methods.Shift.time_shift": {
        "code": "class Shift:\n    def time_shift(self, axis):\n        self.df.shift(1, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self, axis):\n        self.df = DataFrame(np.random.rand(10000, 500))",
        "min_run_count": 2,
        "name": "frame_methods.Shift.time_shift",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "09d28e1e7b36fe4dfa6ed22317da40bcde0164c120b61d4efff8f61b02c768af",
        "warmup_time": -1
    },
    "frame_methods.SortIndexByColumns.time_frame_sort_values_by_columns": {
        "code": "class SortIndexByColumns:\n    def time_frame_sort_values_by_columns(self):\n        self.df.sort_values(by=[\"key1\", \"key2\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndexByColumns:\n    def setup(self):\n        N = 10000\n        K = 10\n        self.df = DataFrame(\n            {\n                \"key1\": tm.makeStringIndex(N).values.repeat(K),\n                \"key2\": tm.makeStringIndex(N).values.repeat(K),\n                \"value\": np.random.randn(N * K),\n            }\n        )",
        "min_run_count": 2,
        "name": "frame_methods.SortIndexByColumns.time_frame_sort_values_by_columns",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "318bad8e24c87625270a0510253512ec3ad9ae054ffad580e2d5bba6ce1ca19d",
        "warmup_time": -1
    },
    "frame_methods.SortValues.time_frame_sort_values": {
        "code": "class SortValues:\n    def time_frame_sort_values(self, ascending):\n        self.df.sort_values(by=\"A\", ascending=ascending)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortValues:\n    def setup(self, ascending):\n        self.df = DataFrame(np.random.randn(1000000, 2), columns=list(\"AB\"))",
        "min_run_count": 2,
        "name": "frame_methods.SortValues.time_frame_sort_values",
        "number": 0,
        "param_names": [
            "ascending"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bf9c8ff877f2cd95431692cfe963e37b3de4634176be673d3de0b663177d7ad3",
        "warmup_time": -1
    },
    "frame_methods.ToDict.time_to_dict_datetimelike": {
        "code": "class ToDict:\n    def time_to_dict_datetimelike(self, orient):\n        self.datetimelike_df.to_dict(orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDict:\n    def setup(self, orient):\n        data = np.random.randint(0, 1000, size=(10000, 4))\n        self.int_df = DataFrame(data)\n        self.datetimelike_df = self.int_df.astype(\"timedelta64[ns]\")",
        "min_run_count": 2,
        "name": "frame_methods.ToDict.time_to_dict_datetimelike",
        "number": 0,
        "param_names": [
            "orient"
        ],
        "params": [
            [
                "'dict'",
                "'list'",
                "'series'",
                "'split'",
                "'records'",
                "'index'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "939f612766529ae46a0b196a3dc13061331265310113f5a5c18d503fd623eb63",
        "warmup_time": -1
    },
    "frame_methods.ToDict.time_to_dict_ints": {
        "code": "class ToDict:\n    def time_to_dict_ints(self, orient):\n        self.int_df.to_dict(orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDict:\n    def setup(self, orient):\n        data = np.random.randint(0, 1000, size=(10000, 4))\n        self.int_df = DataFrame(data)\n        self.datetimelike_df = self.int_df.astype(\"timedelta64[ns]\")",
        "min_run_count": 2,
        "name": "frame_methods.ToDict.time_to_dict_ints",
        "number": 0,
        "param_names": [
            "orient"
        ],
        "params": [
            [
                "'dict'",
                "'list'",
                "'series'",
                "'split'",
                "'records'",
                "'index'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8ca05db38583b86c56e9781a0ba1f399533c5e196accee6737c23ade9750f5c9",
        "warmup_time": -1
    },
    "frame_methods.ToHTML.time_to_html_mixed": {
        "code": "class ToHTML:\n    def time_to_html_mixed(self):\n        self.df2.to_html()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToHTML:\n    def setup(self):\n        nrows = 500\n        self.df2 = DataFrame(np.random.randn(nrows, 10))\n        self.df2[0] = period_range(\"2000\", periods=nrows)\n        self.df2[1] = range(nrows)",
        "min_run_count": 2,
        "name": "frame_methods.ToHTML.time_to_html_mixed",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a63bfb2f9452ef12121452e5a13a47f1ddf16d3a2ecc961f1d143598ae48a31a",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_to_numpy_mixed_tall": {
        "code": "class ToNumpy:\n    def time_to_numpy_mixed_tall(self):\n        self.df_mixed_tall.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_to_numpy_mixed_tall",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5609d5ea9c8d63719954d185af31995af502969500f52a283b95dee96b206b21",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_to_numpy_mixed_wide": {
        "code": "class ToNumpy:\n    def time_to_numpy_mixed_wide(self):\n        self.df_mixed_wide.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_to_numpy_mixed_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b8cf4cdbf480bfa101b1e9bbf6df8e6a9516540d5888f9acf40c29f0b39c4178",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_to_numpy_tall": {
        "code": "class ToNumpy:\n    def time_to_numpy_tall(self):\n        self.df_tall.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_to_numpy_tall",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5569b6deed04489b4f459b07dc638df2d11771fc68bd230503521874fd8280e9",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_to_numpy_wide": {
        "code": "class ToNumpy:\n    def time_to_numpy_wide(self):\n        self.df_wide.to_numpy()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_to_numpy_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bf654b3ba6daa0281ee0f2802eb3d2aeda580273f37f51975c0a6949c7f80d88",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_values_mixed_tall": {
        "code": "class ToNumpy:\n    def time_values_mixed_tall(self):\n        self.df_mixed_tall.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_values_mixed_tall",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "63f9938602ca8bd629ccf01754db81ac30be79e67c04b0f0773bc5b0d042f33d",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_values_mixed_wide": {
        "code": "class ToNumpy:\n    def time_values_mixed_wide(self):\n        self.df_mixed_wide.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_values_mixed_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fafed5c463a9d832b1c45ce00e7755cf10235ae288cb4939713e9e25b2884d1e",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_values_tall": {
        "code": "class ToNumpy:\n    def time_values_tall(self):\n        self.df_tall.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_values_tall",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d7415d8faba6d4a8ac5b59b9db979d88981de08547167f51ec5c31b322149dfb",
        "warmup_time": -1
    },
    "frame_methods.ToNumpy.time_values_wide": {
        "code": "class ToNumpy:\n    def time_values_wide(self):\n        self.df_wide.values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumpy:\n    def setup(self):\n        N = 10000\n        M = 10\n        self.df_tall = DataFrame(np.random.randn(N, M))\n        self.df_wide = DataFrame(np.random.randn(M, N))\n        self.df_mixed_tall = self.df_tall.copy()\n        self.df_mixed_tall[\"foo\"] = \"bar\"\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\n        self.df_mixed_tall[1] = range(N)\n        self.df_mixed_wide = self.df_wide.copy()\n        self.df_mixed_wide[\"foo\"] = \"bar\"\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\n        self.df_mixed_wide[1] = range(M)",
        "min_run_count": 2,
        "name": "frame_methods.ToNumpy.time_values_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5f1b62f28c9211bb22340a6af83d5b86811950ef975bfd00e0684048cb2de22f",
        "warmup_time": -1
    },
    "frame_methods.ToString.time_to_string_floats": {
        "code": "class ToString:\n    def time_to_string_floats(self):\n        self.df.to_string()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToString:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(100, 10))",
        "min_run_count": 2,
        "name": "frame_methods.ToString.time_to_string_floats",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e56ad6695cac3b92e88feb11d8c47fa92f10fb86e51634e87529d771f168cdbf",
        "warmup_time": -1
    },
    "frame_methods.XS.time_frame_xs": {
        "code": "class XS:\n    def time_frame_xs(self, axis):\n        self.df.xs(self.N / 2, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass XS:\n    def setup(self, axis):\n        self.N = 10 ** 4\n        self.df = DataFrame(np.random.randn(self.N, self.N))",
        "min_run_count": 2,
        "name": "frame_methods.XS.time_frame_xs",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bc2ffa325afb7a6d4dd48a9f30d9d7122b8349b6db43e9f5382acfe72fc107ff",
        "warmup_time": -1
    },
    "gil.ParallelDatetimeFields.time_datetime_field_day": {
        "code": "class ParallelDatetimeFields:\n    def time_datetime_field_day(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.day\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")",
        "min_run_count": 2,
        "name": "gil.ParallelDatetimeFields.time_datetime_field_day",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2126fc2f9edac2bd0dbf1da646ee560fd9a4f2ce00482b0c4c9752aef6a073d0",
        "warmup_time": -1
    },
    "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth": {
        "code": "class ParallelDatetimeFields:\n    def time_datetime_field_daysinmonth(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.days_in_month\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")",
        "min_run_count": 2,
        "name": "gil.ParallelDatetimeFields.time_datetime_field_daysinmonth",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "533257d1e027cfe9571c9fdf0199068d3891cc19b8dee8ede42eeb19f012ca7b",
        "warmup_time": -1
    },
    "gil.ParallelDatetimeFields.time_datetime_field_normalize": {
        "code": "class ParallelDatetimeFields:\n    def time_datetime_field_normalize(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.normalize()\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")",
        "min_run_count": 2,
        "name": "gil.ParallelDatetimeFields.time_datetime_field_normalize",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "140858bc569142f33a06cc8619e5e4222ff3b7bc95e4b3caf28e0f5bd216c6c7",
        "warmup_time": -1
    },
    "gil.ParallelDatetimeFields.time_datetime_field_year": {
        "code": "class ParallelDatetimeFields:\n    def time_datetime_field_year(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.year\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")",
        "min_run_count": 2,
        "name": "gil.ParallelDatetimeFields.time_datetime_field_year",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "acf3cf19fc119ec4811a0d4e416e6515db30395529640ab1dc5b72e291111542",
        "warmup_time": -1
    },
    "gil.ParallelDatetimeFields.time_datetime_to_period": {
        "code": "class ParallelDatetimeFields:\n    def time_datetime_to_period(self):\n        @test_parallel(num_threads=2)\n        def run(dti):\n            dti.to_period(\"S\")\n    \n        run(self.dti)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")",
        "min_run_count": 2,
        "name": "gil.ParallelDatetimeFields.time_datetime_to_period",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f4d5d4c2893d93b4ae99af42cbe203c73dc99710bf1cdb08e6600da884955b66",
        "warmup_time": -1
    },
    "gil.ParallelDatetimeFields.time_period_to_datetime": {
        "code": "class ParallelDatetimeFields:\n    def time_period_to_datetime(self):\n        @test_parallel(num_threads=2)\n        def run(period):\n            period.to_timestamp()\n    \n        run(self.period)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelDatetimeFields:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        self.dti = date_range(\"1900-01-01\", periods=N, freq=\"T\")\n        self.period = self.dti.to_period(\"D\")",
        "min_run_count": 2,
        "name": "gil.ParallelDatetimeFields.time_period_to_datetime",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "34e2674ed35356720a0db8052339522b5134c178948bfb10a735cb52dddbae00",
        "warmup_time": -1
    },
    "gil.ParallelFactorize.time_loop": {
        "code": "class ParallelFactorize:\n    def time_loop(self, threads):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n    \n        strings = tm.makeStringIndex(100000)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n    \n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n    \n        self.loop = loop",
        "min_run_count": 2,
        "name": "gil.ParallelFactorize.time_loop",
        "number": 1,
        "param_names": [
            "threads"
        ],
        "params": [
            [
                "2",
                "4",
                "8"
            ]
        ],
        "repeat": 5,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1cb6b402aa2aeb3fae9b8d32dba939f630c762e958a81401ebf7aa3549a929e5",
        "warmup_time": -1
    },
    "gil.ParallelFactorize.time_parallel": {
        "code": "class ParallelFactorize:\n    def time_parallel(self, threads):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelFactorize:\n    def setup(self, threads):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n    \n        strings = tm.makeStringIndex(100000)\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            factorize(strings)\n    \n        self.parallel = parallel\n    \n        def loop():\n            factorize(strings)\n    \n        self.loop = loop",
        "min_run_count": 2,
        "name": "gil.ParallelFactorize.time_parallel",
        "number": 1,
        "param_names": [
            "threads"
        ],
        "params": [
            [
                "2",
                "4",
                "8"
            ]
        ],
        "repeat": 5,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "daf74f02b56c9cc1240bd45208b5f1781595208c174ca8b46c5b4e18d0f14ebb",
        "warmup_time": -1
    },
    "gil.ParallelGroupbyMethods.time_loop": {
        "code": "class ParallelGroupbyMethods:\n    def time_loop(self, threads, method):\n        for i in range(threads):\n            self.loop()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        ngroups = 10 ** 3\n        df = DataFrame(\n            {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n        )\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.loop = loop",
        "min_run_count": 2,
        "name": "gil.ParallelGroupbyMethods.time_loop",
        "number": 0,
        "param_names": [
            "threads",
            "method"
        ],
        "params": [
            [
                "2",
                "4",
                "8"
            ],
            [
                "'count'",
                "'last'",
                "'max'",
                "'mean'",
                "'min'",
                "'prod'",
                "'sum'",
                "'var'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "26fab3439f1d70add69a970db4ad8f59dfaf87998f5d3ae012674e890fdcd9ec",
        "warmup_time": -1
    },
    "gil.ParallelGroupbyMethods.time_parallel": {
        "code": "class ParallelGroupbyMethods:\n    def time_parallel(self, threads, method):\n        self.parallel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroupbyMethods:\n    def setup(self, threads, method):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        ngroups = 10 ** 3\n        df = DataFrame(\n            {\"key\": np.random.randint(0, ngroups, size=N), \"data\": np.random.randn(N)}\n        )\n    \n        @test_parallel(num_threads=threads)\n        def parallel():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.parallel = parallel\n    \n        def loop():\n            getattr(df.groupby(\"key\")[\"data\"], method)()\n    \n        self.loop = loop",
        "min_run_count": 2,
        "name": "gil.ParallelGroupbyMethods.time_parallel",
        "number": 0,
        "param_names": [
            "threads",
            "method"
        ],
        "params": [
            [
                "2",
                "4",
                "8"
            ],
            [
                "'count'",
                "'last'",
                "'max'",
                "'mean'",
                "'min'",
                "'prod'",
                "'sum'",
                "'var'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1c91a1dc158c488c398238502ea26c20b6bf0a8f5b71f97f738e477df638b9f1",
        "warmup_time": -1
    },
    "gil.ParallelGroups.time_get_groups": {
        "code": "class ParallelGroups:\n    def time_get_groups(self, threads):\n        self.get_groups()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelGroups:\n    def setup(self, threads):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        size = 2 ** 22\n        ngroups = 10 ** 3\n        data = Series(np.random.randint(0, ngroups, size=size))\n    \n        @test_parallel(num_threads=threads)\n        def get_groups():\n            data.groupby(data).groups\n    \n        self.get_groups = get_groups",
        "min_run_count": 2,
        "name": "gil.ParallelGroups.time_get_groups",
        "number": 0,
        "param_names": [
            "threads"
        ],
        "params": [
            [
                "2",
                "4",
                "8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eaf458631eed076c8511d43527f800f72677160ecea92af400344272f9bf9ae0",
        "warmup_time": -1
    },
    "gil.ParallelKth.time_kth_smallest": {
        "code": "class ParallelKth:\n    def time_kth_smallest(self):\n        self.parallel_kth_smallest()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelKth:\n    def setup(self):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 7\n        k = 5 * 10 ** 5\n        kwargs_list = [{\"arr\": np.random.randn(N)}, {\"arr\": np.random.randn(N)}]\n    \n        @test_parallel(num_threads=2, kwargs_list=kwargs_list)\n        def parallel_kth_smallest(arr):\n            algos.kth_smallest(arr, k)\n    \n        self.parallel_kth_smallest = parallel_kth_smallest",
        "min_run_count": 2,
        "name": "gil.ParallelKth.time_kth_smallest",
        "number": 1,
        "param_names": [],
        "params": [],
        "repeat": 5,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "602beacdae5800182dfd98e0a1c68c3a2d252ac6a2126059117359d198b3a7ab",
        "warmup_time": -1
    },
    "gil.ParallelReadCSV.time_read_csv": {
        "code": "class ParallelReadCSV:\n    def time_read_csv(self, dtype):\n        self.parallel_read_csv()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelReadCSV:\n    def setup(self, dtype):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        rows = 10000\n        cols = 50\n        data = {\n            \"float\": DataFrame(np.random.randn(rows, cols)),\n            \"datetime\": DataFrame(\n                np.random.randn(rows, cols), index=date_range(\"1/1/2000\", periods=rows)\n            ),\n            \"object\": DataFrame(\n                \"foo\", index=range(rows), columns=[\"object%03d\" for _ in range(5)]\n            ),\n        }\n    \n        self.fname = f\"__test_{dtype}__.csv\"\n        df = data[dtype]\n        df.to_csv(self.fname)\n    \n        @test_parallel(num_threads=2)\n        def parallel_read_csv():\n            read_csv(self.fname)\n    \n        self.parallel_read_csv = parallel_read_csv",
        "min_run_count": 2,
        "name": "gil.ParallelReadCSV.time_read_csv",
        "number": 1,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'object'",
                "'datetime'"
            ]
        ],
        "repeat": 5,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4345ed768439da47675d20721ca0d30b115c17b70c1179a45fd0fed430ebefe8",
        "warmup_time": -1
    },
    "gil.ParallelRolling.time_rolling": {
        "code": "class ParallelRolling:\n    def time_rolling(self, method):\n        self.parallel_rolling()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelRolling:\n    def setup(self, method):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        win = 100\n        arr = np.random.rand(100000)\n        if hasattr(DataFrame, \"rolling\"):\n            df = DataFrame(arr).rolling(win)\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                getattr(df, method)()\n    \n            self.parallel_rolling = parallel_rolling\n        elif have_rolling_methods:\n            rolling = {\n                \"median\": rolling_median,\n                \"mean\": rolling_mean,\n                \"min\": rolling_min,\n                \"max\": rolling_max,\n                \"var\": rolling_var,\n                \"skew\": rolling_skew,\n                \"kurt\": rolling_kurt,\n                \"std\": rolling_std,\n            }\n    \n            @test_parallel(num_threads=2)\n            def parallel_rolling():\n                rolling[method](arr, win)\n    \n            self.parallel_rolling = parallel_rolling\n        else:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "gil.ParallelRolling.time_rolling",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'median'",
                "'mean'",
                "'min'",
                "'max'",
                "'var'",
                "'skew'",
                "'kurt'",
                "'std'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f5818d11ee205ccaeea0b15e116b97672faeb0e8f53d7103b522d14ea8d33a6c",
        "warmup_time": -1
    },
    "gil.ParallelTake1D.time_take1d": {
        "code": "class ParallelTake1D:\n    def time_take1d(self, dtype):\n        self.parallel_take1d()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParallelTake1D:\n    def setup(self, dtype):\n        if not have_real_test_parallel:\n            raise NotImplementedError\n        N = 10 ** 6\n        df = DataFrame({\"col\": np.arange(N, dtype=dtype)})\n        indexer = np.arange(100, len(df) - 100)\n    \n        @test_parallel(num_threads=2)\n        def parallel_take1d():\n            take_nd(df[\"col\"].values, indexer)\n    \n        self.parallel_take1d = parallel_take1d",
        "min_run_count": 2,
        "name": "gil.ParallelTake1D.time_take1d",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int64'",
                "'float64'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d8bed303b59f18e6bb10e9055b77e8fafa3601cd95d099073c0eb1b854a0620c",
        "warmup_time": -1
    },
    "groupby.AggEngine.time_dataframe_cython": {
        "code": "class AggEngine:\n    def time_dataframe_cython(self, parallel):\n        def function(values):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper.agg(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10 ** 3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.AggEngine.time_dataframe_cython",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fe7fb531ef901f10706853bde5d39864c334fe08f383f2a522e28a0552027a39",
        "warmup_time": -1
    },
    "groupby.AggEngine.time_dataframe_numba": {
        "code": "class AggEngine:\n    def time_dataframe_numba(self, parallel):\n        def function(values, index):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper.agg(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10 ** 3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.AggEngine.time_dataframe_numba",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "293dd0c84e0aa1ede7dbc2b40ed93174843e9708825688bcc3d93d7bedeeb4a5",
        "warmup_time": -1
    },
    "groupby.AggEngine.time_series_cython": {
        "code": "class AggEngine:\n    def time_series_cython(self, parallel):\n        def function(values):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper[1].agg(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10 ** 3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.AggEngine.time_series_cython",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9812d138aab66a8b327028163351240c2f29d47b8f07589ab37ba1273e234a02",
        "warmup_time": -1
    },
    "groupby.AggEngine.time_series_numba": {
        "code": "class AggEngine:\n    def time_series_numba(self, parallel):\n        def function(values, index):\n            total = 0\n            for i, value in enumerate(values):\n                if i % 2:\n                    total += value + 5\n                else:\n                    total += value * 2\n            return total\n    \n        self.grouper[1].agg(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggEngine:\n    def setup(self, parallel):\n        N = 10 ** 3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.AggEngine.time_series_numba",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0e083884a8df1225235653229632e8f36f9592d60ec0556754a2a961c2af3eb7",
        "warmup_time": -1
    },
    "groupby.AggFunctions.time_different_numpy_functions": {
        "code": "class AggFunctions:\n    def time_different_numpy_functions(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(\n            {\"value1\": np.mean, \"value2\": np.var, \"value3\": np.sum}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10 ** 5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.AggFunctions.time_different_numpy_functions",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:270",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bd7dbfbf054072af1c15c58b76aecf9a548c38700889da2204df25ed01ab6112",
        "warmup_time": -1
    },
    "groupby.AggFunctions.time_different_python_functions_multicol": {
        "code": "class AggFunctions:\n    def time_different_python_functions_multicol(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg([sum, min, max])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10 ** 5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.AggFunctions.time_different_python_functions_multicol",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:270",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9f3439193005aaa0fdcf1d30c0068ea5cf71519f4ce9d6c4d670849a0e24fa3e",
        "warmup_time": -1
    },
    "groupby.AggFunctions.time_different_python_functions_singlecol": {
        "code": "class AggFunctions:\n    def time_different_python_functions_singlecol(self, df):\n        df.groupby(\"key1\").agg([sum, min, max])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10 ** 5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.AggFunctions.time_different_python_functions_singlecol",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:270",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "706b8c5902bbacf4a697b0ae5d1ca654604b2baddc5ea24813c4da17f06af9af",
        "warmup_time": -1
    },
    "groupby.AggFunctions.time_different_str_functions": {
        "code": "class AggFunctions:\n    def time_different_str_functions(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(\n            {\"value1\": \"mean\", \"value2\": \"var\", \"value3\": \"sum\"}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AggFunctions:\n    def setup_cache(self):\n        N = 10 ** 5\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        df = DataFrame(\n            {\n                \"key1\": fac1.take(np.random.randint(0, 3, size=N)),\n                \"key2\": fac2.take(np.random.randint(0, 2, size=N)),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.AggFunctions.time_different_str_functions",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:270",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3644465d89a832b469237f16a04bc54cd9985334f55cf4c6f4cc9691a045aa0f",
        "warmup_time": -1
    },
    "groupby.Apply.time_copy_function_multi_col": {
        "code": "class Apply:\n    def time_copy_function_multi_col(self, factor):\n        self.df.groupby([\"key\", \"key2\"]).apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10 ** factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df",
        "min_run_count": 2,
        "name": "groupby.Apply.time_copy_function_multi_col",
        "number": 0,
        "param_names": [
            "factor"
        ],
        "params": [
            [
                "4",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b6ca33abccb8ad805d38ce1c37538b48f5b6385e75266fc4168543e7b5f92749",
        "warmup_time": -1
    },
    "groupby.Apply.time_copy_overhead_single_col": {
        "code": "class Apply:\n    def time_copy_overhead_single_col(self, factor):\n        self.df.groupby(\"key\").apply(self.df_copy_function)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10 ** factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df",
        "min_run_count": 2,
        "name": "groupby.Apply.time_copy_overhead_single_col",
        "number": 0,
        "param_names": [
            "factor"
        ],
        "params": [
            [
                "4",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "00936c4fae45a85ff1a121b102f01fa3ad101c87b3c432a14c3320096e22dce4",
        "warmup_time": -1
    },
    "groupby.Apply.time_scalar_function_multi_col": {
        "code": "class Apply:\n    def time_scalar_function_multi_col(self, factor):\n        self.df.groupby([\"key\", \"key2\"]).apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10 ** factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df",
        "min_run_count": 2,
        "name": "groupby.Apply.time_scalar_function_multi_col",
        "number": 0,
        "param_names": [
            "factor"
        ],
        "params": [
            [
                "4",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2280ba6d66d0e5781e217917a63c367c3efd422698ada23bd429129160b184cb",
        "warmup_time": -1
    },
    "groupby.Apply.time_scalar_function_single_col": {
        "code": "class Apply:\n    def time_scalar_function_single_col(self, factor):\n        self.df.groupby(\"key\").apply(lambda x: 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, factor):\n        N = 10 ** factor\n        # two cases:\n        # - small groups: small data (N**4) + many labels (2000) -> average group\n        #   size of 5 (-> larger overhead of slicing method)\n        # - larger groups: larger data (N**5) + fewer labels (20) -> average group\n        #   size of 5000\n        labels = np.random.randint(0, 2000 if factor == 4 else 20, size=N)\n        labels2 = np.random.randint(0, 3, size=N)\n        df = DataFrame(\n            {\n                \"key\": labels,\n                \"key2\": labels2,\n                \"value1\": np.random.randn(N),\n                \"value2\": [\"foo\", \"bar\", \"baz\", \"qux\"] * (N // 4),\n            }\n        )\n        self.df = df",
        "min_run_count": 2,
        "name": "groupby.Apply.time_scalar_function_single_col",
        "number": 0,
        "param_names": [
            "factor"
        ],
        "params": [
            [
                "4",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "27878a415b040bff131000b871e373b3c8082b0445ac49725dc35aa7b54659a0",
        "warmup_time": -1
    },
    "groupby.ApplyDictReturn.time_groupby_apply_dict_return": {
        "code": "class ApplyDictReturn:\n    def time_groupby_apply_dict_return(self):\n        self.data.groupby(self.labels).apply(\n            lambda x: {\"first\": x.values[0], \"last\": x.values[-1]}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ApplyDictReturn:\n    def setup(self):\n        self.labels = np.arange(1000).repeat(10)\n        self.data = Series(np.random.randn(len(self.labels)))",
        "min_run_count": 2,
        "name": "groupby.ApplyDictReturn.time_groupby_apply_dict_return",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5924f4088fcf382ce33f346ce7ddfd12e83ed70b71b93eaec422e9d9eebf6683",
        "warmup_time": -1
    },
    "groupby.Categories.time_groupby_extra_cat_nosort": {
        "code": "class Categories:\n    def time_groupby_extra_cat_nosort(self):\n        self.df_extra_cat.groupby(\"a\", sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.Categories.time_groupby_extra_cat_nosort",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "463a09a3ef3879fb839ddf7bd40d034a738f9517e088a2ee2af846929623da37",
        "warmup_time": -1
    },
    "groupby.Categories.time_groupby_extra_cat_sort": {
        "code": "class Categories:\n    def time_groupby_extra_cat_sort(self):\n        self.df_extra_cat.groupby(\"a\")[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.Categories.time_groupby_extra_cat_sort",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "88a1e68ac4ac7ebb650163773e36b4addcd37b55b31ef4fd8c152630a1b7764b",
        "warmup_time": -1
    },
    "groupby.Categories.time_groupby_nosort": {
        "code": "class Categories:\n    def time_groupby_nosort(self):\n        self.df.groupby(\"a\", sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.Categories.time_groupby_nosort",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "75e65a8b9d99b8d2d561c7c5dbf1c7dd0030c27767544de0e76410b3a1bde32d",
        "warmup_time": -1
    },
    "groupby.Categories.time_groupby_ordered_nosort": {
        "code": "class Categories:\n    def time_groupby_ordered_nosort(self):\n        self.df_ordered.groupby(\"a\", sort=False)[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.Categories.time_groupby_ordered_nosort",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1af40b756b5aae13b25c9dde891b2f792b9f37f1c6bfcb4f8dcd3294ae56e4e2",
        "warmup_time": -1
    },
    "groupby.Categories.time_groupby_ordered_sort": {
        "code": "class Categories:\n    def time_groupby_ordered_sort(self):\n        self.df_ordered.groupby(\"a\")[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.Categories.time_groupby_ordered_sort",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b9ceaadbe442d94b3e2f7ed2ab19e400df253853fd21ffeb136481a1854035a6",
        "warmup_time": -1
    },
    "groupby.Categories.time_groupby_sort": {
        "code": "class Categories:\n    def time_groupby_sort(self):\n        self.df.groupby(\"a\")[\"b\"].count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Categories:\n    def setup(self):\n        N = 10 ** 5\n        arr = np.random.random(N)\n        data = {\"a\": Categorical(np.random.randint(10000, size=N)), \"b\": arr}\n        self.df = DataFrame(data)\n        data = {\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\n            \"b\": arr,\n        }\n        self.df_ordered = DataFrame(data)\n        data = {\n            \"a\": Categorical(\n                np.random.randint(100, size=N), categories=np.arange(10000)\n            ),\n            \"b\": arr,\n        }\n        self.df_extra_cat = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.Categories.time_groupby_sort",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "25d8475154631409f5819e94e2b0f3406c6ea7db01bd8cb5861c7c80ab797fb2",
        "warmup_time": -1
    },
    "groupby.CountMultiDtype.time_multi_count": {
        "code": "class CountMultiDtype:\n    def time_multi_count(self, df):\n        df.groupby([\"key1\", \"key2\"]).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiDtype:\n    def setup_cache(self):\n        n = 10000\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        dates[np.random.rand(n) > 0.5] = np.datetime64(\"nat\")\n        offsets[np.random.rand(n) > 0.5] = np.timedelta64(\"nat\")\n        value2 = np.random.randn(n)\n        value2[np.random.rand(n) > 0.5] = np.nan\n        obj = np.random.choice(list(\"ab\"), size=n).astype(object)\n        obj[np.random.randn(n) > 0.5] = np.nan\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"dates\": dates,\n                \"value2\": value2,\n                \"value3\": np.random.randn(n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"obj\": obj,\n                \"offsets\": offsets,\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.CountMultiDtype.time_multi_count",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:221",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "781eccf167f79b9db2b42e6637dca3e0917b3ee82948078ab34ec1fdd55a8ba7",
        "warmup_time": -1
    },
    "groupby.CountMultiInt.time_multi_int_count": {
        "code": "class CountMultiInt:\n    def time_multi_int_count(self, df):\n        df.groupby([\"key1\", \"key2\"]).count()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"ints2\": np.random.randint(0, 1000, size=n),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.CountMultiInt.time_multi_int_count",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:250",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c0c648960106b54be2a606e2093e04045e55e61c502f37ec87315025300cc688",
        "warmup_time": -1
    },
    "groupby.CountMultiInt.time_multi_int_nunique": {
        "code": "class CountMultiInt:\n    def time_multi_int_nunique(self, df):\n        df.groupby([\"key1\", \"key2\"]).nunique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CountMultiInt:\n    def setup_cache(self):\n        n = 10000\n        df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"ints\": np.random.randint(0, 1000, size=n),\n                \"ints2\": np.random.randint(0, 1000, size=n),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.CountMultiInt.time_multi_int_nunique",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:250",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "02179b80a10ef56e163f7134b90b2b3a14e1e783c29bcd78e8c839cc49c2b89a",
        "warmup_time": -1
    },
    "groupby.Cumulative.time_frame_transform": {
        "code": "class Cumulative:\n    def time_frame_transform(self, dtype, method):\n        self.df.groupby(\"key\").transform(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cumulative:\n    def setup(self, dtype, method):\n        N = 500_000\n        vals = np.random.randint(-10, 10, (N, 5))\n        null_vals = vals.astype(float, copy=True)\n        null_vals[::2, :] = np.nan\n        null_vals[::3, :] = np.nan\n        df = DataFrame(vals, columns=list(\"abcde\"), dtype=dtype)\n        null_df = DataFrame(null_vals, columns=list(\"abcde\"), dtype=dtype)\n        keys = np.random.randint(0, 100, size=N)\n        df[\"key\"] = keys\n        null_df[\"key\"] = keys\n        self.df = df\n        self.null_df = null_df",
        "min_run_count": 2,
        "name": "groupby.Cumulative.time_frame_transform",
        "number": 0,
        "param_names": [
            "dtype",
            "method"
        ],
        "params": [
            [
                "'float64'",
                "'int64'",
                "'Float64'",
                "'Int64'"
            ],
            [
                "'cummin'",
                "'cummax'",
                "'cumsum'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "021e341fad052e016b88d6137e2dc22a41c1e31a7050d5358eb7950b0deca589",
        "warmup_time": -1
    },
    "groupby.Cumulative.time_frame_transform_many_nulls": {
        "code": "class Cumulative:\n    def time_frame_transform_many_nulls(self, dtype, method):\n        self.null_df.groupby(\"key\").transform(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cumulative:\n    def setup(self, dtype, method):\n        N = 500_000\n        vals = np.random.randint(-10, 10, (N, 5))\n        null_vals = vals.astype(float, copy=True)\n        null_vals[::2, :] = np.nan\n        null_vals[::3, :] = np.nan\n        df = DataFrame(vals, columns=list(\"abcde\"), dtype=dtype)\n        null_df = DataFrame(null_vals, columns=list(\"abcde\"), dtype=dtype)\n        keys = np.random.randint(0, 100, size=N)\n        df[\"key\"] = keys\n        null_df[\"key\"] = keys\n        self.df = df\n        self.null_df = null_df",
        "min_run_count": 2,
        "name": "groupby.Cumulative.time_frame_transform_many_nulls",
        "number": 0,
        "param_names": [
            "dtype",
            "method"
        ],
        "params": [
            [
                "'float64'",
                "'int64'",
                "'Float64'",
                "'Int64'"
            ],
            [
                "'cummin'",
                "'cummax'",
                "'cumsum'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ac0a7c8dc1709cc982c0a23cbede0e108be9f8b63dc0cd84e35a5a90a96d6f89",
        "warmup_time": -1
    },
    "groupby.DateAttributes.time_len_groupby_object": {
        "code": "class DateAttributes:\n    def time_len_groupby_object(self):\n        len(self.ts.groupby([self.year, self.month, self.day]))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DateAttributes:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", \"12/31/2005\", freq=\"H\")\n        self.year, self.month, self.day = rng.year, rng.month, rng.day\n        self.ts = Series(np.random.randn(len(rng)), index=rng)",
        "min_run_count": 2,
        "name": "groupby.DateAttributes.time_len_groupby_object",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d1f886f153117a642f7678e24ba28a35956c89d6e7660787a3a1f4b738ec73d7",
        "warmup_time": -1
    },
    "groupby.Datelike.time_sum": {
        "code": "class Datelike:\n    def time_sum(self, grouper):\n        self.df.groupby(self.grouper).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Datelike:\n    def setup(self, grouper):\n        N = 10 ** 4\n        rng_map = {\n            \"period_range\": period_range,\n            \"date_range\": date_range,\n            \"date_range_tz\": partial(date_range, tz=\"US/Central\"),\n        }\n        self.grouper = rng_map[grouper](\"1900-01-01\", freq=\"D\", periods=N)\n        self.df = DataFrame(np.random.randn(10 ** 4, 2))",
        "min_run_count": 2,
        "name": "groupby.Datelike.time_sum",
        "number": 0,
        "param_names": [
            "grouper"
        ],
        "params": [
            [
                "'period_range'",
                "'date_range'",
                "'date_range_tz'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "84ce9ba6f91bbce4c9e10abc7a4e3a4fb64d3bbbec7720694542b46079365fa4",
        "warmup_time": -1
    },
    "groupby.FillNA.time_df_bfill": {
        "code": "class FillNA:\n    def time_df_bfill(self):\n        self.df.groupby(\"group\").fillna(method=\"bfill\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNA:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")",
        "min_run_count": 2,
        "name": "groupby.FillNA.time_df_bfill",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "24c3ea0c498314988ab2f7f514c7177a5d84c854090807e1b44f9dcd27a1b610",
        "warmup_time": -1
    },
    "groupby.FillNA.time_df_ffill": {
        "code": "class FillNA:\n    def time_df_ffill(self):\n        self.df.groupby(\"group\").fillna(method=\"ffill\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNA:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")",
        "min_run_count": 2,
        "name": "groupby.FillNA.time_df_ffill",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "63c157de8d01fd0af22a1c9100ccb582c59bd816eea42ac7f1d13d388e3b1d61",
        "warmup_time": -1
    },
    "groupby.FillNA.time_srs_bfill": {
        "code": "class FillNA:\n    def time_srs_bfill(self):\n        self.df.groupby(\"group\")[\"value\"].fillna(method=\"bfill\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNA:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")",
        "min_run_count": 2,
        "name": "groupby.FillNA.time_srs_bfill",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ef22577198dc333646fb9f334ec1f742f270c7342a8c3cdaf7d93997487f81a2",
        "warmup_time": -1
    },
    "groupby.FillNA.time_srs_ffill": {
        "code": "class FillNA:\n    def time_srs_ffill(self):\n        self.df.groupby(\"group\")[\"value\"].fillna(method=\"ffill\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNA:\n    def setup(self):\n        N = 100\n        self.df = DataFrame(\n            {\"group\": [1] * N + [2] * N, \"value\": [np.nan, 1.0] * N}\n        ).set_index(\"group\")",
        "min_run_count": 2,
        "name": "groupby.FillNA.time_srs_ffill",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b6490c508ad10feb8063c8f257b4fad1618c334fe7783676bbede929f0202dbb",
        "warmup_time": -1
    },
    "groupby.Float32.time_sum": {
        "code": "class Float32:\n    def time_sum(self):\n        self.df.groupby([\"a\"])[\"b\"].sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float32:\n    def setup(self):\n        tmp1 = (np.random.random(10000) * 0.1).astype(np.float32)\n        tmp2 = (np.random.random(10000) * 10.0).astype(np.float32)\n        tmp = np.concatenate((tmp1, tmp2))\n        arr = np.repeat(tmp, 10)\n        self.df = DataFrame({\"a\": arr, \"b\": arr})",
        "min_run_count": 2,
        "name": "groupby.Float32.time_sum",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ffe9e34b1eb793ed006421668ab941faed0e6f0e51c5142f0940d4117f1aedb4",
        "warmup_time": -1
    },
    "groupby.GroupByCythonAgg.time_frame_agg": {
        "code": "class GroupByCythonAgg:\n    def time_frame_agg(self, dtype, method):\n        self.df.groupby(\"key\").agg(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByCythonAgg:\n    def setup(self, dtype, method):\n        N = 1_000_000\n        df = DataFrame(np.random.randn(N, 10), columns=list(\"abcdefghij\"))\n        df[\"key\"] = np.random.randint(0, 100, size=N)\n        self.df = df",
        "min_run_count": 2,
        "name": "groupby.GroupByCythonAgg.time_frame_agg",
        "number": 0,
        "param_names": [
            "dtype",
            "method"
        ],
        "params": [
            [
                "'float64'"
            ],
            [
                "'sum'",
                "'prod'",
                "'min'",
                "'max'",
                "'mean'",
                "'median'",
                "'var'",
                "'first'",
                "'last'",
                "'any'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "08ae292d77e9806660d8e3c10232a024c7526f433635c0290aa62b6b313af20f",
        "warmup_time": -1
    },
    "groupby.GroupByMethods.time_dtype_as_field": {
        "code": "class GroupByMethods:\n    def time_dtype_as_field(self, dtype, method, application, ncols):\n        self.as_field_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application, ncols):\n        if method in method_blocklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n    \n        if ncols != 1 and method in [\"value_counts\", \"unique\"]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        if application == \"transformation\" and method in [\n            \"head\",\n            \"tail\",\n            \"unique\",\n            \"value_counts\",\n            \"size\",\n        ]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups).reshape(-1, 1)\n        rng = np.broadcast_to(rng, (len(rng), ncols))\n        taker = np.random.randint(0, ngroups, size=size)\n        values = rng.take(taker, axis=0)\n        if dtype == \"int\":\n            key = np.random.randint(0, size, size=size)\n        elif dtype == \"uint\":\n            key = np.random.randint(0, size, size=size, dtype=dtype)\n        elif dtype == \"float\":\n            key = np.concatenate(\n                [np.random.random(ngroups) * 0.1, np.random.random(ngroups) * 10.0]\n            )\n        elif dtype == \"object\":\n            key = [\"foo\"] * size\n        elif dtype == \"datetime\":\n            key = date_range(\"1/1/2011\", periods=size, freq=\"s\")\n    \n        cols = [f\"values{n}\" for n in range(ncols)]\n        df = DataFrame(values, columns=cols)\n        df[\"key\"] = key\n    \n        if len(cols) == 1:\n            cols = cols[0]\n    \n        if application == \"transformation\":\n            if method == \"describe\":\n                raise NotImplementedError\n    \n            self.as_group_method = lambda: df.groupby(\"key\")[cols].transform(method)\n            self.as_field_method = lambda: df.groupby(cols)[\"key\"].transform(method)\n        else:\n            self.as_group_method = getattr(df.groupby(\"key\")[cols], method)\n            self.as_field_method = getattr(df.groupby(cols)[\"key\"], method)",
        "min_run_count": 2,
        "name": "groupby.GroupByMethods.time_dtype_as_field",
        "number": 0,
        "param_names": [
            "dtype",
            "method",
            "application",
            "ncols"
        ],
        "params": [
            [
                "'int'",
                "'float'",
                "'object'",
                "'datetime'",
                "'uint'"
            ],
            [
                "'all'",
                "'any'",
                "'bfill'",
                "'count'",
                "'cumcount'",
                "'cummax'",
                "'cummin'",
                "'cumprod'",
                "'cumsum'",
                "'describe'",
                "'ffill'",
                "'first'",
                "'head'",
                "'last'",
                "'mad'",
                "'max'",
                "'min'",
                "'median'",
                "'mean'",
                "'nunique'",
                "'pct_change'",
                "'prod'",
                "'quantile'",
                "'rank'",
                "'sem'",
                "'shift'",
                "'size'",
                "'skew'",
                "'std'",
                "'sum'",
                "'tail'",
                "'unique'",
                "'value_counts'",
                "'var'"
            ],
            [
                "'direct'",
                "'transformation'"
            ],
            [
                "1",
                "2",
                "5",
                "10"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c8a393b3d66b82b6f05bb8f29637726c360eef82469999a7a7271cc7448dc87b",
        "warmup_time": -1
    },
    "groupby.GroupByMethods.time_dtype_as_group": {
        "code": "class GroupByMethods:\n    def time_dtype_as_group(self, dtype, method, application, ncols):\n        self.as_group_method()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupByMethods:\n    def setup(self, dtype, method, application, ncols):\n        if method in method_blocklist.get(dtype, {}):\n            raise NotImplementedError  # skip benchmark\n    \n        if ncols != 1 and method in [\"value_counts\", \"unique\"]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        if application == \"transformation\" and method in [\n            \"head\",\n            \"tail\",\n            \"unique\",\n            \"value_counts\",\n            \"size\",\n        ]:\n            # DataFrameGroupBy doesn't have these methods\n            raise NotImplementedError\n    \n        ngroups = 1000\n        size = ngroups * 2\n        rng = np.arange(ngroups).reshape(-1, 1)\n        rng = np.broadcast_to(rng, (len(rng), ncols))\n        taker = np.random.randint(0, ngroups, size=size)\n        values = rng.take(taker, axis=0)\n        if dtype == \"int\":\n            key = np.random.randint(0, size, size=size)\n        elif dtype == \"uint\":\n            key = np.random.randint(0, size, size=size, dtype=dtype)\n        elif dtype == \"float\":\n            key = np.concatenate(\n                [np.random.random(ngroups) * 0.1, np.random.random(ngroups) * 10.0]\n            )\n        elif dtype == \"object\":\n            key = [\"foo\"] * size\n        elif dtype == \"datetime\":\n            key = date_range(\"1/1/2011\", periods=size, freq=\"s\")\n    \n        cols = [f\"values{n}\" for n in range(ncols)]\n        df = DataFrame(values, columns=cols)\n        df[\"key\"] = key\n    \n        if len(cols) == 1:\n            cols = cols[0]\n    \n        if application == \"transformation\":\n            if method == \"describe\":\n                raise NotImplementedError\n    \n            self.as_group_method = lambda: df.groupby(\"key\")[cols].transform(method)\n            self.as_field_method = lambda: df.groupby(cols)[\"key\"].transform(method)\n        else:\n            self.as_group_method = getattr(df.groupby(\"key\")[cols], method)\n            self.as_field_method = getattr(df.groupby(cols)[\"key\"], method)",
        "min_run_count": 2,
        "name": "groupby.GroupByMethods.time_dtype_as_group",
        "number": 0,
        "param_names": [
            "dtype",
            "method",
            "application",
            "ncols"
        ],
        "params": [
            [
                "'int'",
                "'float'",
                "'object'",
                "'datetime'",
                "'uint'"
            ],
            [
                "'all'",
                "'any'",
                "'bfill'",
                "'count'",
                "'cumcount'",
                "'cummax'",
                "'cummin'",
                "'cumprod'",
                "'cumsum'",
                "'describe'",
                "'ffill'",
                "'first'",
                "'head'",
                "'last'",
                "'mad'",
                "'max'",
                "'min'",
                "'median'",
                "'mean'",
                "'nunique'",
                "'pct_change'",
                "'prod'",
                "'quantile'",
                "'rank'",
                "'sem'",
                "'shift'",
                "'size'",
                "'skew'",
                "'std'",
                "'sum'",
                "'tail'",
                "'unique'",
                "'value_counts'",
                "'var'"
            ],
            [
                "'direct'",
                "'transformation'"
            ],
            [
                "1",
                "2",
                "5",
                "10"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f6cb0af0e438588a669af581f7d71978f2cf60e10503195a21afba2863f3dc67",
        "warmup_time": -1
    },
    "groupby.GroupManyLabels.time_sum": {
        "code": "class GroupManyLabels:\n    def time_sum(self, ncols):\n        self.df.groupby(self.labels).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupManyLabels:\n    def setup(self, ncols):\n        N = 1000\n        data = np.random.randn(N, ncols)\n        self.labels = np.random.randint(0, 100, size=N)\n        self.df = DataFrame(data)",
        "min_run_count": 2,
        "name": "groupby.GroupManyLabels.time_sum",
        "number": 0,
        "param_names": [
            "ncols"
        ],
        "params": [
            [
                "1",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "66b2e0c8c016da785fe5cc599d0ce7892b1c5657f8af53ff854fed498e28878a",
        "warmup_time": -1
    },
    "groupby.GroupStrings.time_multi_columns": {
        "code": "class GroupStrings:\n    def time_multi_columns(self):\n        self.df.groupby(list(\"abcd\")).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupStrings:\n    def setup(self):\n        n = 2 * 10 ** 5\n        alpha = list(map(\"\".join, product(ascii_letters, repeat=4)))\n        data = np.random.choice(alpha, (n // 5, 4), replace=False)\n        data = np.repeat(data, 5, axis=0)\n        self.df = DataFrame(data, columns=list(\"abcd\"))\n        self.df[\"joe\"] = (np.random.randn(len(self.df)) * 10).round(3)\n        self.df = self.df.sample(frac=1).reset_index(drop=True)",
        "min_run_count": 2,
        "name": "groupby.GroupStrings.time_multi_columns",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cb3e4e2b4a70df75bbef2b9b9a6c36a86e426ad8305cae459637686b8904405a",
        "warmup_time": -1
    },
    "groupby.Groups.time_series_groups": {
        "code": "class Groups:\n    def time_series_groups(self, data, key):\n        self.ser.groupby(self.ser).groups\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groups:\n    def setup(self, data, key):\n        self.ser = data[key]\n\n    def setup_cache(self):\n        size = 10 ** 6\n        data = {\n            \"int64_small\": Series(np.random.randint(0, 100, size=size)),\n            \"int64_large\": Series(np.random.randint(0, 10000, size=size)),\n            \"object_small\": Series(\n                tm.makeStringIndex(100).take(np.random.randint(0, 100, size=size))\n            ),\n            \"object_large\": Series(\n                tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=size))\n            ),\n        }\n        return data",
        "min_run_count": 2,
        "name": "groupby.Groups.time_series_groups",
        "number": 0,
        "param_names": [
            "key"
        ],
        "params": [
            [
                "'int64_small'",
                "'int64_large'",
                "'object_small'",
                "'object_large'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:118",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "dd1044fa19f17b0788e2d85583a3fbcb33733e372c92586ed76d8a01e911b639",
        "warmup_time": -1
    },
    "groupby.Groups.time_series_indices": {
        "code": "class Groups:\n    def time_series_indices(self, data, key):\n        self.ser.groupby(self.ser).indices\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groups:\n    def setup(self, data, key):\n        self.ser = data[key]\n\n    def setup_cache(self):\n        size = 10 ** 6\n        data = {\n            \"int64_small\": Series(np.random.randint(0, 100, size=size)),\n            \"int64_large\": Series(np.random.randint(0, 10000, size=size)),\n            \"object_small\": Series(\n                tm.makeStringIndex(100).take(np.random.randint(0, 100, size=size))\n            ),\n            \"object_large\": Series(\n                tm.makeStringIndex(10000).take(np.random.randint(0, 10000, size=size))\n            ),\n        }\n        return data",
        "min_run_count": 2,
        "name": "groupby.Groups.time_series_indices",
        "number": 0,
        "param_names": [
            "key"
        ],
        "params": [
            [
                "'int64_small'",
                "'int64_large'",
                "'object_small'",
                "'object_large'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:118",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0b7fa76cdd3cbff9145774d094a2dc3cb618801b49b4fd65524ab9cf5bd33b67",
        "warmup_time": -1
    },
    "groupby.Int64.time_overflow": {
        "code": "class Int64:\n    def time_overflow(self):\n        self.df.groupby(self.cols).max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Int64:\n    def setup(self):\n        arr = np.random.randint(-1 << 12, 1 << 12, (1 << 17, 5))\n        i = np.random.choice(len(arr), len(arr) * 5)\n        arr = np.vstack((arr, arr[i]))\n        i = np.random.permutation(len(arr))\n        arr = arr[i]\n        self.cols = list(\"abcde\")\n        self.df = DataFrame(arr, columns=self.cols)\n        self.df[\"jim\"], self.df[\"joe\"] = np.random.randn(2, len(self.df)) * 10",
        "min_run_count": 2,
        "name": "groupby.Int64.time_overflow",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c59f5b180f618f9de6657c8e0c5a373add1e863a6f3969b4097836f1f4e40929",
        "warmup_time": -1
    },
    "groupby.MultiColumn.time_col_select_lambda_sum": {
        "code": "class MultiColumn:\n    def time_col_select_lambda_sum(self, df):\n        df.groupby([\"key1\", \"key2\"])[\"data1\"].agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10 ** 5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.MultiColumn.time_col_select_lambda_sum",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:317",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d5ebf71614ac7dfd6a1ecb1da73f6c0f6f2cee31845582a7286748edf90f79e7",
        "warmup_time": -1
    },
    "groupby.MultiColumn.time_col_select_numpy_sum": {
        "code": "class MultiColumn:\n    def time_col_select_numpy_sum(self, df):\n        df.groupby([\"key1\", \"key2\"])[\"data1\"].agg(np.sum)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10 ** 5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.MultiColumn.time_col_select_numpy_sum",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:317",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "448cad16e4d25e4ab1fb0e665497b83c1df6f51e9c5fcebb8110c4d78635ad16",
        "warmup_time": -1
    },
    "groupby.MultiColumn.time_cython_sum": {
        "code": "class MultiColumn:\n    def time_cython_sum(self, df):\n        df.groupby([\"key1\", \"key2\"]).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10 ** 5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.MultiColumn.time_cython_sum",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:317",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2455ee4c7c4568b27b2714da76eebb3f99f354946e543ff4a0f6178259e42780",
        "warmup_time": -1
    },
    "groupby.MultiColumn.time_lambda_sum": {
        "code": "class MultiColumn:\n    def time_lambda_sum(self, df):\n        df.groupby([\"key1\", \"key2\"]).agg(lambda x: x.values.sum())\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiColumn:\n    def setup_cache(self):\n        N = 10 ** 5\n        key1 = np.tile(np.arange(100, dtype=object), 1000)\n        key2 = key1.copy()\n        np.random.shuffle(key1)\n        np.random.shuffle(key2)\n        df = DataFrame(\n            {\n                \"key1\": key1,\n                \"key2\": key2,\n                \"data1\": np.random.randn(N),\n                \"data2\": np.random.randn(N),\n            }\n        )\n        return df",
        "min_run_count": 2,
        "name": "groupby.MultiColumn.time_lambda_sum",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "groupby:317",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5b4a1776f3954b364a29465cff8301d57c19f278348a41861c98eba1d07b22b5",
        "warmup_time": -1
    },
    "groupby.Nth.time_frame_nth": {
        "code": "class Nth:\n    def time_frame_nth(self, dtype):\n        self.df.groupby(\"key\").nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data",
        "min_run_count": 2,
        "name": "groupby.Nth.time_frame_nth",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float32'",
                "'float64'",
                "'datetime'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8b676ec65fb57d3fd55be3c581c53c4d53b855868b834f03e9f168104b84c359",
        "warmup_time": -1
    },
    "groupby.Nth.time_frame_nth_any": {
        "code": "class Nth:\n    def time_frame_nth_any(self, dtype):\n        self.df.groupby(\"key\").nth(0, dropna=\"any\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data",
        "min_run_count": 2,
        "name": "groupby.Nth.time_frame_nth_any",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float32'",
                "'float64'",
                "'datetime'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d911c2006d9fdb4ad060e12100ad9c520abae37d7f36a70075efaa6b11752655",
        "warmup_time": -1
    },
    "groupby.Nth.time_groupby_nth_all": {
        "code": "class Nth:\n    def time_groupby_nth_all(self, dtype):\n        self.df.groupby(\"key\").nth(0, dropna=\"all\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data",
        "min_run_count": 2,
        "name": "groupby.Nth.time_groupby_nth_all",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float32'",
                "'float64'",
                "'datetime'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "127bb9670fd3004f7f5807127a73b6f5c8a27cfbfbddce2ce2f923cff35b6288",
        "warmup_time": -1
    },
    "groupby.Nth.time_series_nth": {
        "code": "class Nth:\n    def time_series_nth(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data",
        "min_run_count": 2,
        "name": "groupby.Nth.time_series_nth",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float32'",
                "'float64'",
                "'datetime'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "581317b5df5188484cc212a0bdc635e8b4cf770792330d7ae0ce09d138462b3d",
        "warmup_time": -1
    },
    "groupby.Nth.time_series_nth_all": {
        "code": "class Nth:\n    def time_series_nth_all(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0, dropna=\"all\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data",
        "min_run_count": 2,
        "name": "groupby.Nth.time_series_nth_all",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float32'",
                "'float64'",
                "'datetime'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e85725f0d70f299908c67be84b1c380c2769fb2d235f1c9a9f7a7f896eacd197",
        "warmup_time": -1
    },
    "groupby.Nth.time_series_nth_any": {
        "code": "class Nth:\n    def time_series_nth_any(self, dtype):\n        self.df[\"values\"].groupby(self.df[\"key\"]).nth(0, dropna=\"any\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Nth:\n    def setup(self, dtype):\n        N = 10 ** 5\n        # with datetimes (GH7555)\n        if dtype == \"datetime\":\n            values = date_range(\"1/1/2011\", periods=N, freq=\"s\")\n        elif dtype == \"object\":\n            values = [\"foo\"] * N\n        else:\n            values = np.arange(N).astype(dtype)\n    \n        key = np.arange(N)\n        self.df = DataFrame({\"key\": key, \"values\": values})\n        self.df.iloc[1, 1] = np.nan  # insert missing data",
        "min_run_count": 2,
        "name": "groupby.Nth.time_series_nth_any",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float32'",
                "'float64'",
                "'datetime'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2a955a6c131353ec6357645240de3629ad8fc0921c6392b90da7c130c7c9d12a",
        "warmup_time": -1
    },
    "groupby.RankWithTies.time_rank_ties": {
        "code": "class RankWithTies:\n    def time_rank_ties(self, dtype, tie_method):\n        self.df.groupby(\"key\").rank(method=tie_method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass RankWithTies:\n    def setup(self, dtype, tie_method):\n        N = 10 ** 4\n        if dtype == \"datetime64\":\n            data = np.array([Timestamp(\"2011/01/01\")] * N, dtype=dtype)\n        else:\n            data = np.array([1] * N, dtype=dtype)\n        self.df = DataFrame({\"values\": data, \"key\": [\"foo\"] * N})",
        "min_run_count": 2,
        "name": "groupby.RankWithTies.time_rank_ties",
        "number": 0,
        "param_names": [
            "dtype",
            "tie_method"
        ],
        "params": [
            [
                "'float64'",
                "'float32'",
                "'int64'",
                "'datetime64'"
            ],
            [
                "'first'",
                "'average'",
                "'dense'",
                "'min'",
                "'max'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "27eec9eb147be5e17060fa041b6bf1efd02796180cd220cc1fdf9bc7a2489e95",
        "warmup_time": -1
    },
    "groupby.Sample.time_sample": {
        "code": "class Sample:\n    def time_sample(self):\n        self.df.groupby(self.groups).sample(n=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sample:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame({\"a\": np.zeros(N)})\n        self.groups = np.arange(0, N)\n        self.weights = np.ones(N)",
        "min_run_count": 2,
        "name": "groupby.Sample.time_sample",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "68b221d9354662a3ba5d7d1b908212f1bc335cd123e2fe19c4b5e622fedd9a05",
        "warmup_time": -1
    },
    "groupby.Sample.time_sample_weights": {
        "code": "class Sample:\n    def time_sample_weights(self):\n        self.df.groupby(self.groups).sample(n=1, weights=self.weights)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sample:\n    def setup(self):\n        N = 10 ** 3\n        self.df = DataFrame({\"a\": np.zeros(N)})\n        self.groups = np.arange(0, N)\n        self.weights = np.ones(N)",
        "min_run_count": 2,
        "name": "groupby.Sample.time_sample_weights",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a7283f19c2b6a59ca16073736d734d079f709382c04db333b0b0bf62b5a398ca",
        "warmup_time": -1
    },
    "groupby.Shift.time_defaults": {
        "code": "class Shift:\n    def time_defaults(self):\n        self.df.groupby(\"g\").shift()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self):\n        N = 18\n        self.df = DataFrame({\"g\": [\"a\", \"b\"] * 9, \"v\": list(range(N))})",
        "min_run_count": 2,
        "name": "groupby.Shift.time_defaults",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6a3a41956cf53e5cacf8be90a4432268657d065e708f3681cb0da232d8442b7b",
        "warmup_time": -1
    },
    "groupby.Shift.time_fill_value": {
        "code": "class Shift:\n    def time_fill_value(self):\n        self.df.groupby(\"g\").shift(fill_value=99)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Shift:\n    def setup(self):\n        N = 18\n        self.df = DataFrame({\"g\": [\"a\", \"b\"] * 9, \"v\": list(range(N))})",
        "min_run_count": 2,
        "name": "groupby.Shift.time_fill_value",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "92e908ccaf513773d03d593373379bb94d333da277d2214a08ee1905d58e0c3b",
        "warmup_time": -1
    },
    "groupby.Size.time_category_size": {
        "code": "class Size:\n    def time_category_size(self):\n        self.draws.groupby(self.cats).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10 ** 5\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        self.df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"value1\": np.random.randn(n),\n                \"value2\": np.random.randn(n),\n                \"value3\": np.random.randn(n),\n                \"dates\": dates,\n            }\n        )\n        self.draws = Series(np.random.randn(n))\n        labels = Series([\"foo\", \"bar\", \"baz\", \"qux\"] * (n // 4))\n        self.cats = labels.astype(\"category\")",
        "min_run_count": 2,
        "name": "groupby.Size.time_category_size",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9a95c0f54910b11fc44e2ef0ec751575c9a8328e300212a4fa4fe0364e4937b4",
        "warmup_time": -1
    },
    "groupby.Size.time_multi_size": {
        "code": "class Size:\n    def time_multi_size(self):\n        self.df.groupby([\"key1\", \"key2\"]).size()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Size:\n    def setup(self):\n        n = 10 ** 5\n        offsets = np.random.randint(n, size=n).astype(\"timedelta64[ns]\")\n        dates = np.datetime64(\"now\") + offsets\n        self.df = DataFrame(\n            {\n                \"key1\": np.random.randint(0, 500, size=n),\n                \"key2\": np.random.randint(0, 100, size=n),\n                \"value1\": np.random.randn(n),\n                \"value2\": np.random.randn(n),\n                \"value3\": np.random.randn(n),\n                \"dates\": dates,\n            }\n        )\n        self.draws = Series(np.random.randn(n))\n        labels = Series([\"foo\", \"bar\", \"baz\", \"qux\"] * (n // 4))\n        self.cats = labels.astype(\"category\")",
        "min_run_count": 2,
        "name": "groupby.Size.time_multi_size",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a3e1f4e1015adc42c110e949d53af4156aaf847ce4514558f5bd6bef3390cc07",
        "warmup_time": -1
    },
    "groupby.String.time_str_func": {
        "code": "class String:\n    def time_str_func(self, dtype, method):\n        self.df.groupby(\"a\")[self.df.columns[1:]].agg(method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass String:\n    def setup(self, dtype, method):\n        cols = list(\"abcdefghjkl\")\n        self.df = DataFrame(\n            np.random.randint(0, 100, size=(1_000_000, len(cols))),\n            columns=cols,\n            dtype=dtype,\n        )",
        "min_run_count": 2,
        "name": "groupby.String.time_str_func",
        "number": 0,
        "param_names": [
            "dtype",
            "method"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'"
            ],
            [
                "'sum'",
                "'prod'",
                "'min'",
                "'max'",
                "'mean'",
                "'median'",
                "'var'",
                "'first'",
                "'last'",
                "'any'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eb4b0307062743daac66c684e6741648a29514e205bdaab33e205f95cd67c2f8",
        "warmup_time": -1
    },
    "groupby.SumBools.time_groupby_sum_booleans": {
        "code": "class SumBools:\n    def time_groupby_sum_booleans(self):\n        self.df.groupby(\"ii\").sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumBools:\n    def setup(self):\n        N = 500\n        self.df = DataFrame({\"ii\": range(N), \"bb\": [True] * N})",
        "min_run_count": 2,
        "name": "groupby.SumBools.time_groupby_sum_booleans",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c3539588ce95b04f6cfe6c310ff1d827826da14d25eafe09e1d58cf28f0f2020",
        "warmup_time": -1
    },
    "groupby.SumMultiLevel.time_groupby_sum_multiindex": {
        "code": "class SumMultiLevel:\n    def time_groupby_sum_multiindex(self):\n        self.df.groupby(level=[0, 1]).sum()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SumMultiLevel:\n    def setup(self):\n        N = 50\n        self.df = DataFrame(\n            {\"A\": list(range(N)) * 2, \"B\": range(N * 2), \"C\": 1}\n        ).set_index([\"A\", \"B\"])",
        "min_run_count": 2,
        "name": "groupby.SumMultiLevel.time_groupby_sum_multiindex",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120.0,
        "type": "time",
        "unit": "seconds",
        "version": "b34947d529ea832ced0c45868dd46b91974ce4d6a23b4212210c255083673ef8",
        "warmup_time": -1
    },
    "groupby.Transform.time_transform_lambda_max": {
        "code": "class Transform:\n    def time_transform_lambda_max(self):\n        self.df.groupby(level=\"lev1\").transform(lambda x: max(x))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]",
        "min_run_count": 2,
        "name": "groupby.Transform.time_transform_lambda_max",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cd97c891cfd1059859a2bc86e34a869d35b0117bb63bdae9d7150cb103a00c45",
        "warmup_time": -1
    },
    "groupby.Transform.time_transform_multi_key1": {
        "code": "class Transform:\n    def time_transform_multi_key1(self):\n        self.df1.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]",
        "min_run_count": 2,
        "name": "groupby.Transform.time_transform_multi_key1",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "de7a6499d15195f0529b29bb278e83701388364921d86166d4734702bd190b42",
        "warmup_time": -1
    },
    "groupby.Transform.time_transform_multi_key2": {
        "code": "class Transform:\n    def time_transform_multi_key2(self):\n        self.df2.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]",
        "min_run_count": 2,
        "name": "groupby.Transform.time_transform_multi_key2",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bde6a59a0f4a0b1451cd299cc9e487be6da327b71f22c0e097bdcfce264ab55f",
        "warmup_time": -1
    },
    "groupby.Transform.time_transform_multi_key3": {
        "code": "class Transform:\n    def time_transform_multi_key3(self):\n        self.df3.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]",
        "min_run_count": 2,
        "name": "groupby.Transform.time_transform_multi_key3",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9eed15a96b8d6f7f96ef236e48c7ea64a4ae61db1fad378eaa10b88b0f1358bb",
        "warmup_time": -1
    },
    "groupby.Transform.time_transform_multi_key4": {
        "code": "class Transform:\n    def time_transform_multi_key4(self):\n        self.df4.groupby([\"jim\", \"joe\"])[\"jolie\"].transform(\"max\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]",
        "min_run_count": 2,
        "name": "groupby.Transform.time_transform_multi_key4",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "30884b75eeb8e9eab9ee099254d810cef94f5376ccdfb63ca34682ee0ab82069",
        "warmup_time": -1
    },
    "groupby.Transform.time_transform_ufunc_max": {
        "code": "class Transform:\n    def time_transform_ufunc_max(self):\n        self.df.groupby(level=\"lev1\").transform(np.max)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Transform:\n    def setup(self):\n        n1 = 400\n        n2 = 250\n        index = MultiIndex(\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\n            names=[\"lev1\", \"lev2\"],\n        )\n        arr = np.random.randn(n1 * n2, 3)\n        arr[::10000, 0] = np.nan\n        arr[1::10000, 1] = np.nan\n        arr[2::10000, 2] = np.nan\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\n        self.df = data\n    \n        n = 20000\n        self.df1 = DataFrame(\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df2 = self.df1.copy()\n        self.df2[\"jim\"] = self.df2[\"joe\"]\n    \n        self.df3 = DataFrame(\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\n        )\n        self.df4 = self.df3.copy()\n        self.df4[\"jim\"] = self.df4[\"joe\"]",
        "min_run_count": 2,
        "name": "groupby.Transform.time_transform_ufunc_max",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a5d580527de05be40791d8efdd188f95a26d2f0850bd9d88c9f8d4513c6a86af",
        "warmup_time": -1
    },
    "groupby.TransformBools.time_transform_mean": {
        "code": "class TransformBools:\n    def time_transform_mean(self):\n        self.df[\"signal\"].groupby(self.g).transform(np.mean)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformBools:\n    def setup(self):\n        N = 120000\n        transition_points = np.sort(np.random.choice(np.arange(N), 1400))\n        transitions = np.zeros(N, dtype=np.bool_)\n        transitions[transition_points] = True\n        self.g = transitions.cumsum()\n        self.df = DataFrame({\"signal\": np.random.rand(N)})",
        "min_run_count": 2,
        "name": "groupby.TransformBools.time_transform_mean",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "77ed5daec80a63b0a692cd76ae976065a154f1889d5c28313a19419a1b677a12",
        "warmup_time": -1
    },
    "groupby.TransformEngine.time_dataframe_cython": {
        "code": "class TransformEngine:\n    def time_dataframe_cython(self, parallel):\n        def function(values):\n            return values * 5\n    \n        self.grouper.transform(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10 ** 3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.TransformEngine.time_dataframe_cython",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f73f1ddca6703fe8ec6a4e4bc2c0bfa45b92207c651f82b0bec38f1bb6e63598",
        "warmup_time": -1
    },
    "groupby.TransformEngine.time_dataframe_numba": {
        "code": "class TransformEngine:\n    def time_dataframe_numba(self, parallel):\n        def function(values, index):\n            return values * 5\n    \n        self.grouper.transform(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10 ** 3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.TransformEngine.time_dataframe_numba",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d8707b84c2599f86c702f0a0a4e43e917562dfc80b881006729205ff8fabd894",
        "warmup_time": -1
    },
    "groupby.TransformEngine.time_series_cython": {
        "code": "class TransformEngine:\n    def time_series_cython(self, parallel):\n        def function(values):\n            return values * 5\n    \n        self.grouper[1].transform(function, engine=\"cython\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10 ** 3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.TransformEngine.time_series_cython",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5a61f7996ca73757f57251300e596c881d857d94ea0e39f862a950af02b48776",
        "warmup_time": -1
    },
    "groupby.TransformEngine.time_series_numba": {
        "code": "class TransformEngine:\n    def time_series_numba(self, parallel):\n        def function(values, index):\n            return values * 5\n    \n        self.grouper[1].transform(\n            function, engine=\"numba\", engine_kwargs={\"parallel\": self.parallel}\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformEngine:\n    def setup(self, parallel):\n        N = 10 ** 3\n        data = DataFrame(\n            {0: [str(i) for i in range(100)] * N, 1: list(range(100)) * N},\n            columns=[0, 1],\n        )\n        self.parallel = parallel\n        self.grouper = data.groupby(0)",
        "min_run_count": 2,
        "name": "groupby.TransformEngine.time_series_numba",
        "number": 0,
        "param_names": [
            "parallel"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "430d2fec019e60359e07e92654c2aeecd089d71675da6899fc2c92fbf4d1c08f",
        "warmup_time": -1
    },
    "groupby.TransformNaN.time_first": {
        "code": "class TransformNaN:\n    def time_first(self):\n        self.df_nans.groupby(\"key\").transform(\"first\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TransformNaN:\n    def setup(self):\n        self.df_nans = DataFrame(\n            {\"key\": np.repeat(np.arange(1000), 10), \"B\": np.nan, \"C\": np.nan}\n        )\n        self.df_nans.loc[4::10, \"B\":\"C\"] = 5",
        "min_run_count": 2,
        "name": "groupby.TransformNaN.time_first",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "466258ae973db79b6c4ae80572d3424a11b6997e4ab98b9751eb9a5d30f468e8",
        "warmup_time": -1
    },
    "hash_functions.Float64GroupIndex.time_groupby": {
        "code": "class Float64GroupIndex:\n    def time_groupby(self):\n        self.df.groupby(self.group_index).last()\n\n    def setup(self):\n        self.df = pd.date_range(\n            start=\"1/1/2018\", end=\"1/2/2018\", periods=10 ** 6\n        ).to_frame()\n        self.group_index = np.round(self.df.index.astype(int) / 10 ** 9)",
        "min_run_count": 2,
        "name": "hash_functions.Float64GroupIndex.time_groupby",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3fefee55c1eefc3455e93d3032193dbc1a7e9ba4293a3385b4cbd7dac659b704",
        "warmup_time": -1
    },
    "hash_functions.NumericSeriesIndexing.time_loc_slice": {
        "code": "class NumericSeriesIndexing:\n    def time_loc_slice(self, index, N):\n        # trigger building of mapping\n        self.data.loc[:800]\n\n    def setup(self, index, N):\n        vals = np.array(list(range(55)) + [54] + list(range(55, N - 1)))\n        indices = index(vals)\n        self.data = pd.Series(np.arange(N), index=indices)",
        "min_run_count": 2,
        "name": "hash_functions.NumericSeriesIndexing.time_loc_slice",
        "number": 0,
        "param_names": [
            "index_dtype",
            "N"
        ],
        "params": [
            [
                "<class 'pandas.core.indexes.numeric.Int64Index'>",
                "<class 'pandas.core.indexes.numeric.UInt64Index'>",
                "<class 'pandas.core.indexes.numeric.Float64Index'>"
            ],
            [
                "10000",
                "100000",
                "500000",
                "1000000",
                "5000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f22593b8d6df9c0420ee8857f9b382c665ecbaf7ef0d0786cf0f5d9d6330ae21",
        "warmup_time": -1
    },
    "hash_functions.NumericSeriesIndexingShuffled.time_loc_slice": {
        "code": "class NumericSeriesIndexingShuffled:\n    def time_loc_slice(self, index, N):\n        # trigger building of mapping\n        self.data.loc[:800]\n\n    def setup(self, index, N):\n        vals = np.array(list(range(55)) + [54] + list(range(55, N - 1)))\n        np.random.shuffle(vals)\n        indices = index(vals)\n        self.data = pd.Series(np.arange(N), index=indices)",
        "min_run_count": 2,
        "name": "hash_functions.NumericSeriesIndexingShuffled.time_loc_slice",
        "number": 0,
        "param_names": [
            "index_dtype",
            "N"
        ],
        "params": [
            [
                "<class 'pandas.core.indexes.numeric.Int64Index'>",
                "<class 'pandas.core.indexes.numeric.UInt64Index'>",
                "<class 'pandas.core.indexes.numeric.Float64Index'>"
            ],
            [
                "10000",
                "100000",
                "500000",
                "1000000",
                "5000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3c20465e8c11d0248c3518850d998ff4e2057e4887b2e53bc01804188718b746",
        "warmup_time": -1
    },
    "hash_functions.UniqueAndFactorizeArange.time_factorize": {
        "code": "class UniqueAndFactorizeArange:\n    def time_factorize(self, exponent):\n        pd.factorize(self.a2)\n\n    def setup(self, exponent):\n        a = np.arange(10 ** 4, dtype=\"float64\")\n        self.a2 = (a + 10 ** exponent).repeat(100)",
        "min_run_count": 2,
        "name": "hash_functions.UniqueAndFactorizeArange.time_factorize",
        "number": 0,
        "param_names": [
            "exponent"
        ],
        "params": [
            [
                "4",
                "5",
                "6",
                "7",
                "8",
                "9",
                "10",
                "11",
                "12",
                "13",
                "14",
                "15"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6b11097fca8fd85ddcb6a5c6cbd68d0dab8b2658d742f78ca378971c117ae134",
        "warmup_time": -1
    },
    "hash_functions.UniqueAndFactorizeArange.time_unique": {
        "code": "class UniqueAndFactorizeArange:\n    def time_unique(self, exponent):\n        pd.unique(self.a2)\n\n    def setup(self, exponent):\n        a = np.arange(10 ** 4, dtype=\"float64\")\n        self.a2 = (a + 10 ** exponent).repeat(100)",
        "min_run_count": 2,
        "name": "hash_functions.UniqueAndFactorizeArange.time_unique",
        "number": 0,
        "param_names": [
            "exponent"
        ],
        "params": [
            [
                "4",
                "5",
                "6",
                "7",
                "8",
                "9",
                "10",
                "11",
                "12",
                "13",
                "14",
                "15"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cc081089eb31bf5d2b47f30485ef073ebc71f64a6bb8cbd5e0dc36b1703f221a",
        "warmup_time": -1
    },
    "hash_functions.UniqueForLargePyObjectInts.time_unique": {
        "code": "class UniqueForLargePyObjectInts:\n    def time_unique(self):\n        pd.unique(self.arr)\n\n    def setup(self):\n        lst = [x << 32 for x in range(5000)]\n        self.arr = np.array(lst, dtype=np.object_)",
        "min_run_count": 2,
        "name": "hash_functions.UniqueForLargePyObjectInts.time_unique",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2b911217a8295551fd862ba4e9a94107678d903c84a5a197b90acce421e6f8c6",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_engine": {
        "code": "class IndexCache:\n    def time_engine(self, index_type):\n        self.idx._engine\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_engine",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e5711e57920100e57ba96f42015aab98294974fe400d2444004f44612dfbbdf9",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_inferred_type": {
        "code": "class IndexCache:\n    def time_inferred_type(self, index_type):\n        self.idx.inferred_type\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_inferred_type",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0d1563fedb3db00e611aa1c2637d903eb84d8765753a986bedd0bc41abe9a39d",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_is_all_dates": {
        "code": "class IndexCache:\n    def time_is_all_dates(self, index_type):\n        self.idx.is_all_dates\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_is_all_dates",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b06b0bb5cc90c234eecfd41c09794f555c85efcd74006c63c7e32d0b52439563",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_is_monotonic": {
        "code": "class IndexCache:\n    def time_is_monotonic(self, index_type):\n        self.idx.is_monotonic\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_is_monotonic",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0d30d65fd0a639c3606a0acaf7df15ef7813bb1cd6d88e59326c3527bbfc0353",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_is_monotonic_decreasing": {
        "code": "class IndexCache:\n    def time_is_monotonic_decreasing(self, index_type):\n        self.idx.is_monotonic_decreasing\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_is_monotonic_decreasing",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1044849fe7369f29cdfe008a73ba5b8f7282dc1996ddc2c6d15fa90db0a2d7ef",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_is_monotonic_increasing": {
        "code": "class IndexCache:\n    def time_is_monotonic_increasing(self, index_type):\n        self.idx.is_monotonic_increasing\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_is_monotonic_increasing",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "28f15a1c62804f41173d0f913dd9341be6ac78237cb10c5c5f8571a73bc54464",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_is_unique": {
        "code": "class IndexCache:\n    def time_is_unique(self, index_type):\n        self.idx.is_unique\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_is_unique",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "09b69db282dddd347a12002639ceb289821c86e2253cdea34f05a987326b6a1e",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_shape": {
        "code": "class IndexCache:\n    def time_shape(self, index_type):\n        self.idx.shape\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_shape",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1edac634ecf1f4b7c0d415d12ff6e35388f80ae61ef7065cc71027a1449c9214",
        "warmup_time": -1
    },
    "index_cached_properties.IndexCache.time_values": {
        "code": "class IndexCache:\n    def time_values(self, index_type):\n        self.idx._values\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        if index_type == \"MultiIndex\":\n            self.idx = pd.MultiIndex.from_product(\n                [pd.date_range(\"1/1/2000\", freq=\"T\", periods=N // 2), [\"a\", \"b\"]]\n            )\n        elif index_type == \"DatetimeIndex\":\n            self.idx = pd.date_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"Int64Index\":\n            self.idx = pd.Index(range(N))\n        elif index_type == \"PeriodIndex\":\n            self.idx = pd.period_range(\"1/1/2000\", freq=\"T\", periods=N)\n        elif index_type == \"RangeIndex\":\n            self.idx = pd.RangeIndex(start=0, stop=N)\n        elif index_type == \"IntervalIndex\":\n            self.idx = pd.IntervalIndex.from_arrays(range(N), range(1, N + 1))\n        elif index_type == \"TimedeltaIndex\":\n            self.idx = pd.TimedeltaIndex(range(N))\n        elif index_type == \"Float64Index\":\n            self.idx = pd.Float64Index(range(N))\n        elif index_type == \"UInt64Index\":\n            self.idx = pd.UInt64Index(range(N))\n        elif index_type == \"CategoricalIndex\":\n            self.idx = pd.CategoricalIndex(range(N), range(N))\n        else:\n            raise ValueError\n        assert len(self.idx) == N\n        self.idx._cache = {}",
        "min_run_count": 2,
        "name": "index_cached_properties.IndexCache.time_values",
        "number": 1,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'CategoricalIndex'",
                "'DatetimeIndex'",
                "'Float64Index'",
                "'IntervalIndex'",
                "'Int64Index'",
                "'MultiIndex'",
                "'PeriodIndex'",
                "'RangeIndex'",
                "'TimedeltaIndex'",
                "'UInt64Index'"
            ]
        ],
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "03dfc24f87caa1cfc1d9cc7ce9146f5750bc7ea3f8b8413e2ec995636e127f1d",
        "warmup_time": -1
    },
    "index_object.Float64IndexMethod.time_get_loc": {
        "code": "class Float64IndexMethod:\n    def time_get_loc(self):\n        self.ind.get_loc(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Float64IndexMethod:\n    def setup(self):\n        N = 100_000\n        a = np.arange(N)\n        self.ind = Float64Index(a * 4.8000000418824129e-08)",
        "min_run_count": 2,
        "name": "index_object.Float64IndexMethod.time_get_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f7e923096c0ae44cf2085402c23e0aa1bfe70a1003bec44d6f201df8882bae0d",
        "warmup_time": -1
    },
    "index_object.GC.peakmem_gc_instances": {
        "code": "class GC:\n    def peakmem_gc_instances(self, N):\n        try:\n            gc.disable()\n    \n            for _ in range(N):\n                self.create_use_drop()\n        finally:\n            gc.enable()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)",
        "name": "index_object.GC.peakmem_gc_instances",
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "1",
                "2",
                "5"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "7b1c36ff9e60323ef8e4df7fa94a4764bdb5c6dce62bfea0095812ca55841ff9"
    },
    "index_object.IndexAppend.time_append_int_list": {
        "code": "class IndexAppend:\n    def time_append_int_list(self):\n        self.int_idx.append(self.int_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n    \n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)",
        "min_run_count": 2,
        "name": "index_object.IndexAppend.time_append_int_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b4aca2a1e58c3a9c1fcf88d609971b27165bb574f75bc27946117b15b806d499",
        "warmup_time": -1
    },
    "index_object.IndexAppend.time_append_obj_list": {
        "code": "class IndexAppend:\n    def time_append_obj_list(self):\n        self.obj_idx.append(self.object_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n    \n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)",
        "min_run_count": 2,
        "name": "index_object.IndexAppend.time_append_obj_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f2bef2c5e270fa50623278c27e4444aeea5804c135372bb41c272c1d92f63896",
        "warmup_time": -1
    },
    "index_object.IndexAppend.time_append_range_list": {
        "code": "class IndexAppend:\n    def time_append_range_list(self):\n        self.range_idx.append(self.range_idxs)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexAppend:\n    def setup(self):\n    \n        N = 10_000\n        self.range_idx = RangeIndex(0, 100)\n        self.int_idx = self.range_idx.astype(int)\n        self.obj_idx = self.int_idx.astype(str)\n        self.range_idxs = []\n        self.int_idxs = []\n        self.object_idxs = []\n        for i in range(1, N):\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\n            self.range_idxs.append(r_idx)\n            i_idx = r_idx.astype(int)\n            self.int_idxs.append(i_idx)\n            o_idx = i_idx.astype(str)\n            self.object_idxs.append(o_idx)",
        "min_run_count": 2,
        "name": "index_object.IndexAppend.time_append_range_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "62d2b448631c0700e954fee9e3b677e0bd5df6367af3695c9597b260b962a96e",
        "warmup_time": -1
    },
    "index_object.IndexEquals.time_non_object_equals_multiindex": {
        "code": "class IndexEquals:\n    def time_non_object_equals_multiindex(self):\n        self.idx_non_object.equals(self.mi_large_slow)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexEquals:\n    def setup(self):\n        idx_large_fast = RangeIndex(100_000)\n        idx_small_slow = date_range(start=\"1/1/2012\", periods=1)\n        self.mi_large_slow = MultiIndex.from_product([idx_large_fast, idx_small_slow])\n    \n        self.idx_non_object = RangeIndex(1)",
        "min_run_count": 2,
        "name": "index_object.IndexEquals.time_non_object_equals_multiindex",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bc0a852a1647f5faba1ff3d27b24d6f703432910d3e11571a9d33ab853b195fe",
        "warmup_time": -1
    },
    "index_object.Indexing.time_boolean_array": {
        "code": "class Indexing:\n    def time_boolean_array(self, dtype):\n        self.idx[self.array_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_boolean_array",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "621e9e811353196bda4f9b910227b25c2025f73979193fb9465713f7ca15c389",
        "warmup_time": -1
    },
    "index_object.Indexing.time_boolean_series": {
        "code": "class Indexing:\n    def time_boolean_series(self, dtype):\n        self.idx[self.series_mask]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_boolean_series",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "de5f2e357f26a203081f4adf0f3535ae4a0576ffc6d640c1eb04d403acf10897",
        "warmup_time": -1
    },
    "index_object.Indexing.time_get": {
        "code": "class Indexing:\n    def time_get(self, dtype):\n        self.idx[1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_get",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "79d5599b3adf46ceac71b1c82a1fd34fa3f446bbaec8ff1f585c049d0b7d3009",
        "warmup_time": -1
    },
    "index_object.Indexing.time_get_loc": {
        "code": "class Indexing:\n    def time_get_loc(self, dtype):\n        self.idx.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_get_loc",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b72a7de96e2d56a60414b74d417fcb2729a648cba6876b974b6533bee8d5fac7",
        "warmup_time": -1
    },
    "index_object.Indexing.time_get_loc_non_unique": {
        "code": "class Indexing:\n    def time_get_loc_non_unique(self, dtype):\n        self.non_unique.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_get_loc_non_unique",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "673e5622b2b87001251131e97cc72ea530f81edc82a12fbd649082b9451e2b6a",
        "warmup_time": -1
    },
    "index_object.Indexing.time_get_loc_non_unique_sorted": {
        "code": "class Indexing:\n    def time_get_loc_non_unique_sorted(self, dtype):\n        self.non_unique_sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_get_loc_non_unique_sorted",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a4836dd7b96631197d722a28be5ed174e994246d3a79e3bf180ad7d42e4b1228",
        "warmup_time": -1
    },
    "index_object.Indexing.time_get_loc_sorted": {
        "code": "class Indexing:\n    def time_get_loc_sorted(self, dtype):\n        self.sorted.get_loc(self.key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_get_loc_sorted",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9e8795c5f15a5514c0d4e09ac821d4ef56284f81af33f006336c605d4c11fba7",
        "warmup_time": -1
    },
    "index_object.Indexing.time_slice": {
        "code": "class Indexing:\n    def time_slice(self, dtype):\n        self.idx[:-1]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_slice",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "03a8970b67dfa97d7eb8b48c0b3c1c5833d7d84afbdd7de0a02c0b1133c100ab",
        "warmup_time": -1
    },
    "index_object.Indexing.time_slice_step": {
        "code": "class Indexing:\n    def time_slice_step(self, dtype):\n        self.idx[::2]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Indexing:\n    def setup(self, dtype):\n        N = 10 ** 6\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\n        self.array_mask = (np.arange(N) % 3) == 0\n        self.series_mask = Series(self.array_mask)\n        self.sorted = self.idx.sort_values()\n        half = N // 2\n        self.non_unique = self.idx[:half].append(self.idx[:half])\n        self.non_unique_sorted = (\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\n        )\n        self.key = self.sorted[N // 4]",
        "min_run_count": 2,
        "name": "index_object.Indexing.time_slice_step",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'String'",
                "'Float'",
                "'Int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "16074701d8120b0bc349b7c9d32ffbf25967ef3ec90e104be83c20ec5a8d332a",
        "warmup_time": -1
    },
    "index_object.IntervalIndexMethod.time_intersection": {
        "code": "class IntervalIndexMethod:\n    def time_intersection(self, N):\n        self.left.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))",
        "min_run_count": 2,
        "name": "index_object.IntervalIndexMethod.time_intersection",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "1000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4211da5ac938e20dc8e3ebad85e3fd809e9b9485898f7bc9fa4b78bf51836ba1",
        "warmup_time": -1
    },
    "index_object.IntervalIndexMethod.time_intersection_both_duplicate": {
        "code": "class IntervalIndexMethod:\n    def time_intersection_both_duplicate(self, N):\n        self.intv.intersection(self.intv2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))",
        "min_run_count": 2,
        "name": "index_object.IntervalIndexMethod.time_intersection_both_duplicate",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "1000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "51c27b25f860d486d8b165a9a8fff37e4de68c2b0a193957783434e9151daaaa",
        "warmup_time": -1
    },
    "index_object.IntervalIndexMethod.time_intersection_one_duplicate": {
        "code": "class IntervalIndexMethod:\n    def time_intersection_one_duplicate(self, N):\n        self.intv.intersection(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))",
        "min_run_count": 2,
        "name": "index_object.IntervalIndexMethod.time_intersection_one_duplicate",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "1000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d690ff28419653e49b71207cafa08bd0c7e2901de3773c422f3c20c5659c70da",
        "warmup_time": -1
    },
    "index_object.IntervalIndexMethod.time_is_unique": {
        "code": "class IntervalIndexMethod:\n    def time_is_unique(self, N):\n        self.intv.is_unique\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))",
        "min_run_count": 2,
        "name": "index_object.IntervalIndexMethod.time_is_unique",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "1000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b17a38c55c09eaaebc6e2a4010627e28285f0f0b8e734cf754a82d09ba25a090",
        "warmup_time": -1
    },
    "index_object.IntervalIndexMethod.time_monotonic_inc": {
        "code": "class IntervalIndexMethod:\n    def time_monotonic_inc(self, N):\n        self.intv.is_monotonic_increasing\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexMethod:\n    def setup(self, N):\n        left = np.append(np.arange(N), np.array(0))\n        right = np.append(np.arange(1, N + 1), np.array(1))\n        self.intv = IntervalIndex.from_arrays(left, right)\n        self.intv._engine\n    \n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\n        self.intv2._engine\n    \n        self.left = IntervalIndex.from_breaks(np.arange(N))\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))",
        "min_run_count": 2,
        "name": "index_object.IntervalIndexMethod.time_monotonic_inc",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "1000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2f556c42b4ba4b668eb1eb25dfddbcc31dc3735f52e12303ef99ae8a4b9243e0",
        "warmup_time": -1
    },
    "index_object.Range.time_get_loc_dec": {
        "code": "class Range:\n    def time_get_loc_dec(self):\n        self.idx_dec.get_loc(100_000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 6, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_get_loc_dec",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3839dd3f41e4e4ac682619a7ed989cb406c6a31436368c77648c02f4dadfc1b8",
        "warmup_time": -1
    },
    "index_object.Range.time_get_loc_inc": {
        "code": "class Range:\n    def time_get_loc_inc(self):\n        self.idx_inc.get_loc(900_000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 6, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_get_loc_inc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8a1160c4fe94a297989da17b1764e89b776aaa6f88eb4aa9214f3685da151578",
        "warmup_time": -1
    },
    "index_object.Range.time_iter_dec": {
        "code": "class Range:\n    def time_iter_dec(self):\n        for _ in self.idx_dec:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 6, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_iter_dec",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "51475c2bd1e62afa4b044fbd08affb16266d35ca759158a5bb2b1ae68f2b998d",
        "warmup_time": -1
    },
    "index_object.Range.time_iter_inc": {
        "code": "class Range:\n    def time_iter_inc(self):\n        for _ in self.idx_inc:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 6, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_iter_inc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "477068c5187c3e897e9da7494af742d2bd16390c2ae55bef712eff9fb0296b46",
        "warmup_time": -1
    },
    "index_object.Range.time_max": {
        "code": "class Range:\n    def time_max(self):\n        self.idx_inc.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 6, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_max",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ddedd951dab010537e6e9a522bd1b2836fb522f7305efa828fe4c95effea4265",
        "warmup_time": -1
    },
    "index_object.Range.time_max_trivial": {
        "code": "class Range:\n    def time_max_trivial(self):\n        self.idx_dec.max()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 6, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_max_trivial",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7129be4c1aa65a49e6079014e8c10a20c66024288076241f05f4b7294da56816",
        "warmup_time": -1
    },
    "index_object.Range.time_min": {
        "code": "class Range:\n    def time_min(self):\n        self.idx_dec.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 6, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_min",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eba390927f0e929ed46292880ee7ae78e30d1a0033fa281bf58474e1429651fe",
        "warmup_time": -1
    },
    "index_object.Range.time_min_trivial": {
        "code": "class Range:\n    def time_min_trivial(self):\n        self.idx_inc.min()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 6, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_min_trivial",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "73d3ae38ff9c96f63c1a6bcb78c682aca66a5670ef0f11df83d69fadcc910b99",
        "warmup_time": -1
    },
    "index_object.Range.time_sort_values_asc": {
        "code": "class Range:\n    def time_sort_values_asc(self):\n        self.idx_inc.sort_values()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 6, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_sort_values_asc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2f1ae0a8cc48a715d768e9808ad09bf6eb159042e5e80f5c3ffbc8d971c2c0ca",
        "warmup_time": -1
    },
    "index_object.Range.time_sort_values_des": {
        "code": "class Range:\n    def time_sort_values_des(self):\n        self.idx_inc.sort_values(ascending=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Range:\n    def setup(self):\n        self.idx_inc = RangeIndex(start=0, stop=10 ** 6, step=3)\n        self.idx_dec = RangeIndex(start=10 ** 6, stop=-1, step=-3)",
        "min_run_count": 2,
        "name": "index_object.Range.time_sort_values_des",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1a949a3132c2bd752e2cc5d1b9f25ad2e9fe4f5f188488c7b546eeabb2e1790b",
        "warmup_time": -1
    },
    "index_object.SetDisjoint.time_datetime_difference_disjoint": {
        "code": "class SetDisjoint:\n    def time_datetime_difference_disjoint(self):\n        self.datetime_left.difference(self.datetime_right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetDisjoint:\n    def setup(self):\n        N = 10 ** 5\n        B = N + 20000\n        self.datetime_left = DatetimeIndex(range(N))\n        self.datetime_right = DatetimeIndex(range(N, B))",
        "min_run_count": 2,
        "name": "index_object.SetDisjoint.time_datetime_difference_disjoint",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "69085e638425b1dfc50a31fb2cea07d9a560a51a5852f00289753770f5573dda",
        "warmup_time": -1
    },
    "index_object.SetOperations.time_operation": {
        "code": "class SetOperations:\n    def time_operation(self, dtype, method):\n        getattr(self.left, method)(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetOperations:\n    def setup(self, dtype, method):\n        N = 10 ** 5\n        dates_left = date_range(\"1/1/2000\", periods=N, freq=\"T\")\n        fmt = \"%Y-%m-%d %H:%M:%S\"\n        date_str_left = Index(dates_left.strftime(fmt))\n        int_left = Index(np.arange(N))\n        str_left = tm.makeStringIndex(N)\n        data = {\n            \"datetime\": {\"left\": dates_left, \"right\": dates_left[:-1]},\n            \"date_string\": {\"left\": date_str_left, \"right\": date_str_left[:-1]},\n            \"int\": {\"left\": int_left, \"right\": int_left[:-1]},\n            \"strings\": {\"left\": str_left, \"right\": str_left[:-1]},\n        }\n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]",
        "min_run_count": 2,
        "name": "index_object.SetOperations.time_operation",
        "number": 0,
        "param_names": [
            "dtype",
            "method"
        ],
        "params": [
            [
                "'datetime'",
                "'date_string'",
                "'int'",
                "'strings'"
            ],
            [
                "'intersection'",
                "'union'",
                "'symmetric_difference'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fb62e800ccfa74ed4ad4cb32dc03eb37db9705d0f6e77dfcad698536c701167e",
        "warmup_time": -1
    },
    "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index": {
        "code": "class AssignTimeseriesIndex:\n    def time_frame_assign_timeseries_index(self):\n        self.df[\"date\"] = self.df.index\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AssignTimeseriesIndex:\n    def setup(self):\n        N = 100000\n        idx = date_range(\"1/1/2000\", periods=N, freq=\"H\")\n        self.df = DataFrame(np.random.randn(N, 1), columns=[\"A\"], index=idx)",
        "min_run_count": 2,
        "name": "indexing.AssignTimeseriesIndex.time_frame_assign_timeseries_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e551ce8d4df98da3d5a232e80a7837bf3adae5c13ecd3d477cc36e1442a5983e",
        "warmup_time": -1
    },
    "indexing.CategoricalIndexIndexing.time_get_indexer_list": {
        "code": "class CategoricalIndexIndexing:\n    def time_get_indexer_list(self, index):\n        self.data_unique.get_indexer(self.cat_list)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex(\n            [\"\".join(perm) for perm in itertools.permutations(string.printable, 3)]\n        )\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]",
        "min_run_count": 2,
        "name": "indexing.CategoricalIndexIndexing.time_get_indexer_list",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8ea9c7039a817fe448a4dac312a856ce05a9192ca798a30faa1cf28b6a12946e",
        "warmup_time": -1
    },
    "indexing.CategoricalIndexIndexing.time_get_loc_scalar": {
        "code": "class CategoricalIndexIndexing:\n    def time_get_loc_scalar(self, index):\n        self.data.get_loc(self.cat_scalar)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex(\n            [\"\".join(perm) for perm in itertools.permutations(string.printable, 3)]\n        )\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]",
        "min_run_count": 2,
        "name": "indexing.CategoricalIndexIndexing.time_get_loc_scalar",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "afc69fb401813ebe0d6e980de27ec5979fdfff2ea164c8a83c1cf53d22440371",
        "warmup_time": -1
    },
    "indexing.CategoricalIndexIndexing.time_getitem_bool_array": {
        "code": "class CategoricalIndexIndexing:\n    def time_getitem_bool_array(self, index):\n        self.data[self.data == self.cat_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex(\n            [\"\".join(perm) for perm in itertools.permutations(string.printable, 3)]\n        )\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]",
        "min_run_count": 2,
        "name": "indexing.CategoricalIndexIndexing.time_getitem_bool_array",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "da8ead6ac5e2df0697e55214dd8944bf5e9bb6363e3145db43589f2b846ffc83",
        "warmup_time": -1
    },
    "indexing.CategoricalIndexIndexing.time_getitem_list": {
        "code": "class CategoricalIndexIndexing:\n    def time_getitem_list(self, index):\n        self.data[self.int_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex(\n            [\"\".join(perm) for perm in itertools.permutations(string.printable, 3)]\n        )\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]",
        "min_run_count": 2,
        "name": "indexing.CategoricalIndexIndexing.time_getitem_list",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d554b51160d1b3d333806f0d9dac107f81d21b5e5174f84ac2d5456b33fb5d7d",
        "warmup_time": -1
    },
    "indexing.CategoricalIndexIndexing.time_getitem_list_like": {
        "code": "class CategoricalIndexIndexing:\n    def time_getitem_list_like(self, index):\n        self.data[[self.int_scalar]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex(\n            [\"\".join(perm) for perm in itertools.permutations(string.printable, 3)]\n        )\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]",
        "min_run_count": 2,
        "name": "indexing.CategoricalIndexIndexing.time_getitem_list_like",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c6f1d67c9c65915f21a5b253c159cb58094ec4d76b36fb06c828d46b245a84f9",
        "warmup_time": -1
    },
    "indexing.CategoricalIndexIndexing.time_getitem_scalar": {
        "code": "class CategoricalIndexIndexing:\n    def time_getitem_scalar(self, index):\n        self.data[self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex(\n            [\"\".join(perm) for perm in itertools.permutations(string.printable, 3)]\n        )\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]",
        "min_run_count": 2,
        "name": "indexing.CategoricalIndexIndexing.time_getitem_scalar",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "93c968f66c94bb030c0706d6783c796173d72ccc3707416d080388f24b0d154f",
        "warmup_time": -1
    },
    "indexing.CategoricalIndexIndexing.time_getitem_slice": {
        "code": "class CategoricalIndexIndexing:\n    def time_getitem_slice(self, index):\n        self.data[: self.int_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalIndexIndexing:\n    def setup(self, index):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        indices = {\n            \"monotonic_incr\": CategoricalIndex(values),\n            \"monotonic_decr\": CategoricalIndex(reversed(values)),\n            \"non_monotonic\": CategoricalIndex(list(\"abc\" * N)),\n        }\n        self.data = indices[index]\n        self.data_unique = CategoricalIndex(\n            [\"\".join(perm) for perm in itertools.permutations(string.printable, 3)]\n        )\n    \n        self.int_scalar = 10000\n        self.int_list = list(range(10000))\n    \n        self.cat_scalar = \"b\"\n        self.cat_list = [\"a\", \"c\"]",
        "min_run_count": 2,
        "name": "indexing.CategoricalIndexIndexing.time_getitem_slice",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "29ec986fadd8640f4709bc5134f176c305ac6f475802206fed2c2d8fb71d2797",
        "warmup_time": -1
    },
    "indexing.ChainIndexing.time_chained_indexing": {
        "code": "class ChainIndexing:\n    def time_chained_indexing(self, mode):\n        df = self.df\n        N = self.N\n        with warnings.catch_warnings(record=True):\n            with option_context(\"mode.chained_assignment\", mode):\n                df2 = df[df.A > N // 2]\n                df2[\"C\"] = 1.0\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ChainIndexing:\n    def setup(self, mode):\n        self.N = 1000000\n        self.df = DataFrame({\"A\": np.arange(self.N), \"B\": \"foo\"})",
        "min_run_count": 2,
        "name": "indexing.ChainIndexing.time_chained_indexing",
        "number": 0,
        "param_names": [
            "mode"
        ],
        "params": [
            [
                "None",
                "'warn'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "16258f12b7c725f7ffc21ffed9c69bd9751f02f6a459f86e81c20750c1fc1bba",
        "warmup_time": -1
    },
    "indexing.DataFrameNumericIndexing.time_bool_indexer": {
        "code": "class DataFrameNumericIndexing:\n    def time_bool_indexer(self):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(100000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 50000 + [False] * 50000",
        "min_run_count": 2,
        "name": "indexing.DataFrameNumericIndexing.time_bool_indexer",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "34844717b27f3c522bdf6bc6b3a1619b52496223b8983ae8e0ac77d096cbe372",
        "warmup_time": -1
    },
    "indexing.DataFrameNumericIndexing.time_iloc": {
        "code": "class DataFrameNumericIndexing:\n    def time_iloc(self):\n        self.df.iloc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(100000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 50000 + [False] * 50000",
        "min_run_count": 2,
        "name": "indexing.DataFrameNumericIndexing.time_iloc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ed7c29c68b306fec7327fff5a2f6add65425e7f21e18db6954555eae05215102",
        "warmup_time": -1
    },
    "indexing.DataFrameNumericIndexing.time_iloc_dups": {
        "code": "class DataFrameNumericIndexing:\n    def time_iloc_dups(self):\n        self.df_dup.iloc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(100000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 50000 + [False] * 50000",
        "min_run_count": 2,
        "name": "indexing.DataFrameNumericIndexing.time_iloc_dups",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3c92a9e5c09323956e9bf41414d53901ec7c7d15d29b9694bd6dd58c6852c8c8",
        "warmup_time": -1
    },
    "indexing.DataFrameNumericIndexing.time_loc": {
        "code": "class DataFrameNumericIndexing:\n    def time_loc(self):\n        self.df.loc[:100, 0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(100000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 50000 + [False] * 50000",
        "min_run_count": 2,
        "name": "indexing.DataFrameNumericIndexing.time_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a84f6f815093934eeb9f66fdb609bd9a347487d7f043f2977c08cd04a1c63ea0",
        "warmup_time": -1
    },
    "indexing.DataFrameNumericIndexing.time_loc_dups": {
        "code": "class DataFrameNumericIndexing:\n    def time_loc_dups(self):\n        self.df_dup.loc[self.idx_dupe]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameNumericIndexing:\n    def setup(self):\n        self.idx_dupe = np.array(range(30)) * 99\n        self.df = DataFrame(np.random.randn(100000, 5))\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\n        self.bool_indexer = [True] * 50000 + [False] * 50000",
        "min_run_count": 2,
        "name": "indexing.DataFrameNumericIndexing.time_loc_dups",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cbb94ce7154e6317af01aacf6ef46c975fb0fc95e3f2655244fdd9a142583346",
        "warmup_time": -1
    },
    "indexing.DataFrameStringIndexing.time_boolean_rows": {
        "code": "class DataFrameStringIndexing:\n    def time_boolean_rows(self):\n        self.df[self.bool_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")",
        "min_run_count": 2,
        "name": "indexing.DataFrameStringIndexing.time_boolean_rows",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "337e03057fef98383104445edb6c4267328a55fe53fb638926d965f5cf58d62c",
        "warmup_time": -1
    },
    "indexing.DataFrameStringIndexing.time_boolean_rows_boolean": {
        "code": "class DataFrameStringIndexing:\n    def time_boolean_rows_boolean(self):\n        self.df[self.boolean_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")",
        "min_run_count": 2,
        "name": "indexing.DataFrameStringIndexing.time_boolean_rows_boolean",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c9f3b2e000c947b4479e318626a31b98afabbd649cb0fcf7107bbdbb0ab57055",
        "warmup_time": -1
    },
    "indexing.DataFrameStringIndexing.time_boolean_rows_object": {
        "code": "class DataFrameStringIndexing:\n    def time_boolean_rows_object(self):\n        self.df[self.bool_obj_indexer]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")",
        "min_run_count": 2,
        "name": "indexing.DataFrameStringIndexing.time_boolean_rows_object",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "362bb6b6048c65b4c6ac3c8336721e4497f0e44e0b12ec89aeba7906cc7ac826",
        "warmup_time": -1
    },
    "indexing.DataFrameStringIndexing.time_getitem_scalar": {
        "code": "class DataFrameStringIndexing:\n    def time_getitem_scalar(self):\n        self.df[self.col_scalar][self.idx_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")",
        "min_run_count": 2,
        "name": "indexing.DataFrameStringIndexing.time_getitem_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6cb8e8daea5819b952bfed19651ac1724a5968bb35c37a752425587dfd49452d",
        "warmup_time": -1
    },
    "indexing.DataFrameStringIndexing.time_loc": {
        "code": "class DataFrameStringIndexing:\n    def time_loc(self):\n        self.df.loc[self.idx_scalar, self.col_scalar]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DataFrameStringIndexing:\n    def setup(self):\n        index = tm.makeStringIndex(1000)\n        columns = tm.makeStringIndex(30)\n        with warnings.catch_warnings(record=True):\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\n        self.idx_scalar = index[100]\n        self.col_scalar = columns[10]\n        self.bool_indexer = self.df[self.col_scalar] > 0\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")",
        "min_run_count": 2,
        "name": "indexing.DataFrameStringIndexing.time_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "265aab9816591b0620d3f729f705598419ec9b26e32927a7fa1a5c4c87630b97",
        "warmup_time": -1
    },
    "indexing.DatetimeIndexIndexing.time_get_indexer_mismatched_tz": {
        "code": "class DatetimeIndexIndexing:\n    def time_get_indexer_mismatched_tz(self):\n        # reached via e.g.\n        #  ser = Series(range(len(dti)), index=dti)\n        #  ser[dti2]\n        self.dti.get_indexer(self.dti2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndexIndexing:\n    def setup(self):\n        dti = date_range(\"2016-01-01\", periods=10000, tz=\"US/Pacific\")\n        dti2 = dti.tz_convert(\"UTC\")\n        self.dti = dti\n        self.dti2 = dti2",
        "min_run_count": 2,
        "name": "indexing.DatetimeIndexIndexing.time_get_indexer_mismatched_tz",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c9cf20755eb4a51e544f3173086738738b06c2840acdc00a8c905a951594ce03",
        "warmup_time": -1
    },
    "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int": {
        "code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_int(self):\n        self.df_int_col[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=[\"A\"])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))",
        "min_run_count": 2,
        "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8516566e6a549f1f7c5a48623aa1378d299f882af8c200a8ab04eb7d321f0a23",
        "warmup_time": -1
    },
    "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label": {
        "code": "class GetItemSingleColumn:\n    def time_frame_getitem_single_column_label(self):\n        self.df_string_col[\"A\"]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItemSingleColumn:\n    def setup(self):\n        self.df_string_col = DataFrame(np.random.randn(3000, 1), columns=[\"A\"])\n        self.df_int_col = DataFrame(np.random.randn(3000, 1))",
        "min_run_count": 2,
        "name": "indexing.GetItemSingleColumn.time_frame_getitem_single_column_label",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a03a82b5117e7c2d6cccfe8ac22ef652a2ac9b039e27f15814a7bfab97c94f00",
        "warmup_time": -1
    },
    "indexing.IndexSingleRow.time_iloc_row": {
        "code": "class IndexSingleRow:\n    def time_iloc_row(self, unique_cols):\n        self.df.iloc[10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexSingleRow:\n    def setup(self, unique_cols):\n        arr = np.arange(10 ** 7).reshape(-1, 10)\n        df = DataFrame(arr)\n        dtypes = [\"u1\", \"u2\", \"u4\", \"u8\", \"i1\", \"i2\", \"i4\", \"i8\", \"f8\", \"f4\"]\n        for i, d in enumerate(dtypes):\n            df[i] = df[i].astype(d)\n    \n        if not unique_cols:\n            # GH#33032 single-row lookups with non-unique columns were\n            #  15x slower than with unique columns\n            df.columns = [\"A\", \"A\"] + list(df.columns[2:])\n    \n        self.df = df",
        "min_run_count": 2,
        "name": "indexing.IndexSingleRow.time_iloc_row",
        "number": 0,
        "param_names": [
            "unique_cols"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7ed07218c992ea3cedb1b109fcc129cc3580f25476e7fceb902b4747cce2b24e",
        "warmup_time": -1
    },
    "indexing.IndexSingleRow.time_loc_row": {
        "code": "class IndexSingleRow:\n    def time_loc_row(self, unique_cols):\n        self.df.loc[10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IndexSingleRow:\n    def setup(self, unique_cols):\n        arr = np.arange(10 ** 7).reshape(-1, 10)\n        df = DataFrame(arr)\n        dtypes = [\"u1\", \"u2\", \"u4\", \"u8\", \"i1\", \"i2\", \"i4\", \"i8\", \"f8\", \"f4\"]\n        for i, d in enumerate(dtypes):\n            df[i] = df[i].astype(d)\n    \n        if not unique_cols:\n            # GH#33032 single-row lookups with non-unique columns were\n            #  15x slower than with unique columns\n            df.columns = [\"A\", \"A\"] + list(df.columns[2:])\n    \n        self.df = df",
        "min_run_count": 2,
        "name": "indexing.IndexSingleRow.time_loc_row",
        "number": 0,
        "param_names": [
            "unique_cols"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "971e8e84fbd6a573d242b3f5dd6d1e346c3a0b6ba4ce1045dcc86f5760269025",
        "warmup_time": -1
    },
    "indexing.InsertColumns.time_assign_list_like_with_setitem": {
        "code": "class InsertColumns:\n    def time_assign_list_like_with_setitem(self):\n        self.df[list(range(100))] = np.random.randn(self.N, 100)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10 ** 3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))",
        "min_run_count": 2,
        "name": "indexing.InsertColumns.time_assign_list_like_with_setitem",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f0d20ae0b7ecbf875b6212af9100e57c2d7a858d5391e0335ad66af6913bbf27",
        "warmup_time": -1
    },
    "indexing.InsertColumns.time_assign_list_of_columns_concat": {
        "code": "class InsertColumns:\n    def time_assign_list_of_columns_concat(self):\n        df = DataFrame(np.random.randn(self.N, 100))\n        concat([self.df, df], axis=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10 ** 3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))",
        "min_run_count": 2,
        "name": "indexing.InsertColumns.time_assign_list_of_columns_concat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6488498fda2f541b42e29ae2312eb8b360958157a907be27ddf5b34c0161a937",
        "warmup_time": -1
    },
    "indexing.InsertColumns.time_assign_with_setitem": {
        "code": "class InsertColumns:\n    def time_assign_with_setitem(self):\n        for i in range(100):\n            self.df[i] = np.random.randn(self.N)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10 ** 3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))",
        "min_run_count": 2,
        "name": "indexing.InsertColumns.time_assign_with_setitem",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d9df947877603c72bff457f468a97b02417e92607d132780d6b770f71ccd5508",
        "warmup_time": -1
    },
    "indexing.InsertColumns.time_insert": {
        "code": "class InsertColumns:\n    def time_insert(self):\n        for i in range(100):\n            self.df.insert(0, i, np.random.randn(self.N), allow_duplicates=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10 ** 3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))",
        "min_run_count": 2,
        "name": "indexing.InsertColumns.time_insert",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c675f1a116c9426fda23d329fa7028edc751ccc723eb90e0ac0a9fd5737d1e9e",
        "warmup_time": -1
    },
    "indexing.InsertColumns.time_insert_middle": {
        "code": "class InsertColumns:\n    def time_insert_middle(self):\n        # same as time_insert but inserting to a middle column rather than\n        #  front or back (which have fast-paths)\n        for i in range(100):\n            self.df2.insert(\n                1, \"colname\", np.random.randn(self.N), allow_duplicates=True\n            )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InsertColumns:\n    def setup(self):\n        self.N = 10 ** 3\n        self.df = DataFrame(index=range(self.N))\n        self.df2 = DataFrame(np.random.randn(self.N, 2))",
        "min_run_count": 2,
        "name": "indexing.InsertColumns.time_insert_middle",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0682502ad9f0ccf074a147a9f6d4babd27f606e4ad4c6293f39973b96af77470",
        "warmup_time": -1
    },
    "indexing.IntervalIndexing.time_getitem_list": {
        "code": "class IntervalIndexing:\n    def time_getitem_list(self, monotonic):\n        monotonic[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic",
        "min_run_count": 2,
        "name": "indexing.IntervalIndexing.time_getitem_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "indexing:228",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ae80a330a1a4becae8c369fe9bcb0c8f430beb2d8ac3986f5e2f82490c50e071",
        "warmup_time": -1
    },
    "indexing.IntervalIndexing.time_getitem_scalar": {
        "code": "class IntervalIndexing:\n    def time_getitem_scalar(self, monotonic):\n        monotonic[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic",
        "min_run_count": 2,
        "name": "indexing.IntervalIndexing.time_getitem_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "indexing:228",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f160eaae3bf3bcbcc3fd20357b12c28670839282da6644be0e8024f97b21204b",
        "warmup_time": -1
    },
    "indexing.IntervalIndexing.time_loc_list": {
        "code": "class IntervalIndexing:\n    def time_loc_list(self, monotonic):\n        monotonic.loc[80000:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic",
        "min_run_count": 2,
        "name": "indexing.IntervalIndexing.time_loc_list",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "indexing:228",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "634735f3995a5c9be2542706652ca9d8a024f91ded9a8e3ec8653b176bb9c556",
        "warmup_time": -1
    },
    "indexing.IntervalIndexing.time_loc_scalar": {
        "code": "class IntervalIndexing:\n    def time_loc_scalar(self, monotonic):\n        monotonic.loc[80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass IntervalIndexing:\n    def setup_cache(self):\n        idx = IntervalIndex.from_breaks(np.arange(1000001))\n        monotonic = Series(np.arange(1000000), index=idx)\n        return monotonic",
        "min_run_count": 2,
        "name": "indexing.IntervalIndexing.time_loc_scalar",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "indexing:228",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9682c17d993a421023a33cdfbf1ae6a67d4f2b1a8a9eb98fb60445f56f4d892e",
        "warmup_time": -1
    },
    "indexing.MethodLookup.time_lookup_iloc": {
        "code": "class MethodLookup:\n    def time_lookup_iloc(self, s):\n        s.iloc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s",
        "min_run_count": 2,
        "name": "indexing.MethodLookup.time_lookup_iloc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "indexing:307",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "de130c1315ebaff60daa5132a0ffba11a1513d688c4d7465c4f0b75fa3b40d4d",
        "warmup_time": -1
    },
    "indexing.MethodLookup.time_lookup_loc": {
        "code": "class MethodLookup:\n    def time_lookup_loc(self, s):\n        s.loc\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MethodLookup:\n    def setup_cache(self):\n        s = Series()\n        return s",
        "min_run_count": 2,
        "name": "indexing.MethodLookup.time_lookup_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "indexing:307",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8f3e9ba1fa6ae32795b77d4fb0a2cb3a36108a494ac5a33197076f41a75cee6c",
        "warmup_time": -1
    },
    "indexing.MultiIndexing.time_index_slice": {
        "code": "class MultiIndexing:\n    def time_index_slice(self):\n        self.mdt.loc[self.idx, :]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MultiIndexing:\n    def setup(self):\n        mi = MultiIndex.from_product([range(1000), range(1000)])\n        self.s = Series(np.random.randn(1000000), index=mi)\n        self.df = DataFrame(self.s)\n    \n        n = 100000\n        with warnings.catch_warnings(record=True):\n            self.mdt = DataFrame(\n                {\n                    \"A\": np.random.choice(range(10000, 45000, 1000), n),\n                    \"B\": np.random.choice(range(10, 400), n),\n                    \"C\": np.random.choice(range(1, 150), n),\n                    \"D\": np.random.choice(range(10000, 45000), n),\n                    \"x\": np.random.choice(range(400), n),\n                    \"y\": np.random.choice(range(25), n),\n                }\n            )\n        self.idx = IndexSlice[20000:30000, 20:30, 35:45, 30000:40000]\n        self.mdt = self.mdt.set_index([\"A\", \"B\", \"C\", \"D\"]).sort_index()",
        "min_run_count": 2,
        "name": "indexing.MultiIndexing.time_index_slice",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c196b75df07e5c8d4a3488406f718ea25e957eb6f2bf0af131e006defa58becb",
        "warmup_time": -1
    },
    "indexing.NonNumericSeriesIndexing.time_getitem_label_slice": {
        "code": "class NonNumericSeriesIndexing:\n    def time_getitem_label_slice(self, index, index_structure):\n        self.s[: self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]",
        "min_run_count": 2,
        "name": "indexing.NonNumericSeriesIndexing.time_getitem_label_slice",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "'string'",
                "'datetime'",
                "'period'"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eb7c31c3494d3a8de85b5e27da2c746b2121e00a640aa373ee6b2b2831f028e7",
        "warmup_time": -1
    },
    "indexing.NonNumericSeriesIndexing.time_getitem_list_like": {
        "code": "class NonNumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.s[[self.lbl]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]",
        "min_run_count": 2,
        "name": "indexing.NonNumericSeriesIndexing.time_getitem_list_like",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "'string'",
                "'datetime'",
                "'period'"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1ec16e127fd343ec78fb56e4d6edc0f47f5646dd76f6d8ee836b0f3d9acb9e2a",
        "warmup_time": -1
    },
    "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice": {
        "code": "class NonNumericSeriesIndexing:\n    def time_getitem_pos_slice(self, index, index_structure):\n        self.s[:80000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]",
        "min_run_count": 2,
        "name": "indexing.NonNumericSeriesIndexing.time_getitem_pos_slice",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "'string'",
                "'datetime'",
                "'period'"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "537ff797463f114c99beb30c73e93cf694b2d390bc3584938f42b37def703d93",
        "warmup_time": -1
    },
    "indexing.NonNumericSeriesIndexing.time_getitem_scalar": {
        "code": "class NonNumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.s[self.lbl]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NonNumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        if index == \"string\":\n            index = tm.makeStringIndex(N)\n        elif index == \"datetime\":\n            index = date_range(\"1900\", periods=N, freq=\"s\")\n        elif index == \"period\":\n            index = period_range(\"1900\", periods=N, freq=\"s\")\n        index = index.sort_values()\n        assert index.is_unique and index.is_monotonic_increasing\n        if index_structure == \"nonunique_monotonic_inc\":\n            index = index.insert(item=index[2], loc=2)[:-1]\n        elif index_structure == \"non_monotonic\":\n            index = index[::2].append(index[1::2])\n            assert len(index) == N\n        self.s = Series(np.random.rand(N), index=index)\n        self.lbl = index[80000]\n        # warm up index mapping\n        self.s[self.lbl]",
        "min_run_count": 2,
        "name": "indexing.NonNumericSeriesIndexing.time_getitem_scalar",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "'string'",
                "'datetime'",
                "'period'"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "11bd494cdfd90b9b1090e4eb5587c824f063da1344f5112043a6caa9e1dd786d",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_getitem_array": {
        "code": "class NumericSeriesIndexing:\n    def time_getitem_array(self, index, index_structure):\n        self.data[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_getitem_array",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'pandas.core.indexes.numeric.Int64Index'>",
                "<class 'pandas.core.indexes.numeric.UInt64Index'>",
                "<class 'pandas.core.indexes.numeric.Float64Index'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "77b9127d2d682aeb06a7c92d485f73d3e92a1d0c25807ae096fd326645e39056",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_getitem_list_like": {
        "code": "class NumericSeriesIndexing:\n    def time_getitem_list_like(self, index, index_structure):\n        self.data[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_getitem_list_like",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'pandas.core.indexes.numeric.Int64Index'>",
                "<class 'pandas.core.indexes.numeric.UInt64Index'>",
                "<class 'pandas.core.indexes.numeric.Float64Index'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f8e37095435d821079b740199f475e8cbd47ca1fe0001ab23250ace420c03655",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_getitem_lists": {
        "code": "class NumericSeriesIndexing:\n    def time_getitem_lists(self, index, index_structure):\n        self.data[self.array_list]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_getitem_lists",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'pandas.core.indexes.numeric.Int64Index'>",
                "<class 'pandas.core.indexes.numeric.UInt64Index'>",
                "<class 'pandas.core.indexes.numeric.Float64Index'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8f1517197693913854e3b0cb8d6218c432c709d7940948c9ca27aa8b8f559696",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_getitem_scalar": {
        "code": "class NumericSeriesIndexing:\n    def time_getitem_scalar(self, index, index_structure):\n        self.data[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_getitem_scalar",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'pandas.core.indexes.numeric.Int64Index'>",
                "<class 'pandas.core.indexes.numeric.UInt64Index'>",
                "<class 'pandas.core.indexes.numeric.Float64Index'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1343f6259c35b93da7907f754f409f52834255bfd66f1ae9b8584f0a1abbabc6",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_getitem_slice": {
        "code": "class NumericSeriesIndexing:\n    def time_getitem_slice(self, index, index_structure):\n        self.data[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_getitem_slice",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'pandas.core.indexes.numeric.Int64Index'>",
                "<class 'pandas.core.indexes.numeric.UInt64Index'>",
                "<class 'pandas.core.indexes.numeric.Float64Index'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1a781acc9b491a86260023d36bca1895c83ff1d79e28d7ed91efd2cfde6f9903",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_iloc_array": {
        "code": "class NumericSeriesIndexing:\n    def time_iloc_array(self, index, index_structure):\n        self.data.iloc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_iloc_array",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'pandas.core.indexes.numeric.Int64Index'>",
                "<class 'pandas.core.indexes.numeric.UInt64Index'>",
                "<class 'pandas.core.indexes.numeric.Float64Index'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "378604259c6cd2a9a45e2f3cf873bfaa6c1750f3067d6fb1acf78ed790e3806d",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_iloc_list_like": {
        "code": "class NumericSeriesIndexing:\n    def time_iloc_list_like(self, index, index_structure):\n        self.data.iloc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_iloc_list_like",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'pandas.core.indexes.numeric.Int64Index'>",
                "<class 'pandas.core.indexes.numeric.UInt64Index'>",
                "<class 'pandas.core.indexes.numeric.Float64Index'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "65e176c5f9a18ba75babd0469a8fc8bab38511dded47836e64a458a7a5adb70e",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_iloc_scalar": {
        "code": "class NumericSeriesIndexing:\n    def time_iloc_scalar(self, index, index_structure):\n        self.data.iloc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_iloc_scalar",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'pandas.core.indexes.numeric.Int64Index'>",
                "<class 'pandas.core.indexes.numeric.UInt64Index'>",
                "<class 'pandas.core.indexes.numeric.Float64Index'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "36c6da9a494a23e24965cae7ac630fbda4685f006039b4f742d3629c2711f1c3",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_iloc_slice": {
        "code": "class NumericSeriesIndexing:\n    def time_iloc_slice(self, index, index_structure):\n        self.data.iloc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_iloc_slice",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'pandas.core.indexes.numeric.Int64Index'>",
                "<class 'pandas.core.indexes.numeric.UInt64Index'>",
                "<class 'pandas.core.indexes.numeric.Float64Index'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "610b98ee410cd2c4afbd06f09646188860748e7949fa023aefe13fe46245579d",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_loc_array": {
        "code": "class NumericSeriesIndexing:\n    def time_loc_array(self, index, index_structure):\n        self.data.loc[self.array]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_loc_array",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'pandas.core.indexes.numeric.Int64Index'>",
                "<class 'pandas.core.indexes.numeric.UInt64Index'>",
                "<class 'pandas.core.indexes.numeric.Float64Index'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "49f6173e5e54f37ab17a1a012feeb68cbbd9e29254b07ca9380d2427d261c3ac",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_loc_list_like": {
        "code": "class NumericSeriesIndexing:\n    def time_loc_list_like(self, index, index_structure):\n        self.data.loc[[800000]]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_loc_list_like",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'pandas.core.indexes.numeric.Int64Index'>",
                "<class 'pandas.core.indexes.numeric.UInt64Index'>",
                "<class 'pandas.core.indexes.numeric.Float64Index'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f7d2327865b6beb9c9b578f295abeae6860c73e8c64b27e2f6e085153b5fb55e",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_loc_scalar": {
        "code": "class NumericSeriesIndexing:\n    def time_loc_scalar(self, index, index_structure):\n        self.data.loc[800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_loc_scalar",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'pandas.core.indexes.numeric.Int64Index'>",
                "<class 'pandas.core.indexes.numeric.UInt64Index'>",
                "<class 'pandas.core.indexes.numeric.Float64Index'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "38308681a480fa47e62206aeebcec5a94044528ecd22d1fbb0712730696d262f",
        "warmup_time": -1
    },
    "indexing.NumericSeriesIndexing.time_loc_slice": {
        "code": "class NumericSeriesIndexing:\n    def time_loc_slice(self, index, index_structure):\n        self.data.loc[:800000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NumericSeriesIndexing:\n    def setup(self, index, index_structure):\n        N = 10 ** 6\n        indices = {\n            \"unique_monotonic_inc\": index(range(N)),\n            \"nonunique_monotonic_inc\": index(\n                list(range(55)) + [54] + list(range(55, N - 1))\n            ),\n        }\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\n        self.array = np.arange(10000)\n        self.array_list = self.array.tolist()",
        "min_run_count": 2,
        "name": "indexing.NumericSeriesIndexing.time_loc_slice",
        "number": 0,
        "param_names": [
            "index_dtype",
            "index_structure"
        ],
        "params": [
            [
                "<class 'pandas.core.indexes.numeric.Int64Index'>",
                "<class 'pandas.core.indexes.numeric.UInt64Index'>",
                "<class 'pandas.core.indexes.numeric.Float64Index'>"
            ],
            [
                "'unique_monotonic_inc'",
                "'nonunique_monotonic_inc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a895c9452d52fa5232868b7fb5f24fd0a7076b5086805a7467045327f3ce9b77",
        "warmup_time": -1
    },
    "indexing.Take.time_take": {
        "code": "class Take:\n    def time_take(self, index):\n        self.s.take(self.indexer)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Take:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": Int64Index(np.arange(N)),\n            \"datetime\": date_range(\"2011-01-01\", freq=\"S\", periods=N),\n        }\n        index = indexes[index]\n        self.s = Series(np.random.rand(N), index=index)\n        self.indexer = np.random.randint(0, N, size=N)",
        "min_run_count": 2,
        "name": "indexing.Take.time_take",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "19dac0e09f08f496c7a6e58ae1abddb856e28a8bc4023c834e94143cf27ab53e",
        "warmup_time": -1
    },
    "indexing_engines.NumericEngineIndexing.time_get_loc": {
        "code": "class NumericEngineIndexing:\n    def time_get_loc(self, engine_and_dtype, index_type, unique, N):\n        self.data.get_loc(self.key_early)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                values = list([1] * N + [2] * N + [3] * N)\n                arr = np.array(values, dtype=dtype)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                values = list([1] * N + [2] * N + [3] * N)\n                arr = np.array(values, dtype=dtype)[::-1]\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.empty(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3] * N, dtype=dtype)\n    \n        self.data = engine(arr)\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]",
        "min_run_count": 2,
        "name": "indexing_engines.NumericEngineIndexing.time_get_loc",
        "number": 0,
        "param_names": [
            "engine_and_dtype",
            "index_type",
            "unique",
            "N"
        ],
        "params": [
            [
                "(<class 'pandas._libs.index.Int64Engine'>, <class 'numpy.int64'>)",
                "(<class 'pandas._libs.index.Int32Engine'>, <class 'numpy.int32'>)",
                "(<class 'pandas._libs.index.Int16Engine'>, <class 'numpy.int16'>)",
                "(<class 'pandas._libs.index.Int8Engine'>, <class 'numpy.int8'>)",
                "(<class 'pandas._libs.index.UInt64Engine'>, <class 'numpy.uint64'>)",
                "(<class 'pandas._libs.index.UInt32Engine'>, <class 'numpy.uint32'>)",
                "(<class 'pandas._libs.index.UInt8Engine'>, <class 'numpy.uint8'>)",
                "(<class 'pandas._libs.index.Float64Engine'>, <class 'numpy.float64'>)",
                "(<class 'pandas._libs.index.Float32Engine'>, <class 'numpy.float32'>)"
            ],
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ],
            [
                "True",
                "False"
            ],
            [
                "100000",
                "2000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eb49cbbf223b552f13727c50a1e3742ad38791c4b24c9d9b3c7dff9d456b637b",
        "warmup_time": -1
    },
    "indexing_engines.NumericEngineIndexing.time_get_loc_near_middle": {
        "code": "class NumericEngineIndexing:\n    def time_get_loc_near_middle(self, engine_and_dtype, index_type, unique, N):\n        # searchsorted performance may be different near the middle of a range\n        #  vs near an endpoint\n        self.data.get_loc(self.key_middle)\n\n    def setup(self, engine_and_dtype, index_type, unique, N):\n        engine, dtype = engine_and_dtype\n    \n        if index_type == \"monotonic_incr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)\n            else:\n                values = list([1] * N + [2] * N + [3] * N)\n                arr = np.array(values, dtype=dtype)\n        elif index_type == \"monotonic_decr\":\n            if unique:\n                arr = np.arange(N * 3, dtype=dtype)[::-1]\n            else:\n                values = list([1] * N + [2] * N + [3] * N)\n                arr = np.array(values, dtype=dtype)[::-1]\n        else:\n            assert index_type == \"non_monotonic\"\n            if unique:\n                arr = np.empty(N * 3, dtype=dtype)\n                arr[:N] = np.arange(N * 2, N * 3, dtype=dtype)\n                arr[N:] = np.arange(N * 2, dtype=dtype)\n            else:\n                arr = np.array([1, 2, 3] * N, dtype=dtype)\n    \n        self.data = engine(arr)\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(2)\n    \n        self.key_middle = arr[len(arr) // 2]\n        self.key_early = arr[2]",
        "min_run_count": 2,
        "name": "indexing_engines.NumericEngineIndexing.time_get_loc_near_middle",
        "number": 0,
        "param_names": [
            "engine_and_dtype",
            "index_type",
            "unique",
            "N"
        ],
        "params": [
            [
                "(<class 'pandas._libs.index.Int64Engine'>, <class 'numpy.int64'>)",
                "(<class 'pandas._libs.index.Int32Engine'>, <class 'numpy.int32'>)",
                "(<class 'pandas._libs.index.Int16Engine'>, <class 'numpy.int16'>)",
                "(<class 'pandas._libs.index.Int8Engine'>, <class 'numpy.int8'>)",
                "(<class 'pandas._libs.index.UInt64Engine'>, <class 'numpy.uint64'>)",
                "(<class 'pandas._libs.index.UInt32Engine'>, <class 'numpy.uint32'>)",
                "(<class 'pandas._libs.index.UInt8Engine'>, <class 'numpy.uint8'>)",
                "(<class 'pandas._libs.index.Float64Engine'>, <class 'numpy.float64'>)",
                "(<class 'pandas._libs.index.Float32Engine'>, <class 'numpy.float32'>)"
            ],
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ],
            [
                "True",
                "False"
            ],
            [
                "100000",
                "2000000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6bd3ade508d6db6ef376f66c545a8ca5531e1ed703ece1938476702134c89ccb",
        "warmup_time": -1
    },
    "indexing_engines.ObjectEngineIndexing.time_get_loc": {
        "code": "class ObjectEngineIndexing:\n    def time_get_loc(self, index_type):\n        self.data.get_loc(\"b\")\n\n    def setup(self, index_type):\n        N = 10 ** 5\n        values = list(\"a\" * N + \"b\" * N + \"c\" * N)\n        arr = {\n            \"monotonic_incr\": np.array(values, dtype=object),\n            \"monotonic_decr\": np.array(list(reversed(values)), dtype=object),\n            \"non_monotonic\": np.array(list(\"abc\") * N, dtype=object),\n        }[index_type]\n    \n        self.data = libindex.ObjectEngine(arr)\n        # code belows avoids populating the mapping etc. while timing.\n        self.data.get_loc(\"b\")",
        "min_run_count": 2,
        "name": "indexing_engines.ObjectEngineIndexing.time_get_loc",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'monotonic_incr'",
                "'monotonic_decr'",
                "'non_monotonic'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7de453d18b237449a1eb98cd6485628661e7f3695d081c49e923e0539f7652af",
        "warmup_time": -1
    },
    "inference.MaybeConvertNumeric.time_convert": {
        "code": "class MaybeConvertNumeric:\n    def time_convert(self, data):\n        lib.maybe_convert_numeric(data, set(), coerce_numeric=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaybeConvertNumeric:\n    def setup_cache(self):\n        N = 10 ** 6\n        arr = np.repeat([2 ** 63], N) + np.arange(N).astype(\"uint64\")\n        data = arr.astype(object)\n        data[1::2] = arr[1::2].astype(str)\n        data[-1] = -1\n        return data",
        "min_run_count": 2,
        "name": "inference.MaybeConvertNumeric.time_convert",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "inference:87",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5288ed11236fea5c06dcca4e538e99c7b855b90981f39928b73be1b769f36698",
        "warmup_time": -1
    },
    "inference.MaybeConvertObjects.time_maybe_convert_objects": {
        "code": "class MaybeConvertObjects:\n    def time_maybe_convert_objects(self):\n        lib.maybe_convert_objects(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MaybeConvertObjects:\n    def setup(self):\n        N = 10 ** 5\n    \n        data = list(range(N))\n        data[0] = NaT\n        data = np.array(data)\n        self.data = data",
        "min_run_count": 2,
        "name": "inference.MaybeConvertObjects.time_maybe_convert_objects",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fa813d126ab732b2ade8643a792e8df846728df23f4a264addea924e3aae00ce",
        "warmup_time": -1
    },
    "inference.ToDatetimeCache.time_dup_seconds_and_unit": {
        "code": "class ToDatetimeCache:\n    def time_dup_seconds_and_unit(self, cache):\n        to_datetime(self.dup_numeric_seconds, unit=\"s\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N",
        "min_run_count": 2,
        "name": "inference.ToDatetimeCache.time_dup_seconds_and_unit",
        "number": 0,
        "param_names": [
            "cache"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "115495d011e90c1e84334a047f0989bfb9edee09d9a3180f0c98d9d55a4f5d9e",
        "warmup_time": -1
    },
    "inference.ToDatetimeCache.time_dup_string_dates": {
        "code": "class ToDatetimeCache:\n    def time_dup_string_dates(self, cache):\n        to_datetime(self.dup_string_dates, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N",
        "min_run_count": 2,
        "name": "inference.ToDatetimeCache.time_dup_string_dates",
        "number": 0,
        "param_names": [
            "cache"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "98daac9ccb43e22cad7edf108a8f9ef3f7dfbf2eb8deb23ea7df594845b8af4c",
        "warmup_time": -1
    },
    "inference.ToDatetimeCache.time_dup_string_dates_and_format": {
        "code": "class ToDatetimeCache:\n    def time_dup_string_dates_and_format(self, cache):\n        to_datetime(self.dup_string_dates, format=\"%Y-%m-%d\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N",
        "min_run_count": 2,
        "name": "inference.ToDatetimeCache.time_dup_string_dates_and_format",
        "number": 0,
        "param_names": [
            "cache"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ee70077e5420259875c0f2299f011187d7baaef6f1cdeb4826b8ef8b1552dbce",
        "warmup_time": -1
    },
    "inference.ToDatetimeCache.time_dup_string_tzoffset_dates": {
        "code": "class ToDatetimeCache:\n    def time_dup_string_tzoffset_dates(self, cache):\n        to_datetime(self.dup_string_with_tz, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N",
        "min_run_count": 2,
        "name": "inference.ToDatetimeCache.time_dup_string_tzoffset_dates",
        "number": 0,
        "param_names": [
            "cache"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9e31f01ac2515ecaf953530ced77a145692dd110a116641738e36e284fe36dd6",
        "warmup_time": -1
    },
    "inference.ToDatetimeCache.time_unique_seconds_and_unit": {
        "code": "class ToDatetimeCache:\n    def time_unique_seconds_and_unit(self, cache):\n        to_datetime(self.unique_numeric_seconds, unit=\"s\", cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCache:\n    def setup(self, cache):\n        N = 10000\n        self.unique_numeric_seconds = list(range(N))\n        self.dup_numeric_seconds = [1000] * N\n        self.dup_string_dates = [\"2000-02-11\"] * N\n        self.dup_string_with_tz = [\"2000-02-11 15:00:00-0800\"] * N",
        "min_run_count": 2,
        "name": "inference.ToDatetimeCache.time_unique_seconds_and_unit",
        "number": 0,
        "param_names": [
            "cache"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0cd72e287b8884f32a7696a5bae419aa06c002232f3f3e5644000bec0a231d7c",
        "warmup_time": -1
    },
    "inference.ToDatetimeCacheSmallCount.time_unique_date_strings": {
        "code": "class ToDatetimeCacheSmallCount:\n    def time_unique_date_strings(self, cache, count):\n        to_datetime(self.unique_date_strings, cache=cache)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeCacheSmallCount:\n    def setup(self, cache, count):\n        rng = date_range(start=\"1/1/1971\", periods=count)\n        self.unique_date_strings = rng.strftime(\"%Y-%m-%d\").tolist()",
        "min_run_count": 2,
        "name": "inference.ToDatetimeCacheSmallCount.time_unique_date_strings",
        "number": 0,
        "param_names": [
            "cache",
            "count"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "50",
                "500",
                "5000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a56323da170a0fe1ab82a8aa298f38bf720a11efd9c5e53816e754fbfa0d2c10",
        "warmup_time": -1
    },
    "inference.ToDatetimeFormat.time_different_offset": {
        "code": "class ToDatetimeFormat:\n    def time_different_offset(self):\n        to_datetime(self.diff_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\")\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFormat.time_different_offset",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4196fd26caa9c6787f80e55ade21d6847fb0229d6b310f8e56df101f18f5720e",
        "warmup_time": -1
    },
    "inference.ToDatetimeFormat.time_different_offset_to_utc": {
        "code": "class ToDatetimeFormat:\n    def time_different_offset_to_utc(self):\n        to_datetime(self.diff_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\", utc=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\")\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFormat.time_different_offset_to_utc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b8691d4fe7628d9f96eafc079ffffa2334fdd3921ed76e663d06bcd35dafae56",
        "warmup_time": -1
    },
    "inference.ToDatetimeFormat.time_exact": {
        "code": "class ToDatetimeFormat:\n    def time_exact(self):\n        to_datetime(self.s2, format=\"%d%b%y\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\")\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFormat.time_exact",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5a1168596eab837562b57e5a7a4d9410353df9b3e4cb2012f1cff263287fe6a5",
        "warmup_time": -1
    },
    "inference.ToDatetimeFormat.time_no_exact": {
        "code": "class ToDatetimeFormat:\n    def time_no_exact(self):\n        to_datetime(self.s, format=\"%d%b%y\", exact=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\")\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFormat.time_no_exact",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6183cf7ee5b523d88f2564ca3c471a792fdd42d4c5d21f4e6343f6f85ce587b5",
        "warmup_time": -1
    },
    "inference.ToDatetimeFormat.time_same_offset": {
        "code": "class ToDatetimeFormat:\n    def time_same_offset(self):\n        to_datetime(self.same_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\")\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFormat.time_same_offset",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0669ea24b7d4d97de7b4a97be069486d2f300f55974b46d08533f38e987bf848",
        "warmup_time": -1
    },
    "inference.ToDatetimeFormat.time_same_offset_to_utc": {
        "code": "class ToDatetimeFormat:\n    def time_same_offset_to_utc(self):\n        to_datetime(self.same_offset, format=\"%m/%d/%Y %H:%M:%S.%f%z\", utc=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormat:\n    def setup(self):\n        N = 100000\n        self.s = Series([\"19MAY11\", \"19MAY11:00:00:00\"] * N)\n        self.s2 = self.s.str.replace(\":\\\\S+$\", \"\")\n    \n        self.same_offset = [\"10/11/2018 00:00:00.045-07:00\"] * N\n        self.diff_offset = [\n            f\"10/11/2018 00:00:00.045-0{offset}:00\" for offset in range(10)\n        ] * (N // 10)",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFormat.time_same_offset_to_utc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3f6f03b6cd2f59c862a59a785bc81fa040c5f726136af55aadbba6af73a11231",
        "warmup_time": -1
    },
    "inference.ToDatetimeFormatQuarters.time_infer_quarter": {
        "code": "class ToDatetimeFormatQuarters:\n    def time_infer_quarter(self):\n        to_datetime(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFormatQuarters:\n    def setup(self):\n        self.s = Series([\"2Q2005\", \"2Q05\", \"2005Q1\", \"05Q1\"] * 10000)",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFormatQuarters.time_infer_quarter",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "87bb6a74eb91c588ca3c6a25551ece61b8b7585eb61f04410973d650e0964120",
        "warmup_time": -1
    },
    "inference.ToDatetimeFromIntsFloats.time_nanosec_float64": {
        "code": "class ToDatetimeFromIntsFloats:\n    def time_nanosec_float64(self):\n        to_datetime(self.ts_nanosec_float, unit=\"ns\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFromIntsFloats.time_nanosec_float64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2a6fbb3b51b828848e8d7f73b076d8fae1161c6e4d53f48a8c4524fb4bd1820e",
        "warmup_time": -1
    },
    "inference.ToDatetimeFromIntsFloats.time_nanosec_int64": {
        "code": "class ToDatetimeFromIntsFloats:\n    def time_nanosec_int64(self):\n        to_datetime(self.ts_nanosec, unit=\"ns\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFromIntsFloats.time_nanosec_int64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8970f8a6a15aef3813dcea5bb9bf3a7c39853f92d88c59907ac2830fd16daef2",
        "warmup_time": -1
    },
    "inference.ToDatetimeFromIntsFloats.time_nanosec_uint64": {
        "code": "class ToDatetimeFromIntsFloats:\n    def time_nanosec_uint64(self):\n        to_datetime(self.ts_nanosec_uint, unit=\"ns\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFromIntsFloats.time_nanosec_uint64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "55b37560ce70ea683ab6134ede09ee43de470162b68416ec0ef8b0f469e90e97",
        "warmup_time": -1
    },
    "inference.ToDatetimeFromIntsFloats.time_sec_float64": {
        "code": "class ToDatetimeFromIntsFloats:\n    def time_sec_float64(self):\n        to_datetime(self.ts_sec_float, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFromIntsFloats.time_sec_float64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "412960192629b47bdb51536bd1acc465c6644d94331ec0b060809f15f2270d21",
        "warmup_time": -1
    },
    "inference.ToDatetimeFromIntsFloats.time_sec_int64": {
        "code": "class ToDatetimeFromIntsFloats:\n    def time_sec_int64(self):\n        to_datetime(self.ts_sec, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFromIntsFloats.time_sec_int64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "723bef42790ad2535ae6772086a189690bbc81c0dc720a9ae78f79b14541e1ed",
        "warmup_time": -1
    },
    "inference.ToDatetimeFromIntsFloats.time_sec_uint64": {
        "code": "class ToDatetimeFromIntsFloats:\n    def time_sec_uint64(self):\n        to_datetime(self.ts_sec_uint, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeFromIntsFloats:\n    def setup(self):\n        self.ts_sec = Series(range(1521080307, 1521685107), dtype=\"int64\")\n        self.ts_sec_uint = Series(range(1521080307, 1521685107), dtype=\"uint64\")\n        self.ts_sec_float = self.ts_sec.astype(\"float64\")\n    \n        self.ts_nanosec = 1_000_000 * self.ts_sec\n        self.ts_nanosec_uint = 1_000_000 * self.ts_sec_uint\n        self.ts_nanosec_float = self.ts_nanosec.astype(\"float64\")",
        "min_run_count": 2,
        "name": "inference.ToDatetimeFromIntsFloats.time_sec_uint64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ca17f492874efa6d87297d7a5eb649d9b0235ba934649a093f70ea48bc399454",
        "warmup_time": -1
    },
    "inference.ToDatetimeISO8601.time_iso8601": {
        "code": "class ToDatetimeISO8601:\n    def time_iso8601(self):\n        to_datetime(self.strings)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]",
        "min_run_count": 2,
        "name": "inference.ToDatetimeISO8601.time_iso8601",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8a9f5fa8618dda5ec7d3fcacc7ea1b91b2f812dea4716f11e58bc0a3e893b194",
        "warmup_time": -1
    },
    "inference.ToDatetimeISO8601.time_iso8601_format": {
        "code": "class ToDatetimeISO8601:\n    def time_iso8601_format(self):\n        to_datetime(self.strings, format=\"%Y-%m-%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]",
        "min_run_count": 2,
        "name": "inference.ToDatetimeISO8601.time_iso8601_format",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d9b6d05dcef0bd9a57b30f88e40cba877d5d3a456d585869ad724c9cd7778691",
        "warmup_time": -1
    },
    "inference.ToDatetimeISO8601.time_iso8601_format_no_sep": {
        "code": "class ToDatetimeISO8601:\n    def time_iso8601_format_no_sep(self):\n        to_datetime(self.strings_nosep, format=\"%Y%m%d %H:%M:%S\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]",
        "min_run_count": 2,
        "name": "inference.ToDatetimeISO8601.time_iso8601_format_no_sep",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "90328a5ba99082bbb0b5759492dd90d4b20174a908bf8eb53038490d589931ff",
        "warmup_time": -1
    },
    "inference.ToDatetimeISO8601.time_iso8601_infer_zero_tz_fromat": {
        "code": "class ToDatetimeISO8601:\n    def time_iso8601_infer_zero_tz_fromat(self):\n        # GH 41047\n        to_datetime(self.strings_zero_tz, infer_datetime_format=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]",
        "min_run_count": 2,
        "name": "inference.ToDatetimeISO8601.time_iso8601_infer_zero_tz_fromat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "18d1b84037f1590dcd9949420496153dbb1ff9b74e8baaa7190b5db5b69e47cb",
        "warmup_time": -1
    },
    "inference.ToDatetimeISO8601.time_iso8601_nosep": {
        "code": "class ToDatetimeISO8601:\n    def time_iso8601_nosep(self):\n        to_datetime(self.strings_nosep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]",
        "min_run_count": 2,
        "name": "inference.ToDatetimeISO8601.time_iso8601_nosep",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "75bb85aabdd375a3bca428f0e741a086e63ddeedd898c59144432029585d0bf2",
        "warmup_time": -1
    },
    "inference.ToDatetimeISO8601.time_iso8601_tz_spaceformat": {
        "code": "class ToDatetimeISO8601:\n    def time_iso8601_tz_spaceformat(self):\n        to_datetime(self.strings_tz_space)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeISO8601:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=20000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()\n        self.strings_nosep = rng.strftime(\"%Y%m%d %H:%M:%S\").tolist()\n        self.strings_tz_space = [\n            x.strftime(\"%Y-%m-%d %H:%M:%S\") + \" -0800\" for x in rng\n        ]\n        self.strings_zero_tz = [x.strftime(\"%Y-%m-%d %H:%M:%S\") + \"Z\" for x in rng]",
        "min_run_count": 2,
        "name": "inference.ToDatetimeISO8601.time_iso8601_tz_spaceformat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ffda3795a72b4023991d1daa18e3b0a3cabffd330b369a59c89a7d6c8d190102",
        "warmup_time": -1
    },
    "inference.ToDatetimeInferDatetimeFormat.time_infer_datetime_format": {
        "code": "class ToDatetimeInferDatetimeFormat:\n    def time_infer_datetime_format(self):\n        to_datetime(self.strings, infer_datetime_format=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeInferDatetimeFormat:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=100000, freq=\"H\")\n        self.strings = rng.strftime(\"%Y-%m-%d %H:%M:%S\").tolist()",
        "min_run_count": 2,
        "name": "inference.ToDatetimeInferDatetimeFormat.time_infer_datetime_format",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1c3c74ed99381261b9280915b0699af46b2fa2fd04caecf83328d1bc6eabf06e",
        "warmup_time": -1
    },
    "inference.ToDatetimeNONISO8601.time_different_offset": {
        "code": "class ToDatetimeNONISO8601:\n    def time_different_offset(self):\n        to_datetime(self.diff_offset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = N // 2\n        ts_string_1 = \"March 1, 2018 12:00:00+0400\"\n        ts_string_2 = \"March 1, 2018 12:00:00+0500\"\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half",
        "min_run_count": 2,
        "name": "inference.ToDatetimeNONISO8601.time_different_offset",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2e0c92a1d5e9a354637aa8cc2832b3bc010f1197d796dc79ef3f026a0281060f",
        "warmup_time": -1
    },
    "inference.ToDatetimeNONISO8601.time_same_offset": {
        "code": "class ToDatetimeNONISO8601:\n    def time_same_offset(self):\n        to_datetime(self.same_offset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeNONISO8601:\n    def setup(self):\n        N = 10000\n        half = N // 2\n        ts_string_1 = \"March 1, 2018 12:00:00+0400\"\n        ts_string_2 = \"March 1, 2018 12:00:00+0500\"\n        self.same_offset = [ts_string_1] * N\n        self.diff_offset = [ts_string_1] * half + [ts_string_2] * half",
        "min_run_count": 2,
        "name": "inference.ToDatetimeNONISO8601.time_same_offset",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f4cfe5cc89ed121e911be978f375ccb3976e7f6b8bc0e40ffd649e75abf676dc",
        "warmup_time": -1
    },
    "inference.ToDatetimeYYYYMMDD.time_format_YYYYMMDD": {
        "code": "class ToDatetimeYYYYMMDD:\n    def time_format_YYYYMMDD(self):\n        to_datetime(self.stringsD, format=\"%Y%m%d\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToDatetimeYYYYMMDD:\n    def setup(self):\n        rng = date_range(start=\"1/1/2000\", periods=10000, freq=\"D\")\n        self.stringsD = Series(rng.strftime(\"%Y%m%d\"))",
        "min_run_count": 2,
        "name": "inference.ToDatetimeYYYYMMDD.time_format_YYYYMMDD",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1231af2c8acd673f7622a4a5cda34d3f69371a14c6d712e970653093e409349a",
        "warmup_time": -1
    },
    "inference.ToNumeric.time_from_float": {
        "code": "class ToNumeric:\n    def time_from_float(self, errors):\n        to_numeric(self.float, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(tm.makeStringIndex(N))",
        "min_run_count": 2,
        "name": "inference.ToNumeric.time_from_float",
        "number": 0,
        "param_names": [
            "errors"
        ],
        "params": [
            [
                "'ignore'",
                "'coerce'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "142e0697d61aecf684621de53345634c6889754a1fe765627387e7212dbfb7e6",
        "warmup_time": -1
    },
    "inference.ToNumeric.time_from_numeric_str": {
        "code": "class ToNumeric:\n    def time_from_numeric_str(self, errors):\n        to_numeric(self.numstr, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(tm.makeStringIndex(N))",
        "min_run_count": 2,
        "name": "inference.ToNumeric.time_from_numeric_str",
        "number": 0,
        "param_names": [
            "errors"
        ],
        "params": [
            [
                "'ignore'",
                "'coerce'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2827b0fccbdea4148c6ddc140ffd204887ec86edcf4b006884d3250ade25e619",
        "warmup_time": -1
    },
    "inference.ToNumeric.time_from_str": {
        "code": "class ToNumeric:\n    def time_from_str(self, errors):\n        to_numeric(self.str, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumeric:\n    def setup(self, errors):\n        N = 10000\n        self.float = Series(np.random.randn(N))\n        self.numstr = self.float.astype(\"str\")\n        self.str = Series(tm.makeStringIndex(N))",
        "min_run_count": 2,
        "name": "inference.ToNumeric.time_from_str",
        "number": 0,
        "param_names": [
            "errors"
        ],
        "params": [
            [
                "'ignore'",
                "'coerce'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "898a2f79d432c9bd2b285b7d3c97441d282b380c9aa9105bd7f057afa3f10267",
        "warmup_time": -1
    },
    "inference.ToNumericDowncast.time_downcast": {
        "code": "class ToNumericDowncast:\n    def time_downcast(self, dtype, downcast):\n        to_numeric(self.data, downcast=downcast)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToNumericDowncast:\n    def setup(self, dtype, downcast):\n        self.data = self.data_dict[dtype]",
        "min_run_count": 2,
        "name": "inference.ToNumericDowncast.time_downcast",
        "number": 0,
        "param_names": [
            "dtype",
            "downcast"
        ],
        "params": [
            [
                "'string-float'",
                "'string-int'",
                "'string-nint'",
                "'datetime64'",
                "'int-list'",
                "'int32'"
            ],
            [
                "None",
                "'integer'",
                "'signed'",
                "'unsigned'",
                "'float'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0c056f48d7870e4188d6e5d83b2fae5d416f447632d4ee4e9e8c1ccec4b933bc",
        "warmup_time": -1
    },
    "inference.ToTimedelta.time_convert_int": {
        "code": "class ToTimedelta:\n    def time_convert_int(self):\n        to_timedelta(self.ints, unit=\"s\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedelta:\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")",
        "min_run_count": 2,
        "name": "inference.ToTimedelta.time_convert_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e3d32b170c7865f14153be4d1dfe4cedbbfa407716af9b931a20cbf2be09aa76",
        "warmup_time": -1
    },
    "inference.ToTimedelta.time_convert_string_days": {
        "code": "class ToTimedelta:\n    def time_convert_string_days(self):\n        to_timedelta(self.str_days)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedelta:\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")",
        "min_run_count": 2,
        "name": "inference.ToTimedelta.time_convert_string_days",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b10b9c32557f6894a8d5cdad6099b33d92453d78580ed6ac9bce54eeda6ac731",
        "warmup_time": -1
    },
    "inference.ToTimedelta.time_convert_string_seconds": {
        "code": "class ToTimedelta:\n    def time_convert_string_seconds(self):\n        to_timedelta(self.str_seconds)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedelta:\n    def setup(self):\n        self.ints = np.random.randint(0, 60, size=10000)\n        self.str_days = []\n        self.str_seconds = []\n        for i in self.ints:\n            self.str_days.append(f\"{i} days\")\n            self.str_seconds.append(f\"00:00:{i:02d}\")",
        "min_run_count": 2,
        "name": "inference.ToTimedelta.time_convert_string_seconds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ab0555d598557f0386f6743a49658aed686a61742a1a10086b99506a9dc533ba",
        "warmup_time": -1
    },
    "inference.ToTimedeltaErrors.time_convert": {
        "code": "class ToTimedeltaErrors:\n    def time_convert(self, errors):\n        to_timedelta(self.arr, errors=errors)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToTimedeltaErrors:\n    def setup(self, errors):\n        ints = np.random.randint(0, 60, size=10000)\n        self.arr = [f\"{i} days\" for i in ints]\n        self.arr[-1] = \"apple\"",
        "min_run_count": 2,
        "name": "inference.ToTimedeltaErrors.time_convert",
        "number": 0,
        "param_names": [
            "errors"
        ],
        "params": [
            [
                "'coerce'",
                "'ignore'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8a1b83205aea85d9e2d96e4303cdb083f3815f1959f3dee5f921a8668cb54c13",
        "warmup_time": -1
    },
    "io.csv.ParseDateComparison.time_read_csv_dayfirst": {
        "code": "class ParseDateComparison:\n    def time_read_csv_dayfirst(self, cache_dates):\n        try:\n            read_csv(\n                self.data(self.StringIO_input),\n                sep=\",\",\n                header=None,\n                names=[\"Date\"],\n                parse_dates=[\"Date\"],\n                cache_dates=cache_dates,\n                dayfirst=True,\n            )\n        except TypeError:\n            # cache_dates is a new keyword in 0.25\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ParseDateComparison.time_read_csv_dayfirst",
        "number": 0,
        "param_names": [
            "cache_dates"
        ],
        "params": [
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b531fbcabfa9f50a40159c707fc3c7f6e7b08d581c7b1d7a345041defb16e66f",
        "warmup_time": -1
    },
    "io.csv.ParseDateComparison.time_to_datetime_dayfirst": {
        "code": "class ParseDateComparison:\n    def time_to_datetime_dayfirst(self, cache_dates):\n        df = read_csv(\n            self.data(self.StringIO_input), dtype={\"date\": str}, names=[\"date\"]\n        )\n        to_datetime(df[\"date\"], cache=cache_dates, dayfirst=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ParseDateComparison.time_to_datetime_dayfirst",
        "number": 0,
        "param_names": [
            "cache_dates"
        ],
        "params": [
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "50d96a36fe567c997d3c1a6fbd696fe9705f2ea698a08554aa84d41cd77fcd4d",
        "warmup_time": -1
    },
    "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY": {
        "code": "class ParseDateComparison:\n    def time_to_datetime_format_DD_MM_YYYY(self, cache_dates):\n        df = read_csv(\n            self.data(self.StringIO_input), dtype={\"date\": str}, names=[\"date\"]\n        )\n        to_datetime(df[\"date\"], cache=cache_dates, format=\"%d-%m-%Y\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ParseDateComparison:\n    def setup(self, cache_dates):\n        count_elem = 10000\n        data = \"12-02-2010\\n\" * count_elem\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ParseDateComparison.time_to_datetime_format_DD_MM_YYYY",
        "number": 0,
        "param_names": [
            "cache_dates"
        ],
        "params": [
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "22583c40b98481bf789be587a51186ee7ff145dc4fb7e8e302872d06333449c9",
        "warmup_time": -1
    },
    "io.csv.ReadCSVCachedParseDates.time_read_csv_cached": {
        "code": "class ReadCSVCachedParseDates:\n    def time_read_csv_cached(self, do_cache, engine):\n        try:\n            read_csv(\n                self.data(self.StringIO_input),\n                engine=engine,\n                header=None,\n                parse_dates=[0],\n                cache_dates=do_cache,\n            )\n        except TypeError:\n            # cache_dates is a new keyword in 0.25\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCachedParseDates:\n    def setup(self, do_cache, engine):\n        data = (\"\\n\".join([f\"10/{year}\" for year in range(2000, 2100)]) + \"\\n\") * 10\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVCachedParseDates.time_read_csv_cached",
        "number": 0,
        "param_names": [
            "do_cache",
            "engine"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'c'",
                "'python'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bd18017d7e35c75b5b8e7641eba13970add0683431db08d765c8d0c218e4a37d",
        "warmup_time": -1
    },
    "io.csv.ReadCSVCategorical.time_convert_direct": {
        "code": "class ReadCSVCategorical:\n    def time_convert_direct(self, engine):\n        read_csv(self.fname, engine=engine, dtype=\"category\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self, engine):\n        N = 100000\n        group1 = [\"aaaaaaaa\", \"bbbbbbb\", \"cccccccc\", \"dddddddd\", \"eeeeeeee\"]\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list(\"abc\"))\n        df.to_csv(self.fname, index=False)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVCategorical.time_convert_direct",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b2e9577b100c6272d45c9326e6ae5cc423be2a61cded554dcded5c3f443ab3d3",
        "warmup_time": -1
    },
    "io.csv.ReadCSVCategorical.time_convert_post": {
        "code": "class ReadCSVCategorical:\n    def time_convert_post(self, engine):\n        read_csv(self.fname, engine=engine).apply(Categorical)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVCategorical:\n    def setup(self, engine):\n        N = 100000\n        group1 = [\"aaaaaaaa\", \"bbbbbbb\", \"cccccccc\", \"dddddddd\", \"eeeeeeee\"]\n        df = DataFrame(np.random.choice(group1, (N, 3)), columns=list(\"abc\"))\n        df.to_csv(self.fname, index=False)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVCategorical.time_convert_post",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b7f42a0fff0e3f819147a800861b2f3c3bfe6ed2893ab8f978bbc88396a2df45",
        "warmup_time": -1
    },
    "io.csv.ReadCSVComment.time_comment": {
        "code": "class ReadCSVComment:\n    def time_comment(self, engine):\n        read_csv(\n            self.data(self.StringIO_input), comment=\"#\", header=None, names=list(\"abc\")\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVComment:\n    def setup(self, engine):\n        data = [\"A,B,C\"] + ([\"1,2,3 # comment\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVComment.time_comment",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a90bbb38eb91ba9eeed032776bd52d7fd80b20ac0f6bc97853a821d08e98cf4b",
        "warmup_time": -1
    },
    "io.csv.ReadCSVConcatDatetime.time_read_csv": {
        "code": "class ReadCSVConcatDatetime:\n    def time_read_csv(self):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\"],\n            parse_dates=[\"foo\"],\n            infer_datetime_format=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetime:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", periods=50000, freq=\"S\")\n        self.StringIO_input = StringIO(\"\\n\".join(rng.strftime(self.iso8601).tolist()))",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVConcatDatetime.time_read_csv",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "04f965ce10ce6bb060584a73051bd6b6062404a406007706d3a43f7f967b672f",
        "warmup_time": -1
    },
    "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv": {
        "code": "class ReadCSVConcatDatetimeBadDateValue:\n    def time_read_csv(self, bad_date_value):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\", \"bar\"],\n            parse_dates=[\"foo\"],\n            infer_datetime_format=False,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVConcatDatetimeBadDateValue:\n    def setup(self, bad_date_value):\n        self.StringIO_input = StringIO((f\"{bad_date_value},\\n\") * 50000)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVConcatDatetimeBadDateValue.time_read_csv",
        "number": 0,
        "param_names": [
            "bad_date_value"
        ],
        "params": [
            [
                "'nan'",
                "'0'",
                "''"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d1a989645a6825f45d9917dc9594da101d94ea1ee2f584f6453e42462e20cc2c",
        "warmup_time": -1
    },
    "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv": {
        "code": "class ReadCSVDInferDatetimeFormat:\n    def time_read_csv(self, infer_datetime_format, format):\n        read_csv(\n            self.data(self.StringIO_input),\n            header=None,\n            names=[\"foo\"],\n            parse_dates=[\"foo\"],\n            infer_datetime_format=infer_datetime_format,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVDInferDatetimeFormat:\n    def setup(self, infer_datetime_format, format):\n        rng = date_range(\"1/1/2000\", periods=1000)\n        formats = {\n            \"custom\": \"%m/%d/%Y %H:%M:%S.%f\",\n            \"iso8601\": \"%Y-%m-%d %H:%M:%S\",\n            \"ymd\": \"%Y%m%d\",\n        }\n        dt_format = formats[format]\n        self.StringIO_input = StringIO(\"\\n\".join(rng.strftime(dt_format).tolist()))",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVDInferDatetimeFormat.time_read_csv",
        "number": 0,
        "param_names": [
            "infer_datetime_format",
            "format"
        ],
        "params": [
            [
                "True",
                "False"
            ],
            [
                "'custom'",
                "'iso8601'",
                "'ymd'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1d766c56889753f724932473cc56dfbb33553878406369271322e8a6d1a04d74",
        "warmup_time": -1
    },
    "io.csv.ReadCSVEngine.time_read_bytescsv": {
        "code": "class ReadCSVEngine:\n    def time_read_bytescsv(self, engine):\n        read_csv(self.data(self.BytesIO_input), engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVEngine:\n    def setup(self, engine):\n        data = [\"A,B,C,D,E\"] + ([\"1,2,3,4,5\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))\n        # simulate reading from file\n        self.BytesIO_input = BytesIO(self.StringIO_input.read().encode(\"utf-8\"))",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVEngine.time_read_bytescsv",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'",
                "'pyarrow'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c55db1629ca6d2b9c2cc35edb1684bf28f0a642354365378b739990b2beb3b36",
        "warmup_time": -1
    },
    "io.csv.ReadCSVEngine.time_read_stringcsv": {
        "code": "class ReadCSVEngine:\n    def time_read_stringcsv(self, engine):\n        read_csv(self.data(self.StringIO_input), engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVEngine:\n    def setup(self, engine):\n        data = [\"A,B,C,D,E\"] + ([\"1,2,3,4,5\"] * 100000)\n        self.StringIO_input = StringIO(\"\\n\".join(data))\n        # simulate reading from file\n        self.BytesIO_input = BytesIO(self.StringIO_input.read().encode(\"utf-8\"))",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVEngine.time_read_stringcsv",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'",
                "'pyarrow'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bcd2541e7d01564732b9ee7d1a6eb25bc0640eba5345d2109c242f2887344d0b",
        "warmup_time": -1
    },
    "io.csv.ReadCSVFloatPrecision.time_read_csv": {
        "code": "class ReadCSVFloatPrecision:\n    def time_read_csv(self, sep, decimal, float_precision):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=sep,\n            header=None,\n            names=list(\"abc\"),\n            float_precision=float_precision,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [\n            \"\".join([random.choice(string.digits) for _ in range(28)])\n            for _ in range(15)\n        ]\n        rows = sep.join([f\"0{decimal}\" + \"{}\"] * 3) + \"\\n\"\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVFloatPrecision.time_read_csv",
        "number": 0,
        "param_names": [
            "sep",
            "decimal",
            "float_precision"
        ],
        "params": [
            [
                "','",
                "';'"
            ],
            [
                "'.'",
                "'_'"
            ],
            [
                "None",
                "'high'",
                "'round_trip'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7ca927092b74728897ae3b2d4d298f95b4afdd520b90b95c43ec758041e8b229",
        "warmup_time": -1
    },
    "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine": {
        "code": "class ReadCSVFloatPrecision:\n    def time_read_csv_python_engine(self, sep, decimal, float_precision):\n        read_csv(\n            self.data(self.StringIO_input),\n            sep=sep,\n            header=None,\n            engine=\"python\",\n            float_precision=None,\n            names=list(\"abc\"),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVFloatPrecision:\n    def setup(self, sep, decimal, float_precision):\n        floats = [\n            \"\".join([random.choice(string.digits) for _ in range(28)])\n            for _ in range(15)\n        ]\n        rows = sep.join([f\"0{decimal}\" + \"{}\"] * 3) + \"\\n\"\n        data = rows * 5\n        data = data.format(*floats) * 200  # 1000 x 3 strings csv\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVFloatPrecision.time_read_csv_python_engine",
        "number": 0,
        "param_names": [
            "sep",
            "decimal",
            "float_precision"
        ],
        "params": [
            [
                "','",
                "';'"
            ],
            [
                "'.'",
                "'_'"
            ],
            [
                "None",
                "'high'",
                "'round_trip'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fe3fa17b401e13d8d7fb9cb246219140f2f15d26b7591c5c2720dbbae5869e48",
        "warmup_time": -1
    },
    "io.csv.ReadCSVMemMapUTF8.time_read_memmapped_utf8": {
        "code": "class ReadCSVMemMapUTF8:\n    def time_read_memmapped_utf8(self):\n        read_csv(self.fname, header=None, memory_map=True, encoding=\"utf-8\", engine=\"c\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVMemMapUTF8:\n    def setup(self):\n        lines = []\n        line_length = 128\n        start_char = \" \"\n        end_char = \"\\U00010080\"\n        # This for loop creates a list of 128-char strings\n        # consisting of consecutive Unicode chars\n        for lnum in range(ord(start_char), ord(end_char), line_length):\n            line = \"\".join([chr(c) for c in range(lnum, lnum + 0x80)]) + \"\\n\"\n            try:\n                line.encode(\"utf-8\")\n            except UnicodeEncodeError:\n                # Some 16-bit words are not valid Unicode chars and must be skipped\n                continue\n            lines.append(line)\n        df = DataFrame(lines)\n        df = concat([df for n in range(100)], ignore_index=True)\n        df.to_csv(self.fname, index=False, header=False, encoding=\"utf-8\")",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVMemMapUTF8.time_read_memmapped_utf8",
        "number": 5,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "28f7fd520f718e3d43c75304bfe758d8db2e0e48f9ecbcc93c96af3d09bb34c5",
        "warmup_time": -1
    },
    "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks": {
        "code": "class ReadCSVMemoryGrowth:\n    def mem_parser_chunks(self, engine):\n        # see gh-24805.\n        result = read_csv(self.fname, chunksize=self.chunksize, engine=engine)\n    \n        for _ in result:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVMemoryGrowth:\n    def setup(self, engine):\n        with open(self.fname, \"w\") as f:\n            for i in range(self.num_rows):\n                f.write(f\"{i}\\n\")",
        "name": "io.csv.ReadCSVMemoryGrowth.mem_parser_chunks",
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'"
            ]
        ],
        "timeout": 60.0,
        "type": "memory",
        "unit": "bytes",
        "version": "5b8828ad6997b8f5dd29b23caf71b20bc6f89ff1813e5ed7dd7eec0aed97be9c"
    },
    "io.csv.ReadCSVParseDates.time_baseline": {
        "code": "class ReadCSVParseDates:\n    def time_baseline(self, engine):\n        read_csv(\n            self.data(self.StringIO_input),\n            engine=engine,\n            sep=\",\",\n            header=None,\n            parse_dates=[1],\n            names=list(string.digits[:9]),\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseDates:\n    def setup(self, engine):\n        data = \"\"\"{},19:00:00,18:56:00,0.8100,2.8100,7.2000,0.0000,280.0000\\n\n                  {},20:00:00,19:56:00,0.0100,2.2100,7.2000,0.0000,260.0000\\n\n                  {},21:00:00,20:56:00,-0.5900,2.2100,5.7000,0.0000,280.0000\\n\n                  {},21:00:00,21:18:00,-0.9900,2.0100,3.6000,0.0000,270.0000\\n\n                  {},22:00:00,21:56:00,-0.5900,1.7100,5.1000,0.0000,290.0000\\n\n               \"\"\"\n        two_cols = [\"KORD,19990127\"] * 5\n        data = data.format(*two_cols)\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVParseDates.time_baseline",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "221a4700fd1f02faac09f891ec2ff4bf841f4f8838d4912b40bd070ce1747d0d",
        "warmup_time": -1
    },
    "io.csv.ReadCSVParseDates.time_multiple_date": {
        "code": "class ReadCSVParseDates:\n    def time_multiple_date(self, engine):\n        read_csv(\n            self.data(self.StringIO_input),\n            engine=engine,\n            sep=\",\",\n            header=None,\n            names=list(string.digits[:9]),\n            parse_dates=[[1, 2], [1, 3]],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseDates:\n    def setup(self, engine):\n        data = \"\"\"{},19:00:00,18:56:00,0.8100,2.8100,7.2000,0.0000,280.0000\\n\n                  {},20:00:00,19:56:00,0.0100,2.2100,7.2000,0.0000,260.0000\\n\n                  {},21:00:00,20:56:00,-0.5900,2.2100,5.7000,0.0000,280.0000\\n\n                  {},21:00:00,21:18:00,-0.9900,2.0100,3.6000,0.0000,270.0000\\n\n                  {},22:00:00,21:56:00,-0.5900,1.7100,5.1000,0.0000,290.0000\\n\n               \"\"\"\n        two_cols = [\"KORD,19990127\"] * 5\n        data = data.format(*two_cols)\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVParseDates.time_multiple_date",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'c'",
                "'python'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ddee417fe3a4e78483aae8d5f9fdc3e5fc75fd2257354f3445f110295eca8b93",
        "warmup_time": -1
    },
    "io.csv.ReadCSVParseSpecialDate.time_read_special_date": {
        "code": "class ReadCSVParseSpecialDate:\n    def time_read_special_date(self, value, engine):\n        read_csv(\n            self.data(self.StringIO_input),\n            engine=engine,\n            sep=\",\",\n            header=None,\n            names=[\"Date\"],\n            parse_dates=[\"Date\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVParseSpecialDate:\n    def setup(self, value, engine):\n        count_elem = 10000\n        data = self.objects[value] * count_elem\n        self.StringIO_input = StringIO(data)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVParseSpecialDate.time_read_special_date",
        "number": 0,
        "param_names": [
            "value",
            "engine"
        ],
        "params": [
            [
                "'mY'",
                "'mdY'",
                "'hm'"
            ],
            [
                "'c'",
                "'python'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4adfa495cb5b837ceef161540601f8b0378f4433acbcd79ec36d1936f32b0276",
        "warmup_time": -1
    },
    "io.csv.ReadCSVSkipRows.time_skipprows": {
        "code": "class ReadCSVSkipRows:\n    def time_skipprows(self, skiprows, engine):\n        read_csv(self.fname, skiprows=skiprows, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVSkipRows:\n    def setup(self, skiprows, engine):\n        N = 20000\n        index = tm.makeStringIndex(N)\n        df = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        df.to_csv(self.fname)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVSkipRows.time_skipprows",
        "number": 0,
        "param_names": [
            "skiprows",
            "engine"
        ],
        "params": [
            [
                "None",
                "10000"
            ],
            [
                "'c'",
                "'python'",
                "'pyarrow'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0dc6d0e8c8764ff0b22a12464e38e2e562d4aae0a4bd527e7a3f5a13303a37e6",
        "warmup_time": -1
    },
    "io.csv.ReadCSVThousands.time_thousands": {
        "code": "class ReadCSVThousands:\n    def time_thousands(self, sep, thousands, engine):\n        read_csv(self.fname, sep=sep, thousands=thousands, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadCSVThousands:\n    def setup(self, sep, thousands, engine):\n        N = 10000\n        K = 8\n        data = np.random.randn(N, K) * np.random.randint(100, 10000, (N, K))\n        df = DataFrame(data)\n        if thousands is not None:\n            fmt = f\":{thousands}\"\n            fmt = \"{\" + fmt + \"}\"\n            df = df.applymap(lambda x: fmt.format(x))\n        df.to_csv(self.fname, sep=sep)",
        "min_run_count": 2,
        "name": "io.csv.ReadCSVThousands.time_thousands",
        "number": 0,
        "param_names": [
            "sep",
            "thousands",
            "engine"
        ],
        "params": [
            [
                "','",
                "'|'"
            ],
            [
                "None",
                "','"
            ],
            [
                "'c'",
                "'python'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "30e186d86b00baebda491c2da633cb23873955f9b445b05c0eca0e91d7e724e5",
        "warmup_time": -1
    },
    "io.csv.ReadUint64Integers.time_read_uint64": {
        "code": "class ReadUint64Integers:\n    def time_read_uint64(self):\n        read_csv(self.data(self.data1), header=None, names=[\"foo\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2 ** 63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2 ** 63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))",
        "min_run_count": 2,
        "name": "io.csv.ReadUint64Integers.time_read_uint64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d31caf610ca9a9ae47be68989378f5136f1152b1921a6145b22ac441fd3f9578",
        "warmup_time": -1
    },
    "io.csv.ReadUint64Integers.time_read_uint64_na_values": {
        "code": "class ReadUint64Integers:\n    def time_read_uint64_na_values(self):\n        read_csv(\n            self.data(self.data1), header=None, names=[\"foo\"], na_values=self.na_values\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2 ** 63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2 ** 63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))",
        "min_run_count": 2,
        "name": "io.csv.ReadUint64Integers.time_read_uint64_na_values",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9a89a386a253764968164aae6e278e5ad27d72c8651b2dd6c33788d23b855ea1",
        "warmup_time": -1
    },
    "io.csv.ReadUint64Integers.time_read_uint64_neg_values": {
        "code": "class ReadUint64Integers:\n    def time_read_uint64_neg_values(self):\n        read_csv(self.data(self.data2), header=None, names=[\"foo\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadUint64Integers:\n    def setup(self):\n        self.na_values = [2 ** 63 + 500]\n        arr = np.arange(10000).astype(\"uint64\") + 2 ** 63\n        self.data1 = StringIO(\"\\n\".join(arr.astype(str).tolist()))\n        arr = arr.astype(object)\n        arr[500] = -1\n        self.data2 = StringIO(\"\\n\".join(arr.astype(str).tolist()))",
        "min_run_count": 2,
        "name": "io.csv.ReadUint64Integers.time_read_uint64_neg_values",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c7c5a6f1c5c162b594e74ded052f2beba0ae2477aa7dc6f0d6928ef0ee79cca3",
        "warmup_time": -1
    },
    "io.csv.ToCSV.time_frame": {
        "code": "class ToCSV:\n    def time_frame(self, kind):\n        self.df.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSV:\n    def setup(self, kind):\n        wide_frame = DataFrame(np.random.randn(3000, 30))\n        long_frame = DataFrame(\n            {\n                \"A\": np.arange(50000),\n                \"B\": np.arange(50000) + 1.0,\n                \"C\": np.arange(50000) + 2.0,\n                \"D\": np.arange(50000) + 3.0,\n            }\n        )\n        mixed_frame = DataFrame(\n            {\n                \"float\": np.random.randn(5000),\n                \"int\": np.random.randn(5000).astype(int),\n                \"bool\": (np.arange(5000) % 2) == 0,\n                \"datetime\": date_range(\"2001\", freq=\"s\", periods=5000),\n                \"object\": [\"foo\"] * 5000,\n            }\n        )\n        mixed_frame.loc[30:500, \"float\"] = np.nan\n        data = {\"wide\": wide_frame, \"long\": long_frame, \"mixed\": mixed_frame}\n        self.df = data[kind]",
        "min_run_count": 2,
        "name": "io.csv.ToCSV.time_frame",
        "number": 0,
        "param_names": [
            "kind"
        ],
        "params": [
            [
                "'wide'",
                "'long'",
                "'mixed'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b207acadf1f9b5992775d04050e8e1c95f5b672a69adc5ea1bb47fac8c558b49",
        "warmup_time": -1
    },
    "io.csv.ToCSVDatetime.time_frame_date_formatting": {
        "code": "class ToCSVDatetime:\n    def time_frame_date_formatting(self):\n        self.data.to_csv(self.fname, date_format=\"%Y%m%d\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetime:\n    def setup(self):\n        rng = date_range(\"1/1/2000\", periods=1000)\n        self.data = DataFrame(rng, index=rng)",
        "min_run_count": 2,
        "name": "io.csv.ToCSVDatetime.time_frame_date_formatting",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "48aec9f413466587de05eec973105aa3ca66fba9830fc6165228f306cfa384d0",
        "warmup_time": -1
    },
    "io.csv.ToCSVDatetimeBig.time_frame": {
        "code": "class ToCSVDatetimeBig:\n    def time_frame(self, obs):\n        self.data.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVDatetimeBig:\n    def setup(self, obs):\n        d = \"2018-11-29\"\n        dt = \"2018-11-26 11:18:27.0\"\n        self.data = DataFrame(\n            {\n                \"dt\": [np.datetime64(dt)] * obs,\n                \"d\": [np.datetime64(d)] * obs,\n                \"r\": [np.random.uniform()] * obs,\n            }\n        )",
        "min_run_count": 2,
        "name": "io.csv.ToCSVDatetimeBig.time_frame",
        "number": 0,
        "param_names": [
            "obs"
        ],
        "params": [
            [
                "1000",
                "10000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 1500,
        "type": "time",
        "unit": "seconds",
        "version": "0af424429330b78d982d95d3db7345e25c98dd6bf7bb45459cc961052ef01e3d",
        "warmup_time": -1
    },
    "io.csv.ToCSVIndexes.time_head_of_multiindex": {
        "code": "class ToCSVIndexes:\n    def time_head_of_multiindex(self):\n        self.df_custom_index_then_head.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVIndexes:\n    def setup(self):\n        ROWS = 100000\n        COLS = 5\n        # For tests using .head(), create an initial dataframe with this many times\n        # more rows\n        HEAD_ROW_MULTIPLIER = 10\n    \n        self.df_standard_index = self._create_df(ROWS, COLS)\n    \n        self.df_custom_index_then_head = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n            .head(ROWS)\n        )\n    \n        self.df_head_then_custom_index = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .head(ROWS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n        )",
        "min_run_count": 2,
        "name": "io.csv.ToCSVIndexes.time_head_of_multiindex",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b19bd98ca4e016f0e4a61cb075ab765fe428f49a7a406dd786bf37617833558c",
        "warmup_time": -1
    },
    "io.csv.ToCSVIndexes.time_multiindex": {
        "code": "class ToCSVIndexes:\n    def time_multiindex(self):\n        self.df_head_then_custom_index.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVIndexes:\n    def setup(self):\n        ROWS = 100000\n        COLS = 5\n        # For tests using .head(), create an initial dataframe with this many times\n        # more rows\n        HEAD_ROW_MULTIPLIER = 10\n    \n        self.df_standard_index = self._create_df(ROWS, COLS)\n    \n        self.df_custom_index_then_head = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n            .head(ROWS)\n        )\n    \n        self.df_head_then_custom_index = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .head(ROWS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n        )",
        "min_run_count": 2,
        "name": "io.csv.ToCSVIndexes.time_multiindex",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e6c356ab53559b97134b83598c7406d7849f7d72f0cd33999f3ed3a1388ae70b",
        "warmup_time": -1
    },
    "io.csv.ToCSVIndexes.time_standard_index": {
        "code": "class ToCSVIndexes:\n    def time_standard_index(self):\n        self.df_standard_index.to_csv(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCSVIndexes:\n    def setup(self):\n        ROWS = 100000\n        COLS = 5\n        # For tests using .head(), create an initial dataframe with this many times\n        # more rows\n        HEAD_ROW_MULTIPLIER = 10\n    \n        self.df_standard_index = self._create_df(ROWS, COLS)\n    \n        self.df_custom_index_then_head = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n            .head(ROWS)\n        )\n    \n        self.df_head_then_custom_index = (\n            self._create_df(ROWS * HEAD_ROW_MULTIPLIER, COLS)\n            .head(ROWS)\n            .set_index([\"index1\", \"index2\", \"index3\"])\n        )",
        "min_run_count": 2,
        "name": "io.csv.ToCSVIndexes.time_standard_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4d8e112a392acdd1a4bdd4008abb8a96e5e23ac65da30366feda0363459f118b",
        "warmup_time": -1
    },
    "io.excel.ReadExcel.time_read_excel": {
        "code": "class ReadExcel:\n    def time_read_excel(self, engine):\n        if engine == \"xlrd\":\n            fname = self.fname_excel_xls\n        elif engine == \"odf\":\n            fname = self.fname_odf\n        else:\n            fname = self.fname_excel\n        read_excel(fname, engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadExcel:\n    def setup_cache(self):\n        self.df = _generate_dataframe()\n    \n        self.df.to_excel(self.fname_excel, sheet_name=\"Sheet1\")\n        self.df.to_excel(self.fname_excel_xls, sheet_name=\"Sheet1\")\n        self._create_odf()",
        "min_run_count": 2,
        "name": "io.excel.ReadExcel.time_read_excel",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'xlrd'",
                "'openpyxl'",
                "'odf'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.excel:72",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a3165bac17f8a50a37282b2d97bf441c609c143a0d6ea7919490259ecdc28488",
        "warmup_time": -1
    },
    "io.excel.WriteExcel.time_write_excel": {
        "code": "class WriteExcel:\n    def time_write_excel(self, engine):\n        bio = BytesIO()\n        bio.seek(0)\n        writer = ExcelWriter(bio, engine=engine)\n        self.df.to_excel(writer, sheet_name=\"Sheet1\")\n        writer.save()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteExcel:\n    def setup(self, engine):\n        self.df = _generate_dataframe()",
        "min_run_count": 2,
        "name": "io.excel.WriteExcel.time_write_excel",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'openpyxl'",
                "'xlsxwriter'",
                "'xlwt'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "78760f97b6f549795dc281fffa62f9907eba040c36d81370627db090e2ec5807",
        "warmup_time": -1
    },
    "io.hdf.HDF.time_read_hdf": {
        "code": "class HDF:\n    def time_read_hdf(self, format):\n        read_hdf(self.fname, \"df\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_hdf(self.fname, \"df\", format=format)",
        "min_run_count": 2,
        "name": "io.hdf.HDF.time_read_hdf",
        "number": 0,
        "param_names": [
            "format"
        ],
        "params": [
            [
                "'table'",
                "'fixed'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "49cd21bd77339dabf37d66948aeaa32be9bc08da2d6a2b5b3e9c1831457b530d",
        "warmup_time": -1
    },
    "io.hdf.HDF.time_write_hdf": {
        "code": "class HDF:\n    def time_write_hdf(self, format):\n        self.df.to_hdf(self.fname, \"df\", format=format)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDF:\n    def setup(self, format):\n        self.fname = \"__test__.h5\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_hdf(self.fname, \"df\", format=format)",
        "min_run_count": 2,
        "name": "io.hdf.HDF.time_write_hdf",
        "number": 0,
        "param_names": [
            "format"
        ],
        "params": [
            [
                "'table'",
                "'fixed'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f468c0ada67cdcd3b710c865e8361b8ad4df1ac7626c74ac846d5f353a5a8734",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_query_store_table": {
        "code": "class HDFStoreDataFrame:\n    def time_query_store_table(self):\n        self.store.select(\"table\", where=\"index > self.start and index < self.stop\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_query_store_table",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e5817534b9f53e876b8ff3d876c014091dce848950eb118641aece8c6cf895b8",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_query_store_table_wide": {
        "code": "class HDFStoreDataFrame:\n    def time_query_store_table_wide(self):\n        self.store.select(\n            \"table_wide\", where=\"index > self.start_wide and index < self.stop_wide\"\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_query_store_table_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c3d7c25200b29f340e234e97d7b346c3e5ff92212ce918917b0c9aa3d1b47bd2",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_read_store": {
        "code": "class HDFStoreDataFrame:\n    def time_read_store(self):\n        self.store.get(\"fixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_read_store",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "216845fdd1deabde9908db89a022473d67186f006a93a038e73830cf99b1aab7",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_read_store_mixed": {
        "code": "class HDFStoreDataFrame:\n    def time_read_store_mixed(self):\n        self.store.get(\"fixed_mixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_read_store_mixed",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "16c0d8842d890753f9913df9c57f4745bdb5c3a523edfc04f4e5a3575222b28b",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_read_store_table": {
        "code": "class HDFStoreDataFrame:\n    def time_read_store_table(self):\n        self.store.select(\"table\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_read_store_table",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "edb8964a29b434ba9ad14fa7b3d241d9813fb2eb2d8063a8cff9c45d33c6c42e",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed": {
        "code": "class HDFStoreDataFrame:\n    def time_read_store_table_mixed(self):\n        self.store.select(\"table_mixed\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_mixed",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "74b6d19b7478b231b7efc184f8bcc1ca34890891a45ef1a4f4664245013632a4",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_read_store_table_wide": {
        "code": "class HDFStoreDataFrame:\n    def time_read_store_table_wide(self):\n        self.store.select(\"table_wide\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_read_store_table_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "688b1cf7e2f243ee3809b675fcfddb9857749acb8134b2ccec93f4e92eba6567",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_store_info": {
        "code": "class HDFStoreDataFrame:\n    def time_store_info(self):\n        self.store.info()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_store_info",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0e940fdd70922efe865eccd3574966c10da9cc8336e0343f925799fced4b2dab",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_store_repr": {
        "code": "class HDFStoreDataFrame:\n    def time_store_repr(self):\n        repr(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_store_repr",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f2b6fc037201b2ef5b2da7117be01406871226d64bd77ea16d7d334a88d00151",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_store_str": {
        "code": "class HDFStoreDataFrame:\n    def time_store_str(self):\n        str(self.store)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_store_str",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b1b93a9fa3a4a23d689e353da1c1d02fe457eb685128bc8509d4357a06bf1e6f",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_write_store": {
        "code": "class HDFStoreDataFrame:\n    def time_write_store(self):\n        self.store.put(\"fixed_write\", self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_write_store",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ab76c6bfa88a0d2a720cc62fa4fe89c1dcfc55cf404e4badf43ccf3c21f6edcc",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_write_store_mixed": {
        "code": "class HDFStoreDataFrame:\n    def time_write_store_mixed(self):\n        self.store.put(\"fixed_mixed_write\", self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_write_store_mixed",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d6d0b19cf5f7252f69fb94a3591e5167d4577824f40f52b38787bdc52b81baf9",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_write_store_table": {
        "code": "class HDFStoreDataFrame:\n    def time_write_store_table(self):\n        self.store.append(\"table_write\", self.df)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_write_store_table",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "31558266bd49642a54701f29af63cfac26ec2050f77bff9c973158664daa0254",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_write_store_table_dc": {
        "code": "class HDFStoreDataFrame:\n    def time_write_store_table_dc(self):\n        self.store.append(\"table_dc_write\", self.df_dc, data_columns=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_dc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b197ef5b10e98508ad6bcb9a06eca72f00c3a598c0b97759b291fa97a6cc11fa",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed": {
        "code": "class HDFStoreDataFrame:\n    def time_write_store_table_mixed(self):\n        self.store.append(\"table_mixed_write\", self.df_mixed)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_mixed",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f0747848a3d0a05373a78bc9d46f35cbcfc4091d06dcc8c83f90bdad33685df9",
        "warmup_time": -1
    },
    "io.hdf.HDFStoreDataFrame.time_write_store_table_wide": {
        "code": "class HDFStoreDataFrame:\n    def time_write_store_table_wide(self):\n        self.store.append(\"table_wide_write\", self.df_wide)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass HDFStoreDataFrame:\n    def setup(self):\n        N = 25000\n        index = tm.makeStringIndex(N)\n        self.df = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)}, index=index\n        )\n        self.df_mixed = DataFrame(\n            {\n                \"float1\": np.random.randn(N),\n                \"float2\": np.random.randn(N),\n                \"string1\": [\"foo\"] * N,\n                \"bool1\": [True] * N,\n                \"int1\": np.random.randint(0, N, size=N),\n            },\n            index=index,\n        )\n        self.df_wide = DataFrame(np.random.randn(N, 100))\n        self.start_wide = self.df_wide.index[10000]\n        self.stop_wide = self.df_wide.index[15000]\n        self.df2 = DataFrame(\n            {\"float1\": np.random.randn(N), \"float2\": np.random.randn(N)},\n            index=date_range(\"1/1/2000\", periods=N),\n        )\n        self.start = self.df2.index[10000]\n        self.stop = self.df2.index[15000]\n        self.df_wide2 = DataFrame(\n            np.random.randn(N, 100), index=date_range(\"1/1/2000\", periods=N)\n        )\n        self.df_dc = DataFrame(\n            np.random.randn(N, 10), columns=[\"C%03d\" % i for i in range(10)]\n        )\n    \n        self.fname = \"__test__.h5\"\n    \n        self.store = HDFStore(self.fname)\n        self.store.put(\"fixed\", self.df)\n        self.store.put(\"fixed_mixed\", self.df_mixed)\n        self.store.append(\"table\", self.df2)\n        self.store.append(\"table_mixed\", self.df_mixed)\n        self.store.append(\"table_wide\", self.df_wide)\n        self.store.append(\"table_wide2\", self.df_wide2)",
        "min_run_count": 2,
        "name": "io.hdf.HDFStoreDataFrame.time_write_store_table_wide",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2553d52362785b73228230bdc2526996ddf86146590b8102873df23685b36848",
        "warmup_time": -1
    },
    "io.json.NormalizeJSON.time_normalize_json": {
        "code": "class NormalizeJSON:\n    def time_normalize_json(self, orient, frame):\n        json_normalize(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NormalizeJSON:\n    def setup(self, orient, frame):\n        data = {\n            \"hello\": [\"thisisatest\", 999898, \"mixed types\"],\n            \"nest1\": {\"nest2\": {\"nest3\": \"nest3_value\", \"nest3_int\": 3445}},\n            \"nest1_list\": {\"nest2\": [\"blah\", 32423, 546456.876, 92030234]},\n            \"hello2\": \"string\",\n        }\n        self.data = [data for i in range(10000)]",
        "min_run_count": 2,
        "name": "io.json.NormalizeJSON.time_normalize_json",
        "number": 0,
        "param_names": [
            "orient",
            "frame"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ],
            [
                "'df'",
                "'df_date_idx'",
                "'df_td_int_ts'",
                "'df_int_floats'",
                "'df_int_float_str'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "318fc7d7f7bff26fc7a49a190be4dc0e2690469149e9fda19e3a8074d89cde6c",
        "warmup_time": -1
    },
    "io.json.ReadJSON.time_read_json": {
        "code": "class ReadJSON:\n    def time_read_json(self, orient, index):\n        read_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSON:\n    def setup(self, orient, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=orient)",
        "min_run_count": 2,
        "name": "io.json.ReadJSON.time_read_json",
        "number": 0,
        "param_names": [
            "orient",
            "index"
        ],
        "params": [
            [
                "'split'",
                "'index'",
                "'records'"
            ],
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3f6c14bc9e55f7a8db1ac1ac3e51554a8b8c13a584d65d6378577af9886c2dc3",
        "warmup_time": -1
    },
    "io.json.ReadJSONLines.peakmem_read_json_lines": {
        "code": "class ReadJSONLines:\n    def peakmem_read_json_lines(self, index):\n        read_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)",
        "name": "io.json.ReadJSONLines.peakmem_read_json_lines",
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "fced1333ed6ef50926ba752d6eea2aee10f15cc17f9083db263457f5505fab40"
    },
    "io.json.ReadJSONLines.peakmem_read_json_lines_concat": {
        "code": "class ReadJSONLines:\n    def peakmem_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient=\"records\", lines=True, chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)",
        "name": "io.json.ReadJSONLines.peakmem_read_json_lines_concat",
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "3753e5a97992c5f90ebacd5cbb7de30dabc2ce781c590e31f20930dfbb2a2b2c"
    },
    "io.json.ReadJSONLines.peakmem_read_json_lines_nrows": {
        "code": "class ReadJSONLines:\n    def peakmem_read_json_lines_nrows(self, index):\n        read_json(self.fname, orient=\"records\", lines=True, nrows=15000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)",
        "name": "io.json.ReadJSONLines.peakmem_read_json_lines_nrows",
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "aaac83799b11da0d6b844ebbb1247cc25cee374c56d01f29168f9d16f17c1d49"
    },
    "io.json.ReadJSONLines.time_read_json_lines": {
        "code": "class ReadJSONLines:\n    def time_read_json_lines(self, index):\n        read_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)",
        "min_run_count": 2,
        "name": "io.json.ReadJSONLines.time_read_json_lines",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c2f51ad2fdab3e2bf25fae93709d02119432db14e1842ce603e2f13a1c128286",
        "warmup_time": -1
    },
    "io.json.ReadJSONLines.time_read_json_lines_concat": {
        "code": "class ReadJSONLines:\n    def time_read_json_lines_concat(self, index):\n        concat(read_json(self.fname, orient=\"records\", lines=True, chunksize=25000))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)",
        "min_run_count": 2,
        "name": "io.json.ReadJSONLines.time_read_json_lines_concat",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "342cb2570c1aa9c8f74d8d089479641e545984a9c1fcc9d158e22c00f93f278a",
        "warmup_time": -1
    },
    "io.json.ReadJSONLines.time_read_json_lines_nrows": {
        "code": "class ReadJSONLines:\n    def time_read_json_lines_nrows(self, index):\n        read_json(self.fname, orient=\"records\", lines=True, nrows=25000)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadJSONLines:\n    def setup(self, index):\n        N = 100000\n        indexes = {\n            \"int\": np.arange(N),\n            \"datetime\": date_range(\"20000101\", periods=N, freq=\"H\"),\n        }\n        df = DataFrame(\n            np.random.randn(N, 5),\n            columns=[f\"float_{i}\" for i in range(5)],\n            index=indexes[index],\n        )\n        df.to_json(self.fname, orient=\"records\", lines=True)",
        "min_run_count": 2,
        "name": "io.json.ReadJSONLines.time_read_json_lines_nrows",
        "number": 0,
        "param_names": [
            "index"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e44d38a5bde453e73625c16e6c33c05c07928b99505a20234085a00aaa76b3ec",
        "warmup_time": -1
    },
    "io.json.ToJSON.peakmem_to_json": {
        "code": "class ToJSON:\n    def peakmem_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n    \n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "name": "io.json.ToJSON.peakmem_to_json",
        "param_names": [
            "orient",
            "frame"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ],
            [
                "'df'",
                "'df_date_idx'",
                "'df_td_int_ts'",
                "'df_int_floats'",
                "'df_int_float_str'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "adf4b554b5c93e0245cb16f1618401622f82bce472f2397fa6d81ca620c40bed"
    },
    "io.json.ToJSON.time_to_json": {
        "code": "class ToJSON:\n    def time_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSON:\n    def setup(self, orient, frame):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n    \n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSON.time_to_json",
        "number": 0,
        "param_names": [
            "orient",
            "frame"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ],
            [
                "'df'",
                "'df_date_idx'",
                "'df_td_int_ts'",
                "'df_int_floats'",
                "'df_int_float_str'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "101333f4d5654ae3ff583e1e6394be69e8b17514ccd32c8fde3b949b9b1305f1",
        "warmup_time": -1
    },
    "io.json.ToJSONISO.time_iso_format": {
        "code": "class ToJSONISO:\n    def time_iso_format(self, orient):\n        self.df.to_json(orient=orient, date_format=\"iso\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONISO:\n    def setup(self, orient):\n        N = 10 ** 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        self.df = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSONISO.time_iso_format",
        "number": 0,
        "param_names": [
            "orient"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9405204baa6622269410397ec27ff78a7be2701c1c4898273d5d91d0bd69f06d",
        "warmup_time": -1
    },
    "io.json.ToJSONLines.time_delta_int_tstamp_lines": {
        "code": "class ToJSONLines:\n    def time_delta_int_tstamp_lines(self):\n        self.df_td_int_ts.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSONLines.time_delta_int_tstamp_lines",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "818451d8121904be3f344e6d836f7b61a2e97a33f98720475d6c5c8f78dafdd7",
        "warmup_time": -1
    },
    "io.json.ToJSONLines.time_float_int_lines": {
        "code": "class ToJSONLines:\n    def time_float_int_lines(self):\n        self.df_int_floats.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSONLines.time_float_int_lines",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bd05ab92644add941b974ecbe4d43efc8b50a6aa3a941f27274ecf75d5a85b48",
        "warmup_time": -1
    },
    "io.json.ToJSONLines.time_float_int_str_lines": {
        "code": "class ToJSONLines:\n    def time_float_int_str_lines(self):\n        self.df_int_float_str.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSONLines.time_float_int_str_lines",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bb3d69b7aacfa3a1b13a65ad2309567e55621988465519d735fa2710e2de5689",
        "warmup_time": -1
    },
    "io.json.ToJSONLines.time_float_longint_str_lines": {
        "code": "class ToJSONLines:\n    def time_float_longint_str_lines(self):\n        self.df_longint_float_str.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSONLines.time_float_longint_str_lines",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eda4ea5713dbfda2d3bb77f392108f7cc7bfa4f33f967451e8c3fa240d5d7c61",
        "warmup_time": -1
    },
    "io.json.ToJSONLines.time_floats_with_dt_index_lines": {
        "code": "class ToJSONLines:\n    def time_floats_with_dt_index_lines(self):\n        self.df_date_idx.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSONLines.time_floats_with_dt_index_lines",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "83161f71fd28f1e5096187ba3e6d83fc213d0504afb455f80c1f239b52869a5f",
        "warmup_time": -1
    },
    "io.json.ToJSONLines.time_floats_with_int_idex_lines": {
        "code": "class ToJSONLines:\n    def time_floats_with_int_idex_lines(self):\n        self.df.to_json(self.fname, orient=\"records\", lines=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONLines:\n    def setup(self):\n        N = 10 ** 5\n        ncols = 5\n        index = date_range(\"20000101\", periods=N, freq=\"H\")\n        timedeltas = timedelta_range(start=1, periods=N, freq=\"s\")\n        datetimes = date_range(start=1, periods=N, freq=\"s\")\n        ints = np.random.randint(100000000, size=N)\n        longints = sys.maxsize * np.random.randint(100000000, size=N)\n        floats = np.random.randn(N)\n        strings = tm.makeStringIndex(N)\n        self.df = DataFrame(np.random.randn(N, ncols), index=np.arange(N))\n        self.df_date_idx = DataFrame(np.random.randn(N, ncols), index=index)\n        self.df_td_int_ts = DataFrame(\n            {\n                \"td_1\": timedeltas,\n                \"td_2\": timedeltas,\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"ts_1\": datetimes,\n                \"ts_2\": datetimes,\n            },\n            index=index,\n        )\n        self.df_int_floats = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"int_3\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"float_3\": floats,\n            },\n            index=index,\n        )\n        self.df_int_float_str = DataFrame(\n            {\n                \"int_1\": ints,\n                \"int_2\": ints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )\n        self.df_longint_float_str = DataFrame(\n            {\n                \"longint_1\": longints,\n                \"longint_2\": longints,\n                \"float_1\": floats,\n                \"float_2\": floats,\n                \"str_1\": strings,\n                \"str_2\": strings,\n            },\n            index=index,\n        )",
        "min_run_count": 2,
        "name": "io.json.ToJSONLines.time_floats_with_int_idex_lines",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "916ad054984d6e8a6bc09d1c60a2b5930edc65fd76b816afbb5c71d15228a21e",
        "warmup_time": -1
    },
    "io.json.ToJSONMem.peakmem_float": {
        "code": "class ToJSONMem:\n    def peakmem_float(self, frames):\n        df = frames[\"float\"]\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        frames = {\"int\": df, \"float\": df.astype(float)}\n    \n        return frames",
        "name": "io.json.ToJSONMem.peakmem_float",
        "param_names": [],
        "params": [],
        "setup_cache_key": "io.json:295",
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "677e93d79bbe82c1e36576a40ccb26b8db281fc3a66e1efc383648d7765de6c2"
    },
    "io.json.ToJSONMem.peakmem_int": {
        "code": "class ToJSONMem:\n    def peakmem_int(self, frames):\n        df = frames[\"int\"]\n        for _ in range(100_000):\n            df.to_json()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONMem:\n    def setup_cache(self):\n        df = DataFrame([[1]])\n        frames = {\"int\": df, \"float\": df.astype(float)}\n    \n        return frames",
        "name": "io.json.ToJSONMem.peakmem_int",
        "param_names": [],
        "params": [],
        "setup_cache_key": "io.json:295",
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "b9f6565999a24da1b2b0b5d21f3a3d6b94040657e615ea1287808b65451b9c27"
    },
    "io.json.ToJSONWide.peakmem_to_json": {
        "code": "class ToJSON:\n    def peakmem_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide",
        "name": "io.json.ToJSONWide.peakmem_to_json",
        "param_names": [
            "orient",
            "frame"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ],
            [
                "'df'",
                "'df_date_idx'",
                "'df_td_int_ts'",
                "'df_int_floats'",
                "'df_int_float_str'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "f179e468594888d4ad11b82d624fc4c3925d4831054986c7642b6a7938e395d8"
    },
    "io.json.ToJSONWide.peakmem_to_json_wide": {
        "code": "class ToJSONWide:\n    def peakmem_to_json_wide(self, orient, frame):\n        self.df_wide.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide",
        "name": "io.json.ToJSONWide.peakmem_to_json_wide",
        "param_names": [
            "orient",
            "frame"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ],
            [
                "'df'",
                "'df_date_idx'",
                "'df_td_int_ts'",
                "'df_int_floats'",
                "'df_int_float_str'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "350c040ee03cb09b3b2af80aacdb6f89f0b64fb12027e7abfcecf1754316da0d"
    },
    "io.json.ToJSONWide.time_to_json": {
        "code": "class ToJSON:\n    def time_to_json(self, orient, frame):\n        getattr(self, frame).to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide",
        "min_run_count": 2,
        "name": "io.json.ToJSONWide.time_to_json",
        "number": 0,
        "param_names": [
            "orient",
            "frame"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ],
            [
                "'df'",
                "'df_date_idx'",
                "'df_td_int_ts'",
                "'df_int_floats'",
                "'df_int_float_str'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3efe5275ae2f37aaa5320e63422ce5b375719e691728af347d4018c67aef213a",
        "warmup_time": -1
    },
    "io.json.ToJSONWide.time_to_json_wide": {
        "code": "class ToJSONWide:\n    def time_to_json_wide(self, orient, frame):\n        self.df_wide.to_json(self.fname, orient=orient)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToJSONWide:\n    def setup(self, orient, frame):\n        super().setup(orient, frame)\n        base_df = getattr(self, frame).copy()\n        df_wide = concat([base_df.iloc[:100]] * 1000, ignore_index=True, axis=1)\n        self.df_wide = df_wide",
        "min_run_count": 2,
        "name": "io.json.ToJSONWide.time_to_json_wide",
        "number": 0,
        "param_names": [
            "orient",
            "frame"
        ],
        "params": [
            [
                "'split'",
                "'columns'",
                "'index'",
                "'values'",
                "'records'"
            ],
            [
                "'df'",
                "'df_date_idx'",
                "'df_td_int_ts'",
                "'df_int_floats'",
                "'df_int_float_str'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "aae5665173eb24e14595380fcf07cfeeab21783b5862479ee4e358e042ba6c38",
        "warmup_time": -1
    },
    "io.parsers.ConcatDateCols.time_check_concat": {
        "code": "class ConcatDateCols:\n    def time_check_concat(self, value, dim):\n        concat_date_cols(self.object)\n\n    def setup(self, value, dim):\n        count_elem = 10000\n        if dim == 1:\n            self.object = (np.array([value] * count_elem),)\n        if dim == 2:\n            self.object = (\n                np.array([value] * count_elem),\n                np.array([value] * count_elem),\n            )",
        "min_run_count": 2,
        "name": "io.parsers.ConcatDateCols.time_check_concat",
        "number": 0,
        "param_names": [
            "value",
            "dim"
        ],
        "params": [
            [
                "1234567890",
                "'AAAA'"
            ],
            [
                "1",
                "2"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9aa4efe73a0a7fdff0a0c0b2ffa389e83a44520cd250bfea1d40fde51c49d9d8",
        "warmup_time": -1
    },
    "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes": {
        "code": "class DoesStringLookLikeDatetime:\n    def time_check_datetimes(self, value):\n        for obj in self.objects:\n            _does_string_look_like_datetime(obj)\n\n    def setup(self, value):\n        self.objects = [value] * 1000000",
        "min_run_count": 2,
        "name": "io.parsers.DoesStringLookLikeDatetime.time_check_datetimes",
        "number": 0,
        "param_names": [
            "value"
        ],
        "params": [
            [
                "'2Q2005'",
                "'0.0'",
                "'10000'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a023015f4dc4ff2fbfce3252f6fd4b6c28970e462a5e405f7c2febd9b2256de7",
        "warmup_time": -1
    },
    "io.pickle.Pickle.peakmem_read_pickle": {
        "code": "class Pickle:\n    def peakmem_read_pickle(self):\n        read_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_pickle(self.fname)",
        "name": "io.pickle.Pickle.peakmem_read_pickle",
        "param_names": [],
        "params": [],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "32588a86b2897062ab806a649b772d609575da1519a6e12c42484150b1367904"
    },
    "io.pickle.Pickle.peakmem_write_pickle": {
        "code": "class Pickle:\n    def peakmem_write_pickle(self):\n        self.df.to_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_pickle(self.fname)",
        "name": "io.pickle.Pickle.peakmem_write_pickle",
        "param_names": [],
        "params": [],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "839a5ff1f363bfec3346c4bf60f8a8bab063593f1c603f5d2187989e53993f18"
    },
    "io.pickle.Pickle.time_read_pickle": {
        "code": "class Pickle:\n    def time_read_pickle(self):\n        read_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_pickle(self.fname)",
        "min_run_count": 2,
        "name": "io.pickle.Pickle.time_read_pickle",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0162d5f685117e8f1bcd5a6d79be23fbb5dbe4448a13b5bce289925a6e251566",
        "warmup_time": -1
    },
    "io.pickle.Pickle.time_write_pickle": {
        "code": "class Pickle:\n    def time_write_pickle(self):\n        self.df.to_pickle(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pickle:\n    def setup(self):\n        self.fname = \"__test__.pkl\"\n        N = 100000\n        C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(N)\n        self.df.to_pickle(self.fname)",
        "min_run_count": 2,
        "name": "io.pickle.Pickle.time_write_pickle",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "80f443c19927866fbbaef6c821598e7249c2d7c7dada4dffc558abcee53f2fc9",
        "warmup_time": -1
    },
    "io.sas.SAS.time_read_sas": {
        "code": "class SAS:\n    def time_read_sas(self, format):\n        read_sas(self.f, format=format)\n\n    def setup(self, format):\n        # Read files that are located in 'pandas/tests/io/sas/data'\n        files = {\"sas7bdat\": \"test1.sas7bdat\", \"xport\": \"paxraw_d_short.xpt\"}\n        file = files[format]\n        paths = [\n            os.path.dirname(__file__),\n            \"..\",\n            \"..\",\n            \"..\",\n            \"pandas\",\n            \"tests\",\n            \"io\",\n            \"sas\",\n            \"data\",\n            file,\n        ]\n        self.f = os.path.join(*paths)",
        "min_run_count": 2,
        "name": "io.sas.SAS.time_read_sas",
        "number": 0,
        "param_names": [
            "format"
        ],
        "params": [
            [
                "'sas7bdat'",
                "'xport'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bf95815431216788cd895f3a56c383c2ab52730695c1bdecd72c6d55e9272a7e",
        "warmup_time": -1
    },
    "io.sql.ReadSQLTable.time_read_sql_table_all": {
        "code": "class ReadSQLTable:\n    def time_read_sql_table_all(self):\n        read_sql_table(self.table_name, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")",
        "min_run_count": 2,
        "name": "io.sql.ReadSQLTable.time_read_sql_table_all",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "61f536cb69b9600648cea2ca86027a6f81b5672c70642443eb77cbb3902e8518",
        "warmup_time": -1
    },
    "io.sql.ReadSQLTable.time_read_sql_table_parse_dates": {
        "code": "class ReadSQLTable:\n    def time_read_sql_table_parse_dates(self):\n        read_sql_table(\n            self.table_name,\n            self.con,\n            columns=[\"datetime_string\"],\n            parse_dates=[\"datetime_string\"],\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTable:\n    def setup(self):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")",
        "min_run_count": 2,
        "name": "io.sql.ReadSQLTable.time_read_sql_table_parse_dates",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a52cdbcd4b5b15ddebd2b6f27956213f4ec4d044873b6b1fe3ba95ed944add92",
        "warmup_time": -1
    },
    "io.sql.ReadSQLTableDtypes.time_read_sql_table_column": {
        "code": "class ReadSQLTableDtypes:\n    def time_read_sql_table_column(self, dtype):\n        read_sql_table(self.table_name, self.con, columns=[dtype])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReadSQLTableDtypes:\n    def setup(self, dtype):\n        N = 10000\n        self.table_name = \"test\"\n        self.con = create_engine(\"sqlite:///:memory:\")\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")",
        "min_run_count": 2,
        "name": "io.sql.ReadSQLTableDtypes.time_read_sql_table_column",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'float'",
                "'float_with_nan'",
                "'string'",
                "'bool'",
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bc4c07d3640a6cec9fa7a8658f2b42016c3340c553593bf03722db5404d9dd8a",
        "warmup_time": -1
    },
    "io.sql.SQL.time_read_sql_query": {
        "code": "class SQL:\n    def time_read_sql_query(self, connection):\n        read_sql_query(self.query_all, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_all = f\"SELECT * FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")",
        "min_run_count": 2,
        "name": "io.sql.SQL.time_read_sql_query",
        "number": 0,
        "param_names": [
            "connection"
        ],
        "params": [
            [
                "'sqlalchemy'",
                "'sqlite'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "241e50bdbc21d4a11d3f33b376240361816c6b99339a06a43155d0c8834ba8d0",
        "warmup_time": -1
    },
    "io.sql.SQL.time_to_sql_dataframe": {
        "code": "class SQL:\n    def time_to_sql_dataframe(self, connection):\n        self.df.to_sql(\"test1\", self.con, if_exists=\"replace\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SQL:\n    def setup(self, connection):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_all = f\"SELECT * FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")",
        "min_run_count": 2,
        "name": "io.sql.SQL.time_to_sql_dataframe",
        "number": 0,
        "param_names": [
            "connection"
        ],
        "params": [
            [
                "'sqlalchemy'",
                "'sqlite'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "73a5242f32301375b3708c050add5fc72fd1efc56c20b659df2184b825a60cdd",
        "warmup_time": -1
    },
    "io.sql.WriteSQLDtypes.time_read_sql_query_select_column": {
        "code": "class WriteSQLDtypes:\n    def time_read_sql_query_select_column(self, connection, dtype):\n        read_sql_query(self.query_col, self.con)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_col = f\"SELECT {dtype} FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")",
        "min_run_count": 2,
        "name": "io.sql.WriteSQLDtypes.time_read_sql_query_select_column",
        "number": 0,
        "param_names": [
            "connection",
            "dtype"
        ],
        "params": [
            [
                "'sqlalchemy'",
                "'sqlite'"
            ],
            [
                "'float'",
                "'float_with_nan'",
                "'string'",
                "'bool'",
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9e59096a3e02d594ea8b05d4e57ba5f3cabec0299315c7db6d90e9f7405638ea",
        "warmup_time": -1
    },
    "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column": {
        "code": "class WriteSQLDtypes:\n    def time_to_sql_dataframe_column(self, connection, dtype):\n        self.df[[dtype]].to_sql(\"test1\", self.con, if_exists=\"replace\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WriteSQLDtypes:\n    def setup(self, connection, dtype):\n        N = 10000\n        con = {\n            \"sqlalchemy\": create_engine(\"sqlite:///:memory:\"),\n            \"sqlite\": sqlite3.connect(\":memory:\"),\n        }\n        self.table_name = \"test_type\"\n        self.query_col = f\"SELECT {dtype} FROM {self.table_name}\"\n        self.con = con[connection]\n        self.df = DataFrame(\n            {\n                \"float\": np.random.randn(N),\n                \"float_with_nan\": np.random.randn(N),\n                \"string\": [\"foo\"] * N,\n                \"bool\": [True] * N,\n                \"int\": np.random.randint(0, N, size=N),\n                \"datetime\": date_range(\"2000-01-01\", periods=N, freq=\"s\"),\n            },\n            index=tm.makeStringIndex(N),\n        )\n        self.df.loc[1000:3000, \"float_with_nan\"] = np.nan\n        self.df[\"datetime_string\"] = self.df[\"datetime\"].astype(str)\n        self.df.to_sql(self.table_name, self.con, if_exists=\"replace\")",
        "min_run_count": 2,
        "name": "io.sql.WriteSQLDtypes.time_to_sql_dataframe_column",
        "number": 0,
        "param_names": [
            "connection",
            "dtype"
        ],
        "params": [
            [
                "'sqlalchemy'",
                "'sqlite'"
            ],
            [
                "'float'",
                "'float_with_nan'",
                "'string'",
                "'bool'",
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2255f51d338823ce5ab15352d630e75b05a8272dab8343a51527285e608b4cb8",
        "warmup_time": -1
    },
    "io.stata.Stata.time_read_stata": {
        "code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = \"__test__.dta\"\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(self.N)\n        self.df[\"int8_\"] = np.random.randint(\n            np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N\n        )\n        self.df[\"int16_\"] = np.random.randint(\n            np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N\n        )\n        self.df[\"int32_\"] = np.random.randint(\n            np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N\n        )\n        self.df[\"float32_\"] = np.array(np.random.randn(N), dtype=np.float32)\n        self.convert_dates = {\"index\": convert_dates}\n        self.df.to_stata(self.fname, self.convert_dates)",
        "min_run_count": 2,
        "name": "io.stata.Stata.time_read_stata",
        "number": 0,
        "param_names": [
            "convert_dates"
        ],
        "params": [
            [
                "'tc'",
                "'td'",
                "'tm'",
                "'tw'",
                "'th'",
                "'tq'",
                "'ty'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c9e8109f2ea54f6686a2245b6842e4d206a527423831ab1b9fdeaeec7117890f",
        "warmup_time": -1
    },
    "io.stata.Stata.time_write_stata": {
        "code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Stata:\n    def setup(self, convert_dates):\n        self.fname = \"__test__.dta\"\n        N = self.N = 100000\n        C = self.C = 5\n        self.df = DataFrame(\n            np.random.randn(N, C),\n            columns=[f\"float{i}\" for i in range(C)],\n            index=date_range(\"20000101\", periods=N, freq=\"H\"),\n        )\n        self.df[\"object\"] = tm.makeStringIndex(self.N)\n        self.df[\"int8_\"] = np.random.randint(\n            np.iinfo(np.int8).min, np.iinfo(np.int8).max - 27, N\n        )\n        self.df[\"int16_\"] = np.random.randint(\n            np.iinfo(np.int16).min, np.iinfo(np.int16).max - 27, N\n        )\n        self.df[\"int32_\"] = np.random.randint(\n            np.iinfo(np.int32).min, np.iinfo(np.int32).max - 27, N\n        )\n        self.df[\"float32_\"] = np.array(np.random.randn(N), dtype=np.float32)\n        self.convert_dates = {\"index\": convert_dates}\n        self.df.to_stata(self.fname, self.convert_dates)",
        "min_run_count": 2,
        "name": "io.stata.Stata.time_write_stata",
        "number": 0,
        "param_names": [
            "convert_dates"
        ],
        "params": [
            [
                "'tc'",
                "'td'",
                "'tm'",
                "'tw'",
                "'th'",
                "'tq'",
                "'ty'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7f80002bdb9f9bf1afdc59b838b31c3e027daf2413e175126ff78272e532b9df",
        "warmup_time": -1
    },
    "io.stata.StataMissing.time_read_stata": {
        "code": "class Stata:\n    def time_read_stata(self, convert_dates):\n        read_stata(self.fname)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df[f\"missing_{i}\"] = missing_data\n        self.df.to_stata(self.fname, self.convert_dates)",
        "min_run_count": 2,
        "name": "io.stata.StataMissing.time_read_stata",
        "number": 0,
        "param_names": [
            "convert_dates"
        ],
        "params": [
            [
                "'tc'",
                "'td'",
                "'tm'",
                "'tw'",
                "'th'",
                "'tq'",
                "'ty'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "75ac8d52d309d33e028aabf8cbf63fb714dffdfeaf6e4da10fd4f70a6ab4f982",
        "warmup_time": -1
    },
    "io.stata.StataMissing.time_write_stata": {
        "code": "class Stata:\n    def time_write_stata(self, convert_dates):\n        self.df.to_stata(self.fname, self.convert_dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass StataMissing:\n    def setup(self, convert_dates):\n        super().setup(convert_dates)\n        for i in range(10):\n            missing_data = np.random.randn(self.N)\n            missing_data[missing_data < 0] = np.nan\n            self.df[f\"missing_{i}\"] = missing_data\n        self.df.to_stata(self.fname, self.convert_dates)",
        "min_run_count": 2,
        "name": "io.stata.StataMissing.time_write_stata",
        "number": 0,
        "param_names": [
            "convert_dates"
        ],
        "params": [
            [
                "'tc'",
                "'td'",
                "'tm'",
                "'tw'",
                "'th'",
                "'tq'",
                "'ty'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "176723ae88d2b2e895a722920a685f395ae424b95e57eb161ff9885f5074d864",
        "warmup_time": -1
    },
    "io.style.Render.peakmem_apply_format_hide_render": {
        "code": "class Render:\n    def peakmem_apply_format_hide_render(self, cols, rows):\n        self._style_apply_format_hide()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "name": "io.style.Render.peakmem_apply_format_hide_render",
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "24efee29e9f4259b3dc32b50ebebd07120a2cc59672b5f07aaf694b3350ffc33"
    },
    "io.style.Render.peakmem_apply_render": {
        "code": "class Render:\n    def peakmem_apply_render(self, cols, rows):\n        self._style_apply()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "name": "io.style.Render.peakmem_apply_render",
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "f1291d9b0cee2ed29164614c2827a58907e0943d031efe0a1f700dd7bb3ea1ef"
    },
    "io.style.Render.peakmem_classes_render": {
        "code": "class Render:\n    def peakmem_classes_render(self, cols, rows):\n        self._style_classes()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "name": "io.style.Render.peakmem_classes_render",
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "1d74d0ee63b8ddbcb67f37a2c6260ebe84c54ec1d2650db12d284630efa672c9"
    },
    "io.style.Render.peakmem_format_render": {
        "code": "class Render:\n    def peakmem_format_render(self, cols, rows):\n        self._style_format()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "name": "io.style.Render.peakmem_format_render",
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "2d2ae2b598964ca4ec2ce6befed05ff0ed2c8833539c314cbc42c2a006d9abcf"
    },
    "io.style.Render.peakmem_tooltips_render": {
        "code": "class Render:\n    def peakmem_tooltips_render(self, cols, rows):\n        self._style_tooltips()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "name": "io.style.Render.peakmem_tooltips_render",
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "f3165d89bad8a5256ce768ec97faaca1dc322cc15dfc6cce5c8f629872c4b625"
    },
    "io.style.Render.time_apply_format_hide_render": {
        "code": "class Render:\n    def time_apply_format_hide_render(self, cols, rows):\n        self._style_apply_format_hide()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "min_run_count": 2,
        "name": "io.style.Render.time_apply_format_hide_render",
        "number": 0,
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4624b648242dbd72367816b07786b7bb20dec67fcf4d8b269046640a281b891b",
        "warmup_time": -1
    },
    "io.style.Render.time_apply_render": {
        "code": "class Render:\n    def time_apply_render(self, cols, rows):\n        self._style_apply()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "min_run_count": 2,
        "name": "io.style.Render.time_apply_render",
        "number": 0,
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b7713a928f5b63249a63e44399f6d18a893bff35ae8541e666af0885aec0a166",
        "warmup_time": -1
    },
    "io.style.Render.time_classes_render": {
        "code": "class Render:\n    def time_classes_render(self, cols, rows):\n        self._style_classes()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "min_run_count": 2,
        "name": "io.style.Render.time_classes_render",
        "number": 0,
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e385c7e77a27a0e29b3941e7cf3c0727f5f83d8b6279cd9500e63fb1f630d7d5",
        "warmup_time": -1
    },
    "io.style.Render.time_format_render": {
        "code": "class Render:\n    def time_format_render(self, cols, rows):\n        self._style_format()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "min_run_count": 2,
        "name": "io.style.Render.time_format_render",
        "number": 0,
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2fe7b97954d549aadb2eb134d3d09b8c1334a640488b36869090ed4c430365ed",
        "warmup_time": -1
    },
    "io.style.Render.time_tooltips_render": {
        "code": "class Render:\n    def time_tooltips_render(self, cols, rows):\n        self._style_tooltips()\n        self.st._render_html(True, True)\n\n    def setup(self, cols, rows):\n        self.df = DataFrame(\n            np.random.randn(rows, cols),\n            columns=[f\"float_{i+1}\" for i in range(cols)],\n            index=[f\"row_{i+1}\" for i in range(rows)],\n        )",
        "min_run_count": 2,
        "name": "io.style.Render.time_tooltips_render",
        "number": 0,
        "param_names": [
            "cols",
            "rows"
        ],
        "params": [
            [
                "12",
                "24",
                "36"
            ],
            [
                "12",
                "120"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bf6a27f9959b331a6f71cda4f842f4ceb8df92624979f2a522fe57cc98a5e34d",
        "warmup_time": -1
    },
    "join_merge.Align.time_series_align_int64_index": {
        "code": "class Align:\n    def time_series_align_int64_index(self):\n        self.ts1 + self.ts2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10 ** 5\n        rng = np.arange(0, 10 ** 13, 10 ** 7)\n        stamps = np.datetime64(\"now\").view(\"i8\") + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)",
        "min_run_count": 2,
        "name": "join_merge.Align.time_series_align_int64_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "466f6a9ae3807ca8561600ddf7b146e6813af8d4d8ce45a58447b59e41891043",
        "warmup_time": -1
    },
    "join_merge.Align.time_series_align_left_monotonic": {
        "code": "class Align:\n    def time_series_align_left_monotonic(self):\n        self.ts1.align(self.ts2, join=\"left\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        size = 5 * 10 ** 5\n        rng = np.arange(0, 10 ** 13, 10 ** 7)\n        stamps = np.datetime64(\"now\").view(\"i8\") + rng\n        idx1 = np.sort(np.random.choice(stamps, size, replace=False))\n        idx2 = np.sort(np.random.choice(stamps, size, replace=False))\n        self.ts1 = Series(np.random.randn(size), idx1)\n        self.ts2 = Series(np.random.randn(size), idx2)",
        "min_run_count": 2,
        "name": "join_merge.Align.time_series_align_left_monotonic",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8b101ccbe803e8d6d26f34be882bbdf172f6809fb709037c7285240b07c9884e",
        "warmup_time": -1
    },
    "join_merge.Append.time_append_homogenous": {
        "code": "class Append:\n    def time_append_homogenous(self):\n        self.df1.append(self.df2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Append:\n    def setup(self):\n        self.df1 = DataFrame(np.random.randn(10000, 4), columns=[\"A\", \"B\", \"C\", \"D\"])\n        self.df2 = self.df1.copy()\n        self.df2.index = np.arange(10000, 20000)\n        self.mdf1 = self.df1.copy()\n        self.mdf1[\"obj1\"] = \"bar\"\n        self.mdf1[\"obj2\"] = \"bar\"\n        self.mdf1[\"int1\"] = 5\n        self.mdf1 = self.mdf1._consolidate()\n        self.mdf2 = self.mdf1.copy()\n        self.mdf2.index = self.df2.index",
        "min_run_count": 2,
        "name": "join_merge.Append.time_append_homogenous",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f4843757110374bfc584dc5acc6777b683eb917c11c1e12c866667a1915de50f",
        "warmup_time": -1
    },
    "join_merge.Append.time_append_mixed": {
        "code": "class Append:\n    def time_append_mixed(self):\n        self.mdf1.append(self.mdf2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Append:\n    def setup(self):\n        self.df1 = DataFrame(np.random.randn(10000, 4), columns=[\"A\", \"B\", \"C\", \"D\"])\n        self.df2 = self.df1.copy()\n        self.df2.index = np.arange(10000, 20000)\n        self.mdf1 = self.df1.copy()\n        self.mdf1[\"obj1\"] = \"bar\"\n        self.mdf1[\"obj2\"] = \"bar\"\n        self.mdf1[\"int1\"] = 5\n        self.mdf1 = self.mdf1._consolidate()\n        self.mdf2 = self.mdf1.copy()\n        self.mdf2.index = self.df2.index",
        "min_run_count": 2,
        "name": "join_merge.Append.time_append_mixed",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ccb50257a5bf505fb569db71b1cbdeb9b39ac8ca49e2f1cdc9432b9fdd749339",
        "warmup_time": -1
    },
    "join_merge.Concat.time_concat_empty_left": {
        "code": "class Concat:\n    def time_concat_empty_left(self, axis):\n        concat(self.empty_left, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]",
        "min_run_count": 2,
        "name": "join_merge.Concat.time_concat_empty_left",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "771951eead3fb1607414b81e64c6c4f545f98d91587d9aa690f2c16527848107",
        "warmup_time": -1
    },
    "join_merge.Concat.time_concat_empty_right": {
        "code": "class Concat:\n    def time_concat_empty_right(self, axis):\n        concat(self.empty_right, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]",
        "min_run_count": 2,
        "name": "join_merge.Concat.time_concat_empty_right",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cf76d8a470d6bd253ad17cebe44463f95276cb7ffd53aff671a6cf14d7347a46",
        "warmup_time": -1
    },
    "join_merge.Concat.time_concat_mixed_ndims": {
        "code": "class Concat:\n    def time_concat_mixed_ndims(self, axis):\n        concat(self.mixed_ndims, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]",
        "min_run_count": 2,
        "name": "join_merge.Concat.time_concat_mixed_ndims",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "17be1136e0e93d3aef782ad81cbe89cf034bcd3f6813fb941787d9e15078c5ff",
        "warmup_time": -1
    },
    "join_merge.Concat.time_concat_series": {
        "code": "class Concat:\n    def time_concat_series(self, axis):\n        concat(self.series, axis=axis, sort=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]",
        "min_run_count": 2,
        "name": "join_merge.Concat.time_concat_series",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8f0c73be876789117e57f2f232e4b74816d6eae4cb9dd656640e8e739bcebf0f",
        "warmup_time": -1
    },
    "join_merge.Concat.time_concat_small_frames": {
        "code": "class Concat:\n    def time_concat_small_frames(self, axis):\n        concat(self.small_frames, axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Concat:\n    def setup(self, axis):\n        N = 1000\n        s = Series(N, index=tm.makeStringIndex(N))\n        self.series = [s[i:-i] for i in range(1, 10)] * 50\n        self.small_frames = [DataFrame(np.random.randn(5, 4))] * 1000\n        df = DataFrame(\n            {\"A\": range(N)}, index=date_range(\"20130101\", periods=N, freq=\"s\")\n        )\n        self.empty_left = [DataFrame(), df]\n        self.empty_right = [df, DataFrame()]\n        self.mixed_ndims = [df, df.head(N // 2)]",
        "min_run_count": 2,
        "name": "join_merge.Concat.time_concat_small_frames",
        "number": 0,
        "param_names": [
            "axis"
        ],
        "params": [
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d449c480b723a83ee34e5dae91211f19d62bbe8beb54d6cbcd7dafe417a710b2",
        "warmup_time": -1
    },
    "join_merge.ConcatDataFrames.time_c_ordered": {
        "code": "class ConcatDataFrames:\n    def time_c_ordered(self, axis, ignore_index):\n        concat(self.frame_c, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"C\"))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"F\"))\n        self.frame_f = [frame_f] * 20",
        "min_run_count": 2,
        "name": "join_merge.ConcatDataFrames.time_c_ordered",
        "number": 0,
        "param_names": [
            "axis",
            "ignore_index"
        ],
        "params": [
            [
                "0",
                "1"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a747cecacb0f57e2d282f77dbc9ba6108bb55d137dcb4cdef4d0cb94bd2ef909",
        "warmup_time": -1
    },
    "join_merge.ConcatDataFrames.time_f_ordered": {
        "code": "class ConcatDataFrames:\n    def time_f_ordered(self, axis, ignore_index):\n        concat(self.frame_f, axis=axis, ignore_index=ignore_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ConcatDataFrames:\n    def setup(self, axis, ignore_index):\n        frame_c = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"C\"))\n        self.frame_c = [frame_c] * 20\n        frame_f = DataFrame(np.zeros((10000, 200), dtype=np.float32, order=\"F\"))\n        self.frame_f = [frame_f] * 20",
        "min_run_count": 2,
        "name": "join_merge.ConcatDataFrames.time_f_ordered",
        "number": 0,
        "param_names": [
            "axis",
            "ignore_index"
        ],
        "params": [
            [
                "0",
                "1"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4ae3b6dda3a99cfd094de14c2550530e69a1ede87ff9911c02706ef1acf501eb",
        "warmup_time": -1
    },
    "join_merge.I8Merge.time_i8merge": {
        "code": "class I8Merge:\n    def time_i8merge(self, how):\n        merge(self.left, self.right, how=how)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass I8Merge:\n    def setup(self, how):\n        low, high, n = -1000, 1000, 10 ** 6\n        self.left = DataFrame(\n            np.random.randint(low, high, (n, 7)), columns=list(\"ABCDEFG\")\n        )\n        self.left[\"left\"] = self.left.sum(axis=1)\n        self.right = self.left.sample(frac=1).rename({\"left\": \"right\"}, axis=1)\n        self.right = self.right.reset_index(drop=True)\n        self.right[\"right\"] *= -1",
        "min_run_count": 2,
        "name": "join_merge.I8Merge.time_i8merge",
        "number": 0,
        "param_names": [
            "how"
        ],
        "params": [
            [
                "'inner'",
                "'outer'",
                "'left'",
                "'right'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "407195271d67accc831554f8e140321c3735642b23c8da77c83e16e28d89f6f3",
        "warmup_time": -1
    },
    "join_merge.Join.time_join_dataframe_index_multi": {
        "code": "class Join:\n    def time_join_dataframe_index_multi(self, sort):\n        self.df.join(self.df_multi, on=[\"key1\", \"key2\"], sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])",
        "min_run_count": 2,
        "name": "join_merge.Join.time_join_dataframe_index_multi",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "04d60570ed4f205d4a485419cd0a4631cdc89807af8a7314d9cf5972a451de31",
        "warmup_time": -1
    },
    "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort": {
        "code": "class Join:\n    def time_join_dataframe_index_shuffle_key_bigger_sort(self, sort):\n        self.df_shuf.join(self.df_key2, on=\"key2\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])",
        "min_run_count": 2,
        "name": "join_merge.Join.time_join_dataframe_index_shuffle_key_bigger_sort",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fdd6e003a0b8d50ed40a79334a136c2088017b024563f7e53d502e74b1904909",
        "warmup_time": -1
    },
    "join_merge.Join.time_join_dataframe_index_single_key_bigger": {
        "code": "class Join:\n    def time_join_dataframe_index_single_key_bigger(self, sort):\n        self.df.join(self.df_key2, on=\"key2\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])",
        "min_run_count": 2,
        "name": "join_merge.Join.time_join_dataframe_index_single_key_bigger",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a24325ee21efd415bc66a6cb7038a38be9952023beec11e90f057dd95353625a",
        "warmup_time": -1
    },
    "join_merge.Join.time_join_dataframe_index_single_key_small": {
        "code": "class Join:\n    def time_join_dataframe_index_single_key_small(self, sort):\n        self.df.join(self.df_key1, on=\"key1\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])",
        "min_run_count": 2,
        "name": "join_merge.Join.time_join_dataframe_index_single_key_small",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c7baaed1de356a5b88295125fa91b5842f03ca0a46dcdb4760be8099aa133e05",
        "warmup_time": -1
    },
    "join_merge.Join.time_join_dataframes_cross": {
        "code": "class Join:\n    def time_join_dataframes_cross(self, sort):\n        self.df.loc[:2000].join(self.df_key1, how=\"cross\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Join:\n    def setup(self, sort):\n        level1 = tm.makeStringIndex(10).values\n        level2 = tm.makeStringIndex(1000).values\n        codes1 = np.arange(10).repeat(1000)\n        codes2 = np.tile(np.arange(1000), 10)\n        index2 = MultiIndex(levels=[level1, level2], codes=[codes1, codes2])\n        self.df_multi = DataFrame(\n            np.random.randn(len(index2), 4), index=index2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        self.key1 = np.tile(level1.take(codes1), 10)\n        self.key2 = np.tile(level2.take(codes2), 10)\n        self.df = DataFrame(\n            {\n                \"data1\": np.random.randn(100000),\n                \"data2\": np.random.randn(100000),\n                \"key1\": self.key1,\n                \"key2\": self.key2,\n            }\n        )\n    \n        self.df_key1 = DataFrame(\n            np.random.randn(len(level1), 4), index=level1, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n        self.df_key2 = DataFrame(\n            np.random.randn(len(level2), 4), index=level2, columns=[\"A\", \"B\", \"C\", \"D\"]\n        )\n    \n        shuf = np.arange(100000)\n        np.random.shuffle(shuf)\n        self.df_shuf = self.df.reindex(self.df.index[shuf])",
        "min_run_count": 2,
        "name": "join_merge.Join.time_join_dataframes_cross",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8d164a39efe7f9060207ec93194fdf100dc393428439ef0b3994a5b46877adf2",
        "warmup_time": -1
    },
    "join_merge.JoinIndex.time_left_outer_join_index": {
        "code": "class JoinIndex:\n    def time_left_outer_join_index(self):\n        self.left.join(self.right, on=\"jim\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinIndex:\n    def setup(self):\n        N = 50000\n        self.left = DataFrame(\n            np.random.randint(1, N / 500, (N, 2)), columns=[\"jim\", \"joe\"]\n        )\n        self.right = DataFrame(\n            np.random.randint(1, N / 500, (N, 2)), columns=[\"jolie\", \"jolia\"]\n        ).set_index(\"jolie\")",
        "min_run_count": 2,
        "name": "join_merge.JoinIndex.time_left_outer_join_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "234696a7a1b723cc8541c1bd6f5ffa740dcdd0c9e3a7dbf3305179c84f0fad1a",
        "warmup_time": -1
    },
    "join_merge.JoinNonUnique.time_join_non_unique_equal": {
        "code": "class JoinNonUnique:\n    def time_join_non_unique_equal(self):\n        self.fracofday * self.temp\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass JoinNonUnique:\n    def setup(self):\n        date_index = date_range(\"01-Jan-2013\", \"23-Jan-2013\", freq=\"T\")\n        daily_dates = date_index.to_period(\"D\").to_timestamp(\"S\", \"S\")\n        self.fracofday = date_index.values - daily_dates.values\n        self.fracofday = self.fracofday.astype(\"timedelta64[ns]\")\n        self.fracofday = self.fracofday.astype(np.float64) / 86_400_000_000_000\n        self.fracofday = Series(self.fracofday, daily_dates)\n        index = date_range(date_index.min(), date_index.max(), freq=\"D\")\n        self.temp = Series(1.0, index)[self.fracofday.index]",
        "min_run_count": 2,
        "name": "join_merge.JoinNonUnique.time_join_non_unique_equal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "da02c75be43afdad1e753b0332fc63ac84ee37c47b12fb2595401365d7989cdf",
        "warmup_time": -1
    },
    "join_merge.Merge.time_merge_2intkey": {
        "code": "class Merge:\n    def time_merge_2intkey(self, sort):\n        merge(self.left, self.right, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]",
        "min_run_count": 2,
        "name": "join_merge.Merge.time_merge_2intkey",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d018a32e48407380b39c62527e1de18b8ebfc5721b5302df50c3145d74b0f246",
        "warmup_time": -1
    },
    "join_merge.Merge.time_merge_dataframe_integer_2key": {
        "code": "class Merge:\n    def time_merge_dataframe_integer_2key(self, sort):\n        merge(self.df, self.df3, sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]",
        "min_run_count": 2,
        "name": "join_merge.Merge.time_merge_dataframe_integer_2key",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "39d8692590ca9746a4f331094fcb81476adb504db6f9ee3e982c9616a8eec137",
        "warmup_time": -1
    },
    "join_merge.Merge.time_merge_dataframe_integer_key": {
        "code": "class Merge:\n    def time_merge_dataframe_integer_key(self, sort):\n        merge(self.df, self.df2, on=\"key1\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]",
        "min_run_count": 2,
        "name": "join_merge.Merge.time_merge_dataframe_integer_key",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "92f383156ff8ad9c40e0c435dbf32a3c5a448df755cd8312c922858f4ddb0cb2",
        "warmup_time": -1
    },
    "join_merge.Merge.time_merge_dataframes_cross": {
        "code": "class Merge:\n    def time_merge_dataframes_cross(self, sort):\n        merge(self.left.loc[:2000], self.right.loc[:2000], how=\"cross\", sort=sort)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Merge:\n    def setup(self, sort):\n        N = 10000\n        indices = tm.makeStringIndex(N).values\n        indices2 = tm.makeStringIndex(N).values\n        key = np.tile(indices[:8000], 10)\n        key2 = np.tile(indices2[:8000], 10)\n        self.left = DataFrame(\n            {\"key\": key, \"key2\": key2, \"value\": np.random.randn(80000)}\n        )\n        self.right = DataFrame(\n            {\n                \"key\": indices[2000:],\n                \"key2\": indices2[2000:],\n                \"value2\": np.random.randn(8000),\n            }\n        )\n    \n        self.df = DataFrame(\n            {\n                \"key1\": np.tile(np.arange(500).repeat(10), 2),\n                \"key2\": np.tile(np.arange(250).repeat(10), 4),\n                \"value\": np.random.randn(10000),\n            }\n        )\n        self.df2 = DataFrame({\"key1\": np.arange(500), \"value2\": np.random.randn(500)})\n        self.df3 = self.df[:5000]",
        "min_run_count": 2,
        "name": "join_merge.Merge.time_merge_dataframes_cross",
        "number": 0,
        "param_names": [
            "sort"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6b9f6476e14b77f687462e3381bf77e3d1248656a9201faf8bf92a80e887c962",
        "warmup_time": -1
    },
    "join_merge.MergeAsof.time_by_int": {
        "code": "class MergeAsof:\n    def time_by_int(self, direction, tolerance):\n        merge_asof(\n            self.df1c,\n            self.df2c,\n            on=\"time\",\n            by=\"key2\",\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]",
        "min_run_count": 2,
        "name": "join_merge.MergeAsof.time_by_int",
        "number": 0,
        "param_names": [
            "direction",
            "tolerance"
        ],
        "params": [
            [
                "'backward'",
                "'forward'",
                "'nearest'"
            ],
            [
                "None",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9388814b37a8f7c3e8196e0e5e974f1114e5d09931e00ac3f102f86743babca9",
        "warmup_time": -1
    },
    "join_merge.MergeAsof.time_by_object": {
        "code": "class MergeAsof:\n    def time_by_object(self, direction, tolerance):\n        merge_asof(\n            self.df1b,\n            self.df2b,\n            on=\"time\",\n            by=\"key\",\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]",
        "min_run_count": 2,
        "name": "join_merge.MergeAsof.time_by_object",
        "number": 0,
        "param_names": [
            "direction",
            "tolerance"
        ],
        "params": [
            [
                "'backward'",
                "'forward'",
                "'nearest'"
            ],
            [
                "None",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "164ee691bc50a6d10e4f62c99daae4dce68786d7b02f5bd35af7bf33191d0405",
        "warmup_time": -1
    },
    "join_merge.MergeAsof.time_multiby": {
        "code": "class MergeAsof:\n    def time_multiby(self, direction, tolerance):\n        merge_asof(\n            self.df1e,\n            self.df2e,\n            on=\"time\",\n            by=[\"key\", \"key2\"],\n            direction=direction,\n            tolerance=tolerance,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]",
        "min_run_count": 2,
        "name": "join_merge.MergeAsof.time_multiby",
        "number": 0,
        "param_names": [
            "direction",
            "tolerance"
        ],
        "params": [
            [
                "'backward'",
                "'forward'",
                "'nearest'"
            ],
            [
                "None",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "464ed78df4c5a78bcd7350edc12851af5dd87d18c63ed889b0ee80e806eed6a1",
        "warmup_time": -1
    },
    "join_merge.MergeAsof.time_on_int": {
        "code": "class MergeAsof:\n    def time_on_int(self, direction, tolerance):\n        merge_asof(\n            self.df1a, self.df2a, on=\"time\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]",
        "min_run_count": 2,
        "name": "join_merge.MergeAsof.time_on_int",
        "number": 0,
        "param_names": [
            "direction",
            "tolerance"
        ],
        "params": [
            [
                "'backward'",
                "'forward'",
                "'nearest'"
            ],
            [
                "None",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a0ba76e01b99515f8c84950f1a4683fb1e2b601110a25798072287f3d1574ca1",
        "warmup_time": -1
    },
    "join_merge.MergeAsof.time_on_int32": {
        "code": "class MergeAsof:\n    def time_on_int32(self, direction, tolerance):\n        merge_asof(\n            self.df1d, self.df2d, on=\"time32\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]",
        "min_run_count": 2,
        "name": "join_merge.MergeAsof.time_on_int32",
        "number": 0,
        "param_names": [
            "direction",
            "tolerance"
        ],
        "params": [
            [
                "'backward'",
                "'forward'",
                "'nearest'"
            ],
            [
                "None",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5c26b3578593ec04d313f1cbf97df60936516fb7691a67ad03f78d68554fa57f",
        "warmup_time": -1
    },
    "join_merge.MergeAsof.time_on_uint64": {
        "code": "class MergeAsof:\n    def time_on_uint64(self, direction, tolerance):\n        merge_asof(\n            self.df1f, self.df2f, on=\"timeu64\", direction=direction, tolerance=tolerance\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeAsof:\n    def setup(self, direction, tolerance):\n        one_count = 200000\n        two_count = 1000000\n    \n        df1 = DataFrame(\n            {\n                \"time\": np.random.randint(0, one_count / 20, one_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), one_count),\n                \"key2\": np.random.randint(0, 25, one_count),\n                \"value1\": np.random.randn(one_count),\n            }\n        )\n        df2 = DataFrame(\n            {\n                \"time\": np.random.randint(0, two_count / 20, two_count),\n                \"key\": np.random.choice(list(string.ascii_uppercase), two_count),\n                \"key2\": np.random.randint(0, 25, two_count),\n                \"value2\": np.random.randn(two_count),\n            }\n        )\n    \n        df1 = df1.sort_values(\"time\")\n        df2 = df2.sort_values(\"time\")\n    \n        df1[\"time32\"] = np.int32(df1.time)\n        df2[\"time32\"] = np.int32(df2.time)\n    \n        df1[\"timeu64\"] = np.uint64(df1.time)\n        df2[\"timeu64\"] = np.uint64(df2.time)\n    \n        self.df1a = df1[[\"time\", \"value1\"]]\n        self.df2a = df2[[\"time\", \"value2\"]]\n        self.df1b = df1[[\"time\", \"key\", \"value1\"]]\n        self.df2b = df2[[\"time\", \"key\", \"value2\"]]\n        self.df1c = df1[[\"time\", \"key2\", \"value1\"]]\n        self.df2c = df2[[\"time\", \"key2\", \"value2\"]]\n        self.df1d = df1[[\"time32\", \"value1\"]]\n        self.df2d = df2[[\"time32\", \"value2\"]]\n        self.df1e = df1[[\"time\", \"key\", \"key2\", \"value1\"]]\n        self.df2e = df2[[\"time\", \"key\", \"key2\", \"value2\"]]\n        self.df1f = df1[[\"timeu64\", \"value1\"]]\n        self.df2f = df2[[\"timeu64\", \"value2\"]]",
        "min_run_count": 2,
        "name": "join_merge.MergeAsof.time_on_uint64",
        "number": 0,
        "param_names": [
            "direction",
            "tolerance"
        ],
        "params": [
            [
                "'backward'",
                "'forward'",
                "'nearest'"
            ],
            [
                "None",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "272c9034f60d2e7af35cd9d80009bb4f6d2ed987924efec03f83106e40c406be",
        "warmup_time": -1
    },
    "join_merge.MergeCategoricals.time_merge_cat": {
        "code": "class MergeCategoricals:\n    def time_merge_cat(self):\n        merge(self.left_cat, self.right_cat, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )",
        "min_run_count": 2,
        "name": "join_merge.MergeCategoricals.time_merge_cat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3185a144b7b998e9d03b6b7aece288eccad44a7d544886cc1de2ef082b9ce10e",
        "warmup_time": -1
    },
    "join_merge.MergeCategoricals.time_merge_object": {
        "code": "class MergeCategoricals:\n    def time_merge_object(self):\n        merge(self.left_object, self.right_object, on=\"X\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeCategoricals:\n    def setup(self):\n        self.left_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Y\": np.random.choice([\"one\", \"two\", \"three\"], size=(10000,)),\n            }\n        )\n    \n        self.right_object = DataFrame(\n            {\n                \"X\": np.random.choice(range(0, 10), size=(10000,)),\n                \"Z\": np.random.choice([\"jjj\", \"kkk\", \"sss\"], size=(10000,)),\n            }\n        )\n    \n        self.left_cat = self.left_object.assign(\n            Y=self.left_object[\"Y\"].astype(\"category\")\n        )\n        self.right_cat = self.right_object.assign(\n            Z=self.right_object[\"Z\"].astype(\"category\")\n        )",
        "min_run_count": 2,
        "name": "join_merge.MergeCategoricals.time_merge_object",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2ff935e4ad35fa42b10fa10d180a6a0db23c24158ad8456205a7cbf56c6a5665",
        "warmup_time": -1
    },
    "join_merge.MergeOrdered.time_merge_ordered": {
        "code": "class MergeOrdered:\n    def time_merge_ordered(self):\n        merge_ordered(self.left, self.right, on=\"key\", left_by=\"group\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MergeOrdered:\n    def setup(self):\n        groups = tm.makeStringIndex(10).values\n        self.left = DataFrame(\n            {\n                \"group\": groups.repeat(5000),\n                \"key\": np.tile(np.arange(0, 10000, 2), 10),\n                \"lvalue\": np.random.randn(50000),\n            }\n        )\n        self.right = DataFrame(\n            {\"key\": np.arange(10000), \"rvalue\": np.random.randn(10000)}\n        )",
        "min_run_count": 2,
        "name": "join_merge.MergeOrdered.time_merge_ordered",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5112a00cde6581c94729aa5bf94cb97a7e4bbc7887d6cee6e2fd3ba7aaf8bf5e",
        "warmup_time": -1
    },
    "libs.CacheReadonly.time_cache_readonly": {
        "code": "class CacheReadonly:\n    def time_cache_readonly(self):\n        self.obj.prop\n\n    def setup(self):\n        class Foo:\n            @cache_readonly\n            def prop(self):\n                return 5\n    \n        self.obj = Foo()",
        "min_run_count": 2,
        "name": "libs.CacheReadonly.time_cache_readonly",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0c1cb69a185e93f75c8a4df1942cf6b4e0cf583d0eb2f7e80d1df4e75305b788",
        "warmup_time": -1
    },
    "libs.FastZip.time_lib_fast_zip": {
        "code": "class FastZip:\n    def time_lib_fast_zip(self):\n        lib.fast_zip(self.col_array_list)\n\n    def setup(self):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        col_array = np.vstack([key1, key2, np.random.randn(N * K)])\n        col_array2 = col_array.copy()\n        col_array2[:, :10000] = np.nan\n        self.col_array_list = list(col_array)",
        "min_run_count": 2,
        "name": "libs.FastZip.time_lib_fast_zip",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "517a0b5f8fe63a2ad52291c0793f9bf201fbe1c44d21e698e04e880eaa98b0b4",
        "warmup_time": -1
    },
    "libs.InferDtype.time_infer_dtype": {
        "code": "class InferDtype:\n    def time_infer_dtype(self, dtype):\n        infer_dtype(self.data_dict[dtype], skipna=False)",
        "min_run_count": 2,
        "name": "libs.InferDtype.time_infer_dtype",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'np-object'",
                "'py-object'",
                "'np-null'",
                "'py-null'",
                "'np-int'",
                "'np-floating'",
                "'empty'",
                "'bytes'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "125f86966c05a7552f7d61e8833a505c865982149242f645b314a569f9830a3e",
        "warmup_time": -1
    },
    "libs.InferDtype.time_infer_dtype_skipna": {
        "code": "class InferDtype:\n    def time_infer_dtype_skipna(self, dtype):\n        infer_dtype(self.data_dict[dtype], skipna=True)",
        "min_run_count": 2,
        "name": "libs.InferDtype.time_infer_dtype_skipna",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'np-object'",
                "'py-object'",
                "'np-null'",
                "'py-null'",
                "'np-int'",
                "'np-floating'",
                "'empty'",
                "'bytes'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "92424cbc247a56269a3db019273c9b16434c61cd8f83fd7210ea2168ac4e31e0",
        "warmup_time": -1
    },
    "libs.ScalarListLike.time_is_list_like": {
        "code": "class ScalarListLike:\n    def time_is_list_like(self, param):\n        is_list_like(param)",
        "min_run_count": 2,
        "name": "libs.ScalarListLike.time_is_list_like",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "0",
                "1.0",
                "(1+2j)",
                "True",
                "'foo'",
                "b'bar'",
                "None",
                "numpy.datetime64('1970-01-01T00:00:00.000000123')",
                "numpy.timedelta64(123,'ns')",
                "NaT",
                "<NA>",
                "array('123', dtype='<U3')",
                "array([1, 2, 3])",
                "{0: 1}",
                "{1, 2, 3}",
                "[1, 2, 3]",
                "(1, 2, 3)"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f12c7f398bcc1c4a71e6dbe7b8aec6631a2565dd2a614a6f834dee7e64388bf8",
        "warmup_time": -1
    },
    "libs.ScalarListLike.time_is_scalar": {
        "code": "class ScalarListLike:\n    def time_is_scalar(self, param):\n        is_scalar(param)",
        "min_run_count": 2,
        "name": "libs.ScalarListLike.time_is_scalar",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "0",
                "1.0",
                "(1+2j)",
                "True",
                "'foo'",
                "b'bar'",
                "None",
                "numpy.datetime64('1970-01-01T00:00:00.000000123')",
                "numpy.timedelta64(123,'ns')",
                "NaT",
                "<NA>",
                "array('123', dtype='<U3')",
                "array([1, 2, 3])",
                "{0: 1}",
                "{1, 2, 3}",
                "[1, 2, 3]",
                "(1, 2, 3)"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ec357011e1e42690c47ad59e42ea37c1b167ef442f92e787301c3ef26d40a34d",
        "warmup_time": -1
    },
    "multiindex_object.CategoricalLevel.time_categorical_level": {
        "code": "class CategoricalLevel:\n    def time_categorical_level(self):\n        self.df.set_index([\"a\", \"b\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass CategoricalLevel:\n    def setup(self):\n    \n        self.df = DataFrame(\n            {\n                \"a\": np.arange(1_000_000, dtype=np.int32),\n                \"b\": np.arange(1_000_000, dtype=np.int64),\n                \"c\": np.arange(1_000_000, dtype=float),\n            }\n        ).astype({\"a\": \"category\", \"b\": \"category\"})",
        "min_run_count": 2,
        "name": "multiindex_object.CategoricalLevel.time_categorical_level",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9bcd6b6b61d8a4ae3095530cfe0e0ea843775210ad6aa47075a49f04b670b9ea",
        "warmup_time": -1
    },
    "multiindex_object.Duplicated.time_duplicated": {
        "code": "class Duplicated:\n    def time_duplicated(self):\n        self.mi.duplicated()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicated:\n    def setup(self):\n        n, k = 200, 5000\n        levels = [np.arange(n), tm.makeStringIndex(n).values, 1000 + np.arange(n)]\n        codes = [np.random.choice(n, (k * n)) for lev in levels]\n        self.mi = MultiIndex(levels=levels, codes=codes)",
        "min_run_count": 2,
        "name": "multiindex_object.Duplicated.time_duplicated",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "dc96303f763f936d1ea9761a0820f81dfa38bff3c381e63bde16ef21be991fe9",
        "warmup_time": -1
    },
    "multiindex_object.Duplicates.time_remove_unused_levels": {
        "code": "class Duplicates:\n    def time_remove_unused_levels(self):\n        self.mi_unused_levels.remove_unused_levels()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Duplicates:\n    def setup(self):\n        size = 65536\n        arrays = [np.random.randint(0, 8192, size), np.random.randint(0, 1024, size)]\n        mask = np.random.rand(size) < 0.1\n        self.mi_unused_levels = MultiIndex.from_arrays(arrays)\n        self.mi_unused_levels = self.mi_unused_levels[mask]",
        "min_run_count": 2,
        "name": "multiindex_object.Duplicates.time_remove_unused_levels",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "858a4d9728167fda18b01dd248d011becaf52569cc3789ebc23781748020a547",
        "warmup_time": -1
    },
    "multiindex_object.Equals.time_equals_non_object_index": {
        "code": "class Equals:\n    def time_equals_non_object_index(self):\n        self.mi_large_slow.equals(self.idx_non_object)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Equals:\n    def setup(self):\n        idx_large_fast = RangeIndex(100000)\n        idx_small_slow = date_range(start=\"1/1/2012\", periods=1)\n        self.mi_large_slow = MultiIndex.from_product([idx_large_fast, idx_small_slow])\n    \n        self.idx_non_object = RangeIndex(1)",
        "min_run_count": 2,
        "name": "multiindex_object.Equals.time_equals_non_object_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "670ae29fa38e3f25c93a8fe7085dd856137ada08f63f625b17da442a35a357b8",
        "warmup_time": -1
    },
    "multiindex_object.GetLoc.time_large_get_loc": {
        "code": "class GetLoc:\n    def time_large_get_loc(self):\n        self.mi_large.get_loc((999, 19, \"Z\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.GetLoc.time_large_get_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "dd084286aabcc048d0407dfacebe59f29ed1f976d92d013a0a10f35ba2e96bdb",
        "warmup_time": -1
    },
    "multiindex_object.GetLoc.time_large_get_loc_warm": {
        "code": "class GetLoc:\n    def time_large_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_large.get_loc((999, 19, \"Z\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.GetLoc.time_large_get_loc_warm",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "137653619e4d1b432e07d94aa7a9cf46441e320de449aa65f5129efc13888912",
        "warmup_time": -1
    },
    "multiindex_object.GetLoc.time_med_get_loc": {
        "code": "class GetLoc:\n    def time_med_get_loc(self):\n        self.mi_med.get_loc((999, 9, \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.GetLoc.time_med_get_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b783d9cb5dbdc6787a0879e0f8c0862c4014d5ea0611abb97c342d46f77826e1",
        "warmup_time": -1
    },
    "multiindex_object.GetLoc.time_med_get_loc_warm": {
        "code": "class GetLoc:\n    def time_med_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_med.get_loc((999, 9, \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.GetLoc.time_med_get_loc_warm",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "50ea4f6a67d9f88227e60e668996edef05b7564987506a1145e7b2c23a2ccb41",
        "warmup_time": -1
    },
    "multiindex_object.GetLoc.time_small_get_loc_warm": {
        "code": "class GetLoc:\n    def time_small_get_loc_warm(self):\n        for _ in range(1000):\n            self.mi_small.get_loc((99, \"A\", \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.GetLoc.time_small_get_loc_warm",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fe1c2475d50cac160a619e2371fc123f6053a4346c2f4d01018f499d4cfec4e7",
        "warmup_time": -1
    },
    "multiindex_object.GetLoc.time_string_get_loc": {
        "code": "class GetLoc:\n    def time_string_get_loc(self):\n        self.mi_small.get_loc((99, \"A\", \"A\"))\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetLoc:\n    def setup(self):\n        self.mi_large = MultiIndex.from_product(\n            [np.arange(1000), np.arange(20), list(string.ascii_letters)],\n            names=[\"one\", \"two\", \"three\"],\n        )\n        self.mi_med = MultiIndex.from_product(\n            [np.arange(1000), np.arange(10), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )\n        self.mi_small = MultiIndex.from_product(\n            [np.arange(100), list(\"A\"), list(\"A\")], names=[\"one\", \"two\", \"three\"]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.GetLoc.time_string_get_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e96912b143865fa80131f906e8f63d1f3c40b3d142b8571de3b1b9615adf1801",
        "warmup_time": -1
    },
    "multiindex_object.Integer.time_get_indexer": {
        "code": "class Integer:\n    def time_get_indexer(self):\n        self.mi_int.get_indexer(self.obj_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.Integer.time_get_indexer",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fbdc58718b979f87ea6a8c82f9bc10f0b1ebc5fb70ea385528f54cff5edb41e7",
        "warmup_time": -1
    },
    "multiindex_object.Integer.time_get_indexer_and_backfill": {
        "code": "class Integer:\n    def time_get_indexer_and_backfill(self):\n        self.mi_int.get_indexer(self.other_mi_many_mismatches, method=\"backfill\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.Integer.time_get_indexer_and_backfill",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f3a337ce0bc68b9b181e2f10744c48edfc0aea4481ed3ae1d3daf65dc1c9d53b",
        "warmup_time": -1
    },
    "multiindex_object.Integer.time_get_indexer_and_pad": {
        "code": "class Integer:\n    def time_get_indexer_and_pad(self):\n        self.mi_int.get_indexer(self.other_mi_many_mismatches, method=\"pad\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.Integer.time_get_indexer_and_pad",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ee2af65e57a49d84022609e04c926f032e6e248514ffaccf6af4a25038d13f78",
        "warmup_time": -1
    },
    "multiindex_object.Integer.time_is_monotonic": {
        "code": "class Integer:\n    def time_is_monotonic(self):\n        self.mi_int.is_monotonic\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Integer:\n    def setup(self):\n        self.mi_int = MultiIndex.from_product(\n            [np.arange(1000), np.arange(1000)], names=[\"one\", \"two\"]\n        )\n        self.obj_index = np.array(\n            [\n                (0, 10),\n                (0, 11),\n                (0, 12),\n                (0, 13),\n                (0, 14),\n                (0, 15),\n                (0, 16),\n                (0, 17),\n                (0, 18),\n                (0, 19),\n            ],\n            dtype=object,\n        )\n        self.other_mi_many_mismatches = MultiIndex.from_tuples(\n            [\n                (-7, 41),\n                (-2, 3),\n                (-0.7, 5),\n                (0, 0),\n                (0, 1.5),\n                (0, 340),\n                (0, 1001),\n                (1, -4),\n                (1, 20),\n                (1, 1040),\n                (432, -5),\n                (432, 17),\n                (439, 165.5),\n                (998, -4),\n                (998, 24065),\n                (999, 865.2),\n                (999, 1000),\n                (1045, -843),\n            ]\n        )",
        "min_run_count": 2,
        "name": "multiindex_object.Integer.time_is_monotonic",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "669bbad711376610b96fc5afdf2576db79f9c1f9f6250550069ad02f6f3230ec",
        "warmup_time": -1
    },
    "multiindex_object.SetOperations.time_operation": {
        "code": "class SetOperations:\n    def time_operation(self, index_structure, dtype, method):\n        getattr(self.left, method)(self.right)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SetOperations:\n    def setup(self, index_structure, dtype, method):\n        N = 10 ** 5\n        level1 = range(1000)\n    \n        level2 = date_range(start=\"1/1/2000\", periods=N // 1000)\n        dates_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = range(N // 1000)\n        int_left = MultiIndex.from_product([level1, level2])\n    \n        level2 = tm.makeStringIndex(N // 1000).values\n        str_left = MultiIndex.from_product([level1, level2])\n    \n        data = {\n            \"datetime\": dates_left,\n            \"int\": int_left,\n            \"string\": str_left,\n        }\n    \n        if index_structure == \"non_monotonic\":\n            data = {k: mi[::-1] for k, mi in data.items()}\n    \n        data = {k: {\"left\": mi, \"right\": mi[:-1]} for k, mi in data.items()}\n        self.left = data[dtype][\"left\"]\n        self.right = data[dtype][\"right\"]",
        "min_run_count": 2,
        "name": "multiindex_object.SetOperations.time_operation",
        "number": 0,
        "param_names": [
            "index_structure",
            "dtype",
            "method"
        ],
        "params": [
            [
                "'monotonic'",
                "'non_monotonic'"
            ],
            [
                "'datetime'",
                "'int'",
                "'string'"
            ],
            [
                "'intersection'",
                "'union'",
                "'symmetric_difference'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7dad17888d836dfdad3b6a77ca03ff0eef0c13f059df7853a7a3d89ccba62e8e",
        "warmup_time": -1
    },
    "multiindex_object.Sortlevel.time_sortlevel_int64": {
        "code": "class Sortlevel:\n    def time_sortlevel_int64(self):\n        self.mi_int.sortlevel()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))",
        "min_run_count": 2,
        "name": "multiindex_object.Sortlevel.time_sortlevel_int64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a8b2951c7f045b903e0cd3abcea3295e405768580e65c267316e5d7993c375e4",
        "warmup_time": -1
    },
    "multiindex_object.Sortlevel.time_sortlevel_one": {
        "code": "class Sortlevel:\n    def time_sortlevel_one(self):\n        self.mi.sortlevel(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))",
        "min_run_count": 2,
        "name": "multiindex_object.Sortlevel.time_sortlevel_one",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "17b98983847e3899dd3aecd51f007b8eee9219cafba180bcd18d23a273f074e4",
        "warmup_time": -1
    },
    "multiindex_object.Sortlevel.time_sortlevel_zero": {
        "code": "class Sortlevel:\n    def time_sortlevel_zero(self):\n        self.mi.sortlevel(0)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Sortlevel:\n    def setup(self):\n        n = 1182720\n        low, high = -4096, 4096\n        arrs = [\n            np.repeat(np.random.randint(low, high, (n // k)), k)\n            for k in [11, 7, 5, 3, 1]\n        ]\n        self.mi_int = MultiIndex.from_arrays(arrs)[np.random.permutation(n)]\n    \n        a = np.repeat(np.arange(100), 1000)\n        b = np.tile(np.arange(1000), 100)\n        self.mi = MultiIndex.from_arrays([a, b])\n        self.mi = self.mi.take(np.random.permutation(np.arange(100000)))",
        "min_run_count": 2,
        "name": "multiindex_object.Sortlevel.time_sortlevel_zero",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1f7d209d70d9ce641fdba817c8598ab8212457073e4f1218e5ecec974b8af00b",
        "warmup_time": -1
    },
    "multiindex_object.Values.time_datetime_level_values_copy": {
        "code": "class Values:\n    def time_datetime_level_values_copy(self, mi):\n        mi.copy().values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n    \n        level1 = range(1000)\n        level2 = date_range(start=\"1/1/2012\", periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi",
        "min_run_count": 2,
        "name": "multiindex_object.Values.time_datetime_level_values_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "multiindex_object:155",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c4016e908e200db60dc74572449fd83309d6866f39c59eeb997b3b7c8273984b",
        "warmup_time": -1
    },
    "multiindex_object.Values.time_datetime_level_values_sliced": {
        "code": "class Values:\n    def time_datetime_level_values_sliced(self, mi):\n        mi[:10].values\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Values:\n    def setup_cache(self):\n    \n        level1 = range(1000)\n        level2 = date_range(start=\"1/1/2012\", periods=100)\n        mi = MultiIndex.from_product([level1, level2])\n        return mi",
        "min_run_count": 2,
        "name": "multiindex_object.Values.time_datetime_level_values_sliced",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "multiindex_object:155",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fc55c7789deed8b7f3265ab9f4a1395d1fc9f57c447d2af072a54cc0808b4f0b",
        "warmup_time": -1
    },
    "package.TimeImport.time_import": {
        "code": "class TimeImport:\n    def time_import(self):\n        # on py37+ we the \"-X importtime\" usage gives us a more precise\n        #  measurement of the import time we actually care about,\n        #  without the subprocess or interpreter overhead\n        cmd = [sys.executable, \"-X\", \"importtime\", \"-c\", \"import pandas as pd\"]\n        p = subprocess.run(cmd, stderr=subprocess.PIPE)\n    \n        line = p.stderr.splitlines()[-1]\n        field = line.split(b\"|\")[-2].strip()\n        total = int(field)  # microseconds\n        return total",
        "min_run_count": 2,
        "name": "package.TimeImport.time_import",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fe157d537aaadd3a9a6ba7cebe36d3e66b36da9a5bd9bf2c0d2e3b2f7f6b8069",
        "warmup_time": -1
    },
    "period.Algorithms.time_drop_duplicates": {
        "code": "class Algorithms:\n    def time_drop_duplicates(self, typ):\n        self.vector.drop_duplicates()\n\n    def setup(self, typ):\n        data = [\n            Period(\"2011-01\", freq=\"M\"),\n            Period(\"2011-02\", freq=\"M\"),\n            Period(\"2011-03\", freq=\"M\"),\n            Period(\"2011-04\", freq=\"M\"),\n        ]\n    \n        if typ == \"index\":\n            self.vector = PeriodIndex(data * 1000, freq=\"M\")\n        elif typ == \"series\":\n            self.vector = Series(data * 1000)",
        "min_run_count": 2,
        "name": "period.Algorithms.time_drop_duplicates",
        "number": 0,
        "param_names": [
            "typ"
        ],
        "params": [
            [
                "'index'",
                "'series'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5ed71a0e29ea9fe94acdf37fe778becc6a166703e59fe06b43693190e73c358c",
        "warmup_time": -1
    },
    "period.Algorithms.time_value_counts": {
        "code": "class Algorithms:\n    def time_value_counts(self, typ):\n        self.vector.value_counts()\n\n    def setup(self, typ):\n        data = [\n            Period(\"2011-01\", freq=\"M\"),\n            Period(\"2011-02\", freq=\"M\"),\n            Period(\"2011-03\", freq=\"M\"),\n            Period(\"2011-04\", freq=\"M\"),\n        ]\n    \n        if typ == \"index\":\n            self.vector = PeriodIndex(data * 1000, freq=\"M\")\n        elif typ == \"series\":\n            self.vector = Series(data * 1000)",
        "min_run_count": 2,
        "name": "period.Algorithms.time_value_counts",
        "number": 0,
        "param_names": [
            "typ"
        ],
        "params": [
            [
                "'index'",
                "'series'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7aaad3304a09d800100a2dc5f7da82c36953722c7da6aca2ca4c2e446a3badc8",
        "warmup_time": -1
    },
    "period.DataFramePeriodColumn.time_set_index": {
        "code": "class DataFramePeriodColumn:\n    def time_set_index(self):\n        # GH#21582 limited by comparisons of Period objects\n        self.df[\"col2\"] = self.rng\n        self.df.set_index(\"col2\", append=True)\n\n    def setup(self):\n        self.rng = period_range(start=\"1/1/1990\", freq=\"S\", periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))",
        "min_run_count": 2,
        "name": "period.DataFramePeriodColumn.time_set_index",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "223baa21285346a0b70e9d11fe853a0b156662cd2530575dc66cfcb8d65cf46a",
        "warmup_time": -1
    },
    "period.DataFramePeriodColumn.time_setitem_period_column": {
        "code": "class DataFramePeriodColumn:\n    def time_setitem_period_column(self):\n        self.df[\"col\"] = self.rng\n\n    def setup(self):\n        self.rng = period_range(start=\"1/1/1990\", freq=\"S\", periods=20000)\n        self.df = DataFrame(index=range(len(self.rng)))",
        "min_run_count": 2,
        "name": "period.DataFramePeriodColumn.time_setitem_period_column",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e7044b31af083678ecf627851ca14fa1108e6ec19cd7acf41ebe60f0283fefe8",
        "warmup_time": -1
    },
    "period.Indexing.time_align": {
        "code": "class Indexing:\n    def time_align(self):\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]",
        "min_run_count": 2,
        "name": "period.Indexing.time_align",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7ba91f5b4184a97b1e578ce06acd5823a15ef927984c534ef97a97209494f3e9",
        "warmup_time": -1
    },
    "period.Indexing.time_get_loc": {
        "code": "class Indexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.period)\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]",
        "min_run_count": 2,
        "name": "period.Indexing.time_get_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "16c0233f1354d0efad7e0568b42faab3ceda761dbe321e610db062449c038b2b",
        "warmup_time": -1
    },
    "period.Indexing.time_intersection": {
        "code": "class Indexing:\n    def time_intersection(self):\n        self.index[:750].intersection(self.index[250:])\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]",
        "min_run_count": 2,
        "name": "period.Indexing.time_intersection",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e473ad8ce23861754e1a2322452188035f32546b5106e9c354504575f161c9dc",
        "warmup_time": -1
    },
    "period.Indexing.time_series_loc": {
        "code": "class Indexing:\n    def time_series_loc(self):\n        self.series.loc[self.period]\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]",
        "min_run_count": 2,
        "name": "period.Indexing.time_series_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "051bdec8fea0886aa445b372b56bf9dc434ca870d0168882015b967bb1545aa4",
        "warmup_time": -1
    },
    "period.Indexing.time_shallow_copy": {
        "code": "class Indexing:\n    def time_shallow_copy(self):\n        self.index._view()\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]",
        "min_run_count": 2,
        "name": "period.Indexing.time_shallow_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ec340ef909e8666710788924d6a879a98eceecf319ce9ddaa3afaef7f7c6a891",
        "warmup_time": -1
    },
    "period.Indexing.time_unique": {
        "code": "class Indexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.period = self.index[500]",
        "min_run_count": 2,
        "name": "period.Indexing.time_unique",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c4ce9c886be5dcc91f24921a741cee9552a169c54f69f0ec4893b19145ca6cda",
        "warmup_time": -1
    },
    "period.PeriodIndexConstructor.time_from_date_range": {
        "code": "class PeriodIndexConstructor:\n    def time_from_date_range(self, freq, is_offset):\n        PeriodIndex(self.rng, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq",
        "min_run_count": 2,
        "name": "period.PeriodIndexConstructor.time_from_date_range",
        "number": 0,
        "param_names": [
            "freq",
            "is_offset"
        ],
        "params": [
            [
                "'D'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "90341c890b6fd853e93fe5ad5a5d9935048545a0c2bf70da9324aca627215961",
        "warmup_time": -1
    },
    "period.PeriodIndexConstructor.time_from_ints": {
        "code": "class PeriodIndexConstructor:\n    def time_from_ints(self, freq, is_offset):\n        PeriodIndex(self.ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq",
        "min_run_count": 2,
        "name": "period.PeriodIndexConstructor.time_from_ints",
        "number": 0,
        "param_names": [
            "freq",
            "is_offset"
        ],
        "params": [
            [
                "'D'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "40e20dbe294496152b0cab99ad8277ec6836602167d363e0c665de9915971d7d",
        "warmup_time": -1
    },
    "period.PeriodIndexConstructor.time_from_ints_daily": {
        "code": "class PeriodIndexConstructor:\n    def time_from_ints_daily(self, freq, is_offset):\n        PeriodIndex(self.daily_ints, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq",
        "min_run_count": 2,
        "name": "period.PeriodIndexConstructor.time_from_ints_daily",
        "number": 0,
        "param_names": [
            "freq",
            "is_offset"
        ],
        "params": [
            [
                "'D'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7ec1c957be1d06e33b08c4eb1a645648cba0172013a8b73a1e8c8d8f8e5725a8",
        "warmup_time": -1
    },
    "period.PeriodIndexConstructor.time_from_pydatetime": {
        "code": "class PeriodIndexConstructor:\n    def time_from_pydatetime(self, freq, is_offset):\n        PeriodIndex(self.rng2, freq=freq)\n\n    def setup(self, freq, is_offset):\n        self.rng = date_range(\"1985\", periods=1000)\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\n        self.ints = list(range(2000, 3000))\n        self.daily_ints = (\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\n        )\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq",
        "min_run_count": 2,
        "name": "period.PeriodIndexConstructor.time_from_pydatetime",
        "number": 0,
        "param_names": [
            "freq",
            "is_offset"
        ],
        "params": [
            [
                "'D'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2e9a86e7434b9d0777e5ccc8fc9165eaf99b3ae701c88bb9a2f2bfbb3a8742c1",
        "warmup_time": -1
    },
    "plotting.BackendLoading.time_get_plot_backend": {
        "code": "class BackendLoading:\n    def time_get_plot_backend(self):\n        _get_plot_backend(\"my_backend\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass BackendLoading:\n    def setup(self):\n        dist = pkg_resources.get_distribution(\"pandas\")\n        spec = importlib.machinery.ModuleSpec(\"my_backend\", None)\n        mod = importlib.util.module_from_spec(spec)\n        mod.plot = lambda *args, **kwargs: 1\n    \n        backends = pkg_resources.get_entry_map(\"pandas\")\n        my_entrypoint = pkg_resources.EntryPoint(\n            \"pandas_plotting_backend\", mod.__name__, dist=dist\n        )\n        backends[\"pandas_plotting_backends\"][mod.__name__] = my_entrypoint\n        for i in range(10):\n            backends[\"pandas_plotting_backends\"][str(i)] = my_entrypoint\n        sys.modules[\"my_backend\"] = mod",
        "min_run_count": 2,
        "name": "plotting.BackendLoading.time_get_plot_backend",
        "number": 1,
        "param_names": [],
        "params": [],
        "repeat": 1,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1bff19c5665b66ee248c44123bb06a284926260cb79caa71d59b4e0f5e63a491",
        "warmup_time": 0
    },
    "plotting.FramePlotting.time_frame_plot": {
        "code": "class FramePlotting:\n    def time_frame_plot(self, kind):\n        self.df.plot(x=\"x\", y=\"y\", kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FramePlotting:\n    def setup(self, kind):\n        if kind in [\"bar\", \"barh\", \"pie\"]:\n            n = 100\n        elif kind in [\"kde\", \"scatter\", \"hexbin\"]:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.x = Series(np.random.randn(n))\n        self.y = Series(np.random.randn(n))\n        if kind in [\"area\", \"pie\"]:\n            self.x = self.x.abs()\n            self.y = self.y.abs()\n        self.df = DataFrame({\"x\": self.x, \"y\": self.y})",
        "min_run_count": 2,
        "name": "plotting.FramePlotting.time_frame_plot",
        "number": 0,
        "param_names": [
            "kind"
        ],
        "params": [
            [
                "'line'",
                "'bar'",
                "'area'",
                "'barh'",
                "'hist'",
                "'kde'",
                "'pie'",
                "'scatter'",
                "'hexbin'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d6c19f0e6ee8994eb981863b029fa07bc3dc6e28ca77fd1947a32124682e279a",
        "warmup_time": -1
    },
    "plotting.Misc.time_plot_andrews_curves": {
        "code": "class Misc:\n    def time_plot_andrews_curves(self):\n        andrews_curves(self.df, \"Name\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Misc:\n    def setup(self):\n        N = 500\n        M = 10\n        self.df = DataFrame(np.random.randn(N, M))\n        self.df[\"Name\"] = [\"A\"] * N",
        "min_run_count": 2,
        "name": "plotting.Misc.time_plot_andrews_curves",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c5cdb631131db0763b96053825ebc29d36564b7efc93174553deebff526d0e51",
        "warmup_time": -1
    },
    "plotting.SeriesPlotting.time_series_plot": {
        "code": "class SeriesPlotting:\n    def time_series_plot(self, kind):\n        self.s.plot(kind=kind)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesPlotting:\n    def setup(self, kind):\n        if kind in [\"bar\", \"barh\", \"pie\"]:\n            n = 100\n        elif kind in [\"kde\"]:\n            n = 10000\n        else:\n            n = 1000000\n    \n        self.s = Series(np.random.randn(n))\n        if kind in [\"area\", \"pie\"]:\n            self.s = self.s.abs()",
        "min_run_count": 2,
        "name": "plotting.SeriesPlotting.time_series_plot",
        "number": 0,
        "param_names": [
            "kind"
        ],
        "params": [
            [
                "'line'",
                "'bar'",
                "'area'",
                "'barh'",
                "'hist'",
                "'kde'",
                "'pie'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "160ab68dd1bbcfdc4cb7ac7c745857d954d7b49e2140f072e93341253436ffb2",
        "warmup_time": -1
    },
    "plotting.TimeseriesPlotting.time_plot_irregular": {
        "code": "class TimeseriesPlotting:\n    def time_plot_irregular(self):\n        self.df2.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )",
        "min_run_count": 2,
        "name": "plotting.TimeseriesPlotting.time_plot_irregular",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eebbebf937fc740e9be07af175a3643c600ac60a98e1f1606d1ed7150b2966b0",
        "warmup_time": -1
    },
    "plotting.TimeseriesPlotting.time_plot_regular": {
        "code": "class TimeseriesPlotting:\n    def time_plot_regular(self):\n        self.df.plot()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )",
        "min_run_count": 2,
        "name": "plotting.TimeseriesPlotting.time_plot_regular",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c3871908c149bdf0cd9d3c7cdce5ed7bd993762db8bacec201061775ac030be2",
        "warmup_time": -1
    },
    "plotting.TimeseriesPlotting.time_plot_regular_compat": {
        "code": "class TimeseriesPlotting:\n    def time_plot_regular_compat(self):\n        self.df.plot(x_compat=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )",
        "min_run_count": 2,
        "name": "plotting.TimeseriesPlotting.time_plot_regular_compat",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6b83eb693399183277a784aee0704171f06e4913b66ddd6bddde0dcc2fb427ff",
        "warmup_time": -1
    },
    "plotting.TimeseriesPlotting.time_plot_table": {
        "code": "class TimeseriesPlotting:\n    def time_plot_table(self):\n        self.df.plot(table=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeseriesPlotting:\n    def setup(self):\n        N = 2000\n        M = 5\n        idx = date_range(\"1/1/1975\", periods=N)\n        self.df = DataFrame(np.random.randn(N, M), index=idx)\n    \n        idx_irregular = DatetimeIndex(\n            np.concatenate((idx.values[0:10], idx.values[12:]))\n        )\n        self.df2 = DataFrame(\n            np.random.randn(len(idx_irregular), M), index=idx_irregular\n        )",
        "min_run_count": 2,
        "name": "plotting.TimeseriesPlotting.time_plot_table",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2c526eb7965a6c381c8aa22565224994f1cbd2c378f4a0aa87af283821f76da3",
        "warmup_time": -1
    },
    "reindex.Align.time_align_series_irregular_string": {
        "code": "class Align:\n    def time_align_series_irregular_string(self):\n        self.x + self.y\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Align:\n    def setup(self):\n        n = 50000\n        indices = tm.makeStringIndex(n)\n        subsample_size = 40000\n        self.x = Series(np.random.randn(n), indices)\n        self.y = Series(\n            np.random.randn(subsample_size),\n            index=np.random.choice(indices, subsample_size, replace=False),\n        )",
        "min_run_count": 2,
        "name": "reindex.Align.time_align_series_irregular_string",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5317d292c85b136c6b3c6d6afee0e3e55ee2ebe744d776079d6343067c2cf36a",
        "warmup_time": -1
    },
    "reindex.DropDuplicates.time_frame_drop_dups": {
        "code": "class DropDuplicates:\n    def time_frame_drop_dups(self, inplace):\n        self.df.drop_duplicates([\"key1\", \"key2\"], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))",
        "min_run_count": 2,
        "name": "reindex.DropDuplicates.time_frame_drop_dups",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5601e84063057792b96f079167feef132981d69442c96b9925041d93fc0695f3",
        "warmup_time": -1
    },
    "reindex.DropDuplicates.time_frame_drop_dups_bool": {
        "code": "class DropDuplicates:\n    def time_frame_drop_dups_bool(self, inplace):\n        self.df_bool.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))",
        "min_run_count": 2,
        "name": "reindex.DropDuplicates.time_frame_drop_dups_bool",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "07a191dda9869dd1ff45d8e8c24e5f1dc8743f52d1c79a43aff5caf7138065d4",
        "warmup_time": -1
    },
    "reindex.DropDuplicates.time_frame_drop_dups_int": {
        "code": "class DropDuplicates:\n    def time_frame_drop_dups_int(self, inplace):\n        self.df_int.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))",
        "min_run_count": 2,
        "name": "reindex.DropDuplicates.time_frame_drop_dups_int",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "12a616d1f0f8f398f549d4b0ac3dac2debd8da94ac4c6593e17c7ccd76c2d49f",
        "warmup_time": -1
    },
    "reindex.DropDuplicates.time_frame_drop_dups_na": {
        "code": "class DropDuplicates:\n    def time_frame_drop_dups_na(self, inplace):\n        self.df_nan.drop_duplicates([\"key1\", \"key2\"], inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))",
        "min_run_count": 2,
        "name": "reindex.DropDuplicates.time_frame_drop_dups_na",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4e56e5907b5b39bbc60adf72b6012b2650441408d0ccdc903c1cb1d2c0ef0e38",
        "warmup_time": -1
    },
    "reindex.DropDuplicates.time_series_drop_dups_int": {
        "code": "class DropDuplicates:\n    def time_series_drop_dups_int(self, inplace):\n        self.s.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))",
        "min_run_count": 2,
        "name": "reindex.DropDuplicates.time_series_drop_dups_int",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "00b3ba44340a5448eea11f3eaf2869149b056d6b590cb8837529de4a00e1eefd",
        "warmup_time": -1
    },
    "reindex.DropDuplicates.time_series_drop_dups_string": {
        "code": "class DropDuplicates:\n    def time_series_drop_dups_string(self, inplace):\n        self.s_str.drop_duplicates(inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DropDuplicates:\n    def setup(self, inplace):\n        N = 10000\n        K = 10\n        key1 = tm.makeStringIndex(N).values.repeat(K)\n        key2 = tm.makeStringIndex(N).values.repeat(K)\n        self.df = DataFrame(\n            {\"key1\": key1, \"key2\": key2, \"value\": np.random.randn(N * K)}\n        )\n        self.df_nan = self.df.copy()\n        self.df_nan.iloc[:10000, :] = np.nan\n    \n        self.s = Series(np.random.randint(0, 1000, size=10000))\n        self.s_str = Series(np.tile(tm.makeStringIndex(1000).values, 10))\n    \n        N = 1000000\n        K = 10000\n        key1 = np.random.randint(0, K, size=N)\n        self.df_int = DataFrame({\"key1\": key1})\n        self.df_bool = DataFrame(np.random.randint(0, 2, size=(K, 10), dtype=bool))",
        "min_run_count": 2,
        "name": "reindex.DropDuplicates.time_series_drop_dups_string",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a5aff11532f4e1c1e669a5d97eda9ac45dbe689892e787fc8fd287a623862bd5",
        "warmup_time": -1
    },
    "reindex.Fillna.time_float_32": {
        "code": "class Fillna:\n    def time_float_32(self, method):\n        self.ts_float32.fillna(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, method):\n        N = 100000\n        self.idx = date_range(\"1/1/2000\", periods=N, freq=\"1min\")\n        ts = Series(np.random.randn(N), index=self.idx)[::2]\n        self.ts_reindexed = ts.reindex(self.idx)\n        self.ts_float32 = self.ts_reindexed.astype(\"float32\")",
        "min_run_count": 2,
        "name": "reindex.Fillna.time_float_32",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'pad'",
                "'backfill'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "603854c2615c955a22b92209cae44d5d4b8524235d08f0336c955170faa1ca03",
        "warmup_time": -1
    },
    "reindex.Fillna.time_reindexed": {
        "code": "class Fillna:\n    def time_reindexed(self, method):\n        self.ts_reindexed.fillna(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Fillna:\n    def setup(self, method):\n        N = 100000\n        self.idx = date_range(\"1/1/2000\", periods=N, freq=\"1min\")\n        ts = Series(np.random.randn(N), index=self.idx)[::2]\n        self.ts_reindexed = ts.reindex(self.idx)\n        self.ts_float32 = self.ts_reindexed.astype(\"float32\")",
        "min_run_count": 2,
        "name": "reindex.Fillna.time_reindexed",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'pad'",
                "'backfill'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a1ff25b418f5286adef892c902a1ab7521aefd0fd6cb8f9881c0d86eb0b62533",
        "warmup_time": -1
    },
    "reindex.LevelAlign.time_align_level": {
        "code": "class LevelAlign:\n    def time_align_level(self):\n        self.df.align(self.df_level, level=1, copy=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[\n                np.arange(10).repeat(10000),\n                np.tile(np.arange(100).repeat(100), 10),\n                np.tile(np.tile(np.arange(100), 100), 10),\n            ],\n        )\n        self.df = DataFrame(np.random.randn(len(self.index), 4), index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4), index=self.index.levels[1])",
        "min_run_count": 2,
        "name": "reindex.LevelAlign.time_align_level",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cced19c77cf2154fcd7f760f955314b571a4c552f1c3dda834b08449c39cf96a",
        "warmup_time": -1
    },
    "reindex.LevelAlign.time_reindex_level": {
        "code": "class LevelAlign:\n    def time_reindex_level(self):\n        self.df_level.reindex(self.index, level=1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass LevelAlign:\n    def setup(self):\n        self.index = MultiIndex(\n            levels=[np.arange(10), np.arange(100), np.arange(100)],\n            codes=[\n                np.arange(10).repeat(10000),\n                np.tile(np.arange(100).repeat(100), 10),\n                np.tile(np.tile(np.arange(100), 100), 10),\n            ],\n        )\n        self.df = DataFrame(np.random.randn(len(self.index), 4), index=self.index)\n        self.df_level = DataFrame(np.random.randn(100, 4), index=self.index.levels[1])",
        "min_run_count": 2,
        "name": "reindex.LevelAlign.time_reindex_level",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9c4e829ee0f877d248f2dca88a52830e615dd62d42be7dc5b046cd79771b41d2",
        "warmup_time": -1
    },
    "reindex.Reindex.time_reindex_columns": {
        "code": "class Reindex:\n    def time_reindex_columns(self):\n        self.df2.reindex(columns=self.df.columns[1:5])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]",
        "min_run_count": 2,
        "name": "reindex.Reindex.time_reindex_columns",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2da2725f17f95dad7f5e41ce14559e9841d23114f82f2c10a3d1a42b04e542d8",
        "warmup_time": -1
    },
    "reindex.Reindex.time_reindex_dates": {
        "code": "class Reindex:\n    def time_reindex_dates(self):\n        self.df.reindex(self.rng_subset)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]",
        "min_run_count": 2,
        "name": "reindex.Reindex.time_reindex_dates",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b975d9cf57147cc797cd34f107dc3c31406912098458ffd52fb0da6d7e58719d",
        "warmup_time": -1
    },
    "reindex.Reindex.time_reindex_multiindex": {
        "code": "class Reindex:\n    def time_reindex_multiindex(self):\n        self.s.reindex(self.s_subset.index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Reindex:\n    def setup(self):\n        rng = date_range(start=\"1/1/1970\", periods=10000, freq=\"1min\")\n        self.df = DataFrame(np.random.rand(10000, 10), index=rng, columns=range(10))\n        self.df[\"foo\"] = \"bar\"\n        self.rng_subset = Index(rng[::2])\n        self.df2 = DataFrame(\n            index=range(10000), data=np.random.rand(10000, 30), columns=range(30)\n        )\n        N = 5000\n        K = 200\n        level1 = tm.makeStringIndex(N).values.repeat(K)\n        level2 = np.tile(tm.makeStringIndex(K).values, N)\n        index = MultiIndex.from_arrays([level1, level2])\n        self.s = Series(np.random.randn(N * K), index=index)\n        self.s_subset = self.s[::2]",
        "min_run_count": 2,
        "name": "reindex.Reindex.time_reindex_multiindex",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a8b483855d662cfd730a1340609e0796c67ad27290cb8842c8b1e1b3b2ebc587",
        "warmup_time": -1
    },
    "reindex.ReindexMethod.time_reindex_method": {
        "code": "class ReindexMethod:\n    def time_reindex_method(self, method, constructor):\n        self.ts.reindex(self.idx, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReindexMethod:\n    def setup(self, method, constructor):\n        N = 100000\n        self.idx = constructor(\"1/1/2000\", periods=N, freq=\"1min\")\n        self.ts = Series(np.random.randn(N), index=self.idx)[::2]",
        "min_run_count": 2,
        "name": "reindex.ReindexMethod.time_reindex_method",
        "number": 0,
        "param_names": [
            "method",
            "constructor"
        ],
        "params": [
            [
                "'pad'",
                "'backfill'"
            ],
            [
                "<function date_range>",
                "<function period_range>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "52e66df756313fc255334a8a0cb3c1dbaf796d0b655126ff3c140d0a2207a3bc",
        "warmup_time": -1
    },
    "replace.Convert.time_replace": {
        "code": "class Convert:\n    def time_replace(self, constructor, replace_data):\n        self.data.replace(self.to_replace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Convert:\n    def setup(self, constructor, replace_data):\n        N = 10 ** 3\n        data = {\n            \"Series\": pd.Series(np.random.randint(N, size=N)),\n            \"DataFrame\": pd.DataFrame(\n                {\"A\": np.random.randint(N, size=N), \"B\": np.random.randint(N, size=N)}\n            ),\n        }\n        self.to_replace = {i: getattr(pd, replace_data) for i in range(N)}\n        self.data = data[constructor]",
        "min_run_count": 2,
        "name": "replace.Convert.time_replace",
        "number": 0,
        "param_names": [
            "constructor",
            "replace_data"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "'Timestamp'",
                "'Timedelta'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "92882ee71a2357501d07e0c6315a6184a582d114f22b577b04faeb3b282059b4",
        "warmup_time": -1
    },
    "replace.FillNa.time_fillna": {
        "code": "class FillNa:\n    def time_fillna(self, inplace):\n        self.ts.fillna(0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10 ** 6\n        rng = pd.date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)",
        "min_run_count": 2,
        "name": "replace.FillNa.time_fillna",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "310d6ea898d577a05a6a41a7826de45ff86944fa1a527f15c35d20f2c5fa6ca4",
        "warmup_time": -1
    },
    "replace.FillNa.time_replace": {
        "code": "class FillNa:\n    def time_replace(self, inplace):\n        self.ts.replace(np.nan, 0.0, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FillNa:\n    def setup(self, inplace):\n        N = 10 ** 6\n        rng = pd.date_range(\"1/1/2000\", periods=N, freq=\"min\")\n        data = np.random.randn(N)\n        data[::2] = np.nan\n        self.ts = pd.Series(data, index=rng)",
        "min_run_count": 2,
        "name": "replace.FillNa.time_replace",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "74aef85e750aaa73222b0dfc46b78204d31dc1e0e0dd25db06e2e03b99cce8ad",
        "warmup_time": -1
    },
    "replace.ReplaceDict.time_replace_series": {
        "code": "class ReplaceDict:\n    def time_replace_series(self, inplace):\n        self.s.replace(self.to_rep, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceDict:\n    def setup(self, inplace):\n        N = 10 ** 5\n        start_value = 10 ** 5\n        self.to_rep = dict(enumerate(np.arange(N) + start_value))\n        self.s = pd.Series(np.random.randint(N, size=10 ** 3))",
        "min_run_count": 2,
        "name": "replace.ReplaceDict.time_replace_series",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f0cf7da77a3f4077bee143d0af9cc37d914d137a9913174f2501dbbb19c2f201",
        "warmup_time": -1
    },
    "replace.ReplaceList.time_replace_list": {
        "code": "class ReplaceList:\n    def time_replace_list(self, inplace):\n        self.df.replace([np.inf, -np.inf], np.nan, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceList:\n    def setup(self, inplace):\n        self.df = pd.DataFrame({\"A\": 0, \"B\": 0}, index=range(4 * 10 ** 7))",
        "min_run_count": 2,
        "name": "replace.ReplaceList.time_replace_list",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "afb55879c4537fac98c750bdc8747c635c379aaa402687af561588b0c389664d",
        "warmup_time": -1
    },
    "replace.ReplaceList.time_replace_list_one_match": {
        "code": "class ReplaceList:\n    def time_replace_list_one_match(self, inplace):\n        # the 1 can be held in self._df.blocks[0], while the inf and -inf cant\n        self.df.replace([np.inf, -np.inf, 1], np.nan, inplace=inplace)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReplaceList:\n    def setup(self, inplace):\n        self.df = pd.DataFrame({\"A\": 0, \"B\": 0}, index=range(4 * 10 ** 7))",
        "min_run_count": 2,
        "name": "replace.ReplaceList.time_replace_list_one_match",
        "number": 0,
        "param_names": [
            "inplace"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c82d4c704799b7a555431f3571e99fe786569247af52510eb9ad04d1f15cf4a2",
        "warmup_time": -1
    },
    "reshape.Crosstab.time_crosstab": {
        "code": "class Crosstab:\n    def time_crosstab(self):\n        pd.crosstab(self.vec1, self.vec2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)",
        "min_run_count": 2,
        "name": "reshape.Crosstab.time_crosstab",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9111a9ad9a258688c45ba6a0c05b7b226f360b676432ed650b695e5397fde93e",
        "warmup_time": -1
    },
    "reshape.Crosstab.time_crosstab_normalize": {
        "code": "class Crosstab:\n    def time_crosstab_normalize(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)",
        "min_run_count": 2,
        "name": "reshape.Crosstab.time_crosstab_normalize",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5aca65001068430d0914d98785bddb8561273e9c8aa15b387c7dd93043ebf568",
        "warmup_time": -1
    },
    "reshape.Crosstab.time_crosstab_normalize_margins": {
        "code": "class Crosstab:\n    def time_crosstab_normalize_margins(self):\n        pd.crosstab(self.vec1, self.vec2, normalize=True, margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)",
        "min_run_count": 2,
        "name": "reshape.Crosstab.time_crosstab_normalize_margins",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4c136fc000722c789e91a8ae69e2c658c5bedd669b2178c0fc2a1f4f2b42727b",
        "warmup_time": -1
    },
    "reshape.Crosstab.time_crosstab_values": {
        "code": "class Crosstab:\n    def time_crosstab_values(self):\n        pd.crosstab(self.vec1, self.vec2, values=self.ind1, aggfunc=\"sum\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Crosstab:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        self.ind1 = np.random.randint(0, 3, size=N)\n        self.ind2 = np.random.randint(0, 2, size=N)\n        self.vec1 = fac1.take(self.ind1)\n        self.vec2 = fac2.take(self.ind2)",
        "min_run_count": 2,
        "name": "reshape.Crosstab.time_crosstab_values",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3b4ec27deb69daa12d4b65e15cc4b7b2edcc88df3a066962121c333f57a3423e",
        "warmup_time": -1
    },
    "reshape.Cut.peakmem_cut_interval": {
        "code": "class Cut:\n    def peakmem_cut_interval(self, bins):\n        # GH 27668\n        pd.cut(self.int_series, self.interval_bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "name": "reshape.Cut.peakmem_cut_interval",
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "bf454de7be5b3b382e21da6ae59cf978e5070f669118a8e13ce7b33e500c7e2b"
    },
    "reshape.Cut.time_cut_datetime": {
        "code": "class Cut:\n    def time_cut_datetime(self, bins):\n        pd.cut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_cut_datetime",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e338767e96d113fba850abb2baea4e0be06e899fa70e61aa7ddf1f220c4e4907",
        "warmup_time": -1
    },
    "reshape.Cut.time_cut_float": {
        "code": "class Cut:\n    def time_cut_float(self, bins):\n        pd.cut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_cut_float",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e821ef1cbe1751f4f5a568c52f978a9943d8cbcd6cd90ea4e590bf2d4ca8bc90",
        "warmup_time": -1
    },
    "reshape.Cut.time_cut_int": {
        "code": "class Cut:\n    def time_cut_int(self, bins):\n        pd.cut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_cut_int",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cbe709364947f0174ec3b6c01c9cfa62ca8d331f5b4a9f9fb81130c6fe89886f",
        "warmup_time": -1
    },
    "reshape.Cut.time_cut_interval": {
        "code": "class Cut:\n    def time_cut_interval(self, bins):\n        # GH 27668\n        pd.cut(self.int_series, self.interval_bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_cut_interval",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d007b5f1b0ecacb03e86220a5b7aa1ea9a62244849d0de4aae7de625877eefda",
        "warmup_time": -1
    },
    "reshape.Cut.time_cut_timedelta": {
        "code": "class Cut:\n    def time_cut_timedelta(self, bins):\n        pd.cut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_cut_timedelta",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b3c27e64900bc2d3d4c176d42198c3a8d7da277983f51b49ba3b195ab3fbc72c",
        "warmup_time": -1
    },
    "reshape.Cut.time_qcut_datetime": {
        "code": "class Cut:\n    def time_qcut_datetime(self, bins):\n        pd.qcut(self.datetime_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_qcut_datetime",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a1a50ff250e54f24aacbe0817fbacf83b2a030475341643a0f567a5818ed1845",
        "warmup_time": -1
    },
    "reshape.Cut.time_qcut_float": {
        "code": "class Cut:\n    def time_qcut_float(self, bins):\n        pd.qcut(self.float_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_qcut_float",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "69f12f4a31950899d5d0831ca67b6ed64be89f1c4424eb9ca734c0ed47581667",
        "warmup_time": -1
    },
    "reshape.Cut.time_qcut_int": {
        "code": "class Cut:\n    def time_qcut_int(self, bins):\n        pd.qcut(self.int_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_qcut_int",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1d91e71ba84fbce6455506a0b763f888e88b8123536a587d87ca7cd412241696",
        "warmup_time": -1
    },
    "reshape.Cut.time_qcut_timedelta": {
        "code": "class Cut:\n    def time_qcut_timedelta(self, bins):\n        pd.qcut(self.timedelta_series, bins)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Cut:\n    def setup(self, bins):\n        N = 10 ** 5\n        self.int_series = pd.Series(np.arange(N).repeat(5))\n        self.float_series = pd.Series(np.random.randn(N).repeat(5))\n        self.timedelta_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"timedelta64[ns]\"\n        )\n        self.datetime_series = pd.Series(\n            np.random.randint(N, size=N), dtype=\"datetime64[ns]\"\n        )\n        self.interval_bins = pd.IntervalIndex.from_breaks(np.linspace(0, N, bins))",
        "min_run_count": 2,
        "name": "reshape.Cut.time_qcut_timedelta",
        "number": 0,
        "param_names": [
            "bins"
        ],
        "params": [
            [
                "4",
                "10",
                "1000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "376a5d75957ec4f907aa94acda239afd18ac452270b4ff38e3a8f457efda7f77",
        "warmup_time": -1
    },
    "reshape.Explode.time_explode": {
        "code": "class Explode:\n    def time_explode(self, n_rows, max_list_length):\n        self.series.explode()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Explode:\n    def setup(self, n_rows, max_list_length):\n    \n        data = [np.arange(np.random.randint(max_list_length)) for _ in range(n_rows)]\n        self.series = pd.Series(data)",
        "min_run_count": 2,
        "name": "reshape.Explode.time_explode",
        "number": 0,
        "param_names": [
            "n_rows",
            "max_list_length"
        ],
        "params": [
            [
                "100",
                "1000",
                "10000"
            ],
            [
                "3",
                "5",
                "10"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8c418403e6e1f6089948dfff75b25da3aad72c7394cfbf78da526dbaab207cda",
        "warmup_time": -1
    },
    "reshape.GetDummies.time_get_dummies_1d": {
        "code": "class GetDummies:\n    def time_get_dummies_1d(self):\n        pd.get_dummies(self.s, sparse=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(\n            np.random.choice(categories, size=1000000),\n            dtype=CategoricalDtype(categories),\n        )\n        self.s = s",
        "min_run_count": 2,
        "name": "reshape.GetDummies.time_get_dummies_1d",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f6981c8b44fbd13f60eff496356529e393625318426d340155a55ed3d7ffb4ee",
        "warmup_time": -1
    },
    "reshape.GetDummies.time_get_dummies_1d_sparse": {
        "code": "class GetDummies:\n    def time_get_dummies_1d_sparse(self):\n        pd.get_dummies(self.s, sparse=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetDummies:\n    def setup(self):\n        categories = list(string.ascii_letters[:12])\n        s = pd.Series(\n            np.random.choice(categories, size=1000000),\n            dtype=CategoricalDtype(categories),\n        )\n        self.s = s",
        "min_run_count": 2,
        "name": "reshape.GetDummies.time_get_dummies_1d_sparse",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f4b85a94bf96350e6ae89b0267fcb36cf05e306063a0915e425fc9e5a1a4467e",
        "warmup_time": -1
    },
    "reshape.Melt.time_melt_dataframe": {
        "code": "class Melt:\n    def time_melt_dataframe(self):\n        melt(self.df, id_vars=[\"id1\", \"id2\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Melt:\n    def setup(self):\n        self.df = DataFrame(np.random.randn(10000, 3), columns=[\"A\", \"B\", \"C\"])\n        self.df[\"id1\"] = np.random.randint(0, 10, 10000)\n        self.df[\"id2\"] = np.random.randint(100, 1000, 10000)",
        "min_run_count": 2,
        "name": "reshape.Melt.time_melt_dataframe",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "383757f57e2de17989d80557ad0d498d420dc48e5db81a58c9320a09395be869",
        "warmup_time": -1
    },
    "reshape.Pivot.time_reshape_pivot_time_series": {
        "code": "class Pivot:\n    def time_reshape_pivot_time_series(self):\n        self.df.pivot(\"date\", \"variable\", \"value\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pivot:\n    def setup(self):\n        N = 10000\n        index = date_range(\"1/1/2000\", periods=N, freq=\"h\")\n        data = {\n            \"value\": np.random.randn(N * 50),\n            \"variable\": np.arange(50).repeat(N),\n            \"date\": np.tile(index.values, 50),\n        }\n        self.df = DataFrame(data)",
        "min_run_count": 2,
        "name": "reshape.Pivot.time_reshape_pivot_time_series",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "737d7bc1d8993405fd16a36a6357f89005b1233d6328bfb792ee063f1fb4d9e8",
        "warmup_time": -1
    },
    "reshape.PivotTable.time_pivot_table": {
        "code": "class PivotTable:\n    def time_pivot_table(self):\n        self.df.pivot_table(index=\"key1\", columns=[\"key2\", \"key3\"])\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")",
        "min_run_count": 2,
        "name": "reshape.PivotTable.time_pivot_table",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "03f1827427df23f7923b9d2b4ff8790a8896570fbbccf7ccd79cda77f3b29fb6",
        "warmup_time": -1
    },
    "reshape.PivotTable.time_pivot_table_agg": {
        "code": "class PivotTable:\n    def time_pivot_table_agg(self):\n        self.df.pivot_table(\n            index=\"key1\", columns=[\"key2\", \"key3\"], aggfunc=[\"sum\", \"mean\"]\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")",
        "min_run_count": 2,
        "name": "reshape.PivotTable.time_pivot_table_agg",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e31596884db26ad8a96fbca432b50937254b59d0e4139cefbc2d930b6835d13b",
        "warmup_time": -1
    },
    "reshape.PivotTable.time_pivot_table_categorical": {
        "code": "class PivotTable:\n    def time_pivot_table_categorical(self):\n        self.df2.pivot_table(\n            index=\"col1\", values=\"col3\", columns=\"col2\", aggfunc=np.sum, fill_value=0\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")",
        "min_run_count": 2,
        "name": "reshape.PivotTable.time_pivot_table_categorical",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9ef4ae37c73ff3879061357527840ad44914df57b2018d7659a559efef8c85bd",
        "warmup_time": -1
    },
    "reshape.PivotTable.time_pivot_table_categorical_observed": {
        "code": "class PivotTable:\n    def time_pivot_table_categorical_observed(self):\n        self.df2.pivot_table(\n            index=\"col1\",\n            values=\"col3\",\n            columns=\"col2\",\n            aggfunc=np.sum,\n            fill_value=0,\n            observed=True,\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")",
        "min_run_count": 2,
        "name": "reshape.PivotTable.time_pivot_table_categorical_observed",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "431e23a2024cc29bc9b1fe0ec05dc21a362cc6acf6d87b93b9f0c52b56163874",
        "warmup_time": -1
    },
    "reshape.PivotTable.time_pivot_table_margins": {
        "code": "class PivotTable:\n    def time_pivot_table_margins(self):\n        self.df.pivot_table(index=\"key1\", columns=[\"key2\", \"key3\"], margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")",
        "min_run_count": 2,
        "name": "reshape.PivotTable.time_pivot_table_margins",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0afefd1f2578cc7e47b9f9ef6791eac3f77b8ec807c5725b2ef687d228c99241",
        "warmup_time": -1
    },
    "reshape.PivotTable.time_pivot_table_margins_only_column": {
        "code": "class PivotTable:\n    def time_pivot_table_margins_only_column(self):\n        self.df.pivot_table(columns=[\"key2\", \"key3\"], margins=True)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PivotTable:\n    def setup(self):\n        N = 100000\n        fac1 = np.array([\"A\", \"B\", \"C\"], dtype=\"O\")\n        fac2 = np.array([\"one\", \"two\"], dtype=\"O\")\n        ind1 = np.random.randint(0, 3, size=N)\n        ind2 = np.random.randint(0, 2, size=N)\n        self.df = DataFrame(\n            {\n                \"key1\": fac1.take(ind1),\n                \"key2\": fac2.take(ind2),\n                \"key3\": fac2.take(ind2),\n                \"value1\": np.random.randn(N),\n                \"value2\": np.random.randn(N),\n                \"value3\": np.random.randn(N),\n            }\n        )\n        self.df2 = DataFrame(\n            {\"col1\": list(\"abcde\"), \"col2\": list(\"fghij\"), \"col3\": [1, 2, 3, 4, 5]}\n        )\n        self.df2.col1 = self.df2.col1.astype(\"category\")\n        self.df2.col2 = self.df2.col2.astype(\"category\")",
        "min_run_count": 2,
        "name": "reshape.PivotTable.time_pivot_table_margins_only_column",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d505191e6af2e2284bd3bdb6a9a4ed31336d427c176f62dd8cdc12878f3cd799",
        "warmup_time": -1
    },
    "reshape.ReshapeExtensionDtype.time_stack": {
        "code": "class ReshapeExtensionDtype:\n    def time_stack(self, dtype):\n        self.df.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df",
        "min_run_count": 2,
        "name": "reshape.ReshapeExtensionDtype.time_stack",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'datetime64[ns, US/Pacific]'",
                "'Period[s]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "71f50c1837c91a2ab25587dc3675ead2ce4cc6662b0442f0b8aabc7677405330",
        "warmup_time": -1
    },
    "reshape.ReshapeExtensionDtype.time_transpose": {
        "code": "class ReshapeExtensionDtype:\n    def time_transpose(self, dtype):\n        self.df.T\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df",
        "min_run_count": 2,
        "name": "reshape.ReshapeExtensionDtype.time_transpose",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'datetime64[ns, US/Pacific]'",
                "'Period[s]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "de98fb88e477fc5bd7f6b256e4a9b735100ef3450027db1f429fee20265ecde3",
        "warmup_time": -1
    },
    "reshape.ReshapeExtensionDtype.time_unstack_fast": {
        "code": "class ReshapeExtensionDtype:\n    def time_unstack_fast(self, dtype):\n        # last level -> doesnt have to make copies\n        self.ser.unstack(\"bar\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df",
        "min_run_count": 2,
        "name": "reshape.ReshapeExtensionDtype.time_unstack_fast",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'datetime64[ns, US/Pacific]'",
                "'Period[s]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4dac7d91fef87b9ce4e0b597fcd09446786f98877ed3150c56071ae90346ef6d",
        "warmup_time": -1
    },
    "reshape.ReshapeExtensionDtype.time_unstack_slow": {
        "code": "class ReshapeExtensionDtype:\n    def time_unstack_slow(self, dtype):\n        # first level -> must make copies\n        self.ser.unstack(\"foo\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ReshapeExtensionDtype:\n    def setup(self, dtype):\n        lev = pd.Index(list(\"ABCDEFGHIJ\"))\n        ri = pd.Index(range(1000))\n        mi = MultiIndex.from_product([lev, ri], names=[\"foo\", \"bar\"])\n    \n        index = date_range(\"2016-01-01\", periods=10000, freq=\"s\", tz=\"US/Pacific\")\n        if dtype == \"Period[s]\":\n            index = index.tz_localize(None).to_period(\"s\")\n    \n        ser = pd.Series(index, index=mi)\n        df = ser.unstack(\"bar\")\n        # roundtrips -> df.stack().equals(ser)\n    \n        self.ser = ser\n        self.df = df",
        "min_run_count": 2,
        "name": "reshape.ReshapeExtensionDtype.time_unstack_slow",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'datetime64[ns, US/Pacific]'",
                "'Period[s]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "19cf929eb6cc86687d322f9c25207cd480041be2aafd11fe37cf4815e5be49c8",
        "warmup_time": -1
    },
    "reshape.SimpleReshape.time_stack": {
        "code": "class SimpleReshape:\n    def time_stack(self):\n        self.udf.stack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100), np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)",
        "min_run_count": 2,
        "name": "reshape.SimpleReshape.time_stack",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a6d770036abb815e9c3a58b1e211a9731ce733599757aa8153db703496818011",
        "warmup_time": -1
    },
    "reshape.SimpleReshape.time_unstack": {
        "code": "class SimpleReshape:\n    def time_unstack(self):\n        self.df.unstack(1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SimpleReshape:\n    def setup(self):\n        arrays = [np.arange(100).repeat(100), np.roll(np.tile(np.arange(100), 100), 25)]\n        index = MultiIndex.from_arrays(arrays)\n        self.df = DataFrame(np.random.randn(10000, 4), index=index)\n        self.udf = self.df.unstack(1)",
        "min_run_count": 2,
        "name": "reshape.SimpleReshape.time_unstack",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ee883fcccbd0ef7d6c8bb60b550c2de5d2bc5b98458113c63b9f23a2f652e873",
        "warmup_time": -1
    },
    "reshape.SparseIndex.time_unstack": {
        "code": "class SparseIndex:\n    def time_unstack(self):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseIndex:\n    def setup(self):\n        NUM_ROWS = 1000\n        self.df = DataFrame(\n            {\n                \"A\": np.random.randint(50, size=NUM_ROWS),\n                \"B\": np.random.randint(50, size=NUM_ROWS),\n                \"C\": np.random.randint(-10, 10, size=NUM_ROWS),\n                \"D\": np.random.randint(-10, 10, size=NUM_ROWS),\n                \"E\": np.random.randint(10, size=NUM_ROWS),\n                \"F\": np.random.randn(NUM_ROWS),\n            }\n        )\n        self.df = self.df.set_index([\"A\", \"B\", \"C\", \"D\", \"E\"])",
        "min_run_count": 2,
        "name": "reshape.SparseIndex.time_unstack",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "41381253268a24b9d6ee1f0c20e6602a24860a05d0e483f11a992776103b51be",
        "warmup_time": -1
    },
    "reshape.Unstack.time_full_product": {
        "code": "class Unstack:\n    def time_full_product(self, dtype):\n        self.df.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == \"int\":\n            values = np.arange(m * m * n).reshape(m * m, n)\n            self.df = DataFrame(values, index, columns)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n            self.df = DataFrame(\n                {i: cat for i, cat in enumerate(values)}, index, columns\n            )\n    \n        self.df2 = self.df.iloc[:-1]",
        "min_run_count": 2,
        "name": "reshape.Unstack.time_full_product",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'int'",
                "'category'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f5e62e0092d74cb1b148dcb165576dc7e40150a556d605e500de44e987cfc89f",
        "warmup_time": -1
    },
    "reshape.Unstack.time_without_last_row": {
        "code": "class Unstack:\n    def time_without_last_row(self, dtype):\n        self.df2.unstack()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Unstack:\n    def setup(self, dtype):\n        m = 100\n        n = 1000\n    \n        levels = np.arange(m)\n        index = MultiIndex.from_product([levels] * 2)\n        columns = np.arange(n)\n        if dtype == \"int\":\n            values = np.arange(m * m * n).reshape(m * m, n)\n            self.df = DataFrame(values, index, columns)\n        else:\n            # the category branch is ~20x slower than int. So we\n            # cut down the size a bit. Now it's only ~3x slower.\n            n = 50\n            columns = columns[:n]\n            indices = np.random.randint(0, 52, size=(m * m, n))\n            values = np.take(list(string.ascii_letters), indices)\n            values = [pd.Categorical(v) for v in values.T]\n    \n            self.df = DataFrame(\n                {i: cat for i, cat in enumerate(values)}, index, columns\n            )\n    \n        self.df2 = self.df.iloc[:-1]",
        "min_run_count": 2,
        "name": "reshape.Unstack.time_without_last_row",
        "number": 0,
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'int'",
                "'category'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8c8cd57809171d106187023a3e108c86bf282887838b049335b9f497e2e50df4",
        "warmup_time": -1
    },
    "reshape.WideToLong.time_wide_to_long_big": {
        "code": "class WideToLong:\n    def time_wide_to_long_big(self):\n        wide_to_long(self.df, self.letters, i=\"id\", j=\"year\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass WideToLong:\n    def setup(self):\n        nyrs = 20\n        nidvars = 20\n        N = 5000\n        self.letters = list(\"ABCD\")\n        yrvars = [\n            letter + str(num)\n            for letter, num in product(self.letters, range(1, nyrs + 1))\n        ]\n        columns = [str(i) for i in range(nidvars)] + yrvars\n        self.df = DataFrame(np.random.randn(N, nidvars + len(yrvars)), columns=columns)\n        self.df[\"id\"] = self.df.index",
        "min_run_count": 2,
        "name": "reshape.WideToLong.time_wide_to_long_big",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "38b6ee0820735de02ad64b598a14cbe298769f714808e915411fde11e73f8598",
        "warmup_time": -1
    },
    "rolling.Apply.time_rolling": {
        "code": "class Apply:\n    def time_rolling(self, constructor, window, dtype, function, raw):\n        self.roll.apply(function, raw=raw)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Apply:\n    def setup(self, constructor, window, dtype, function, raw):\n        N = 10 ** 3\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)",
        "min_run_count": 2,
        "name": "rolling.Apply.time_rolling",
        "number": 0,
        "param_names": [
            "constructor",
            "window",
            "dtype",
            "function",
            "raw"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "3",
                "300"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "<built-in function sum>",
                "<function sum>",
                "<function Apply.<lambda>>"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4f2f60fa69f7afc1e20abe49b871c2112e6ba0d30d2416186ca1ee7be0aaa16a",
        "warmup_time": -1
    },
    "rolling.EWMMethods.time_ewm": {
        "code": "class EWMMethods:\n    def time_ewm(self, constructor, kwargs_method, dtype):\n        getattr(self.ewm, self.method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass EWMMethods:\n    def setup(self, constructor, kwargs_method, dtype):\n        N = 10 ** 5\n        kwargs, method = kwargs_method\n        arr = (100 * np.random.random(N)).astype(dtype)\n        self.method = method\n        self.ewm = getattr(pd, constructor)(arr).ewm(**kwargs)",
        "min_run_count": 2,
        "name": "rolling.EWMMethods.time_ewm",
        "number": 0,
        "param_names": [
            "constructor",
            "kwargs_method",
            "dtype"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "({'halflife': 10}, 'mean')",
                "({'halflife': 10}, 'std')",
                "({'halflife': 1000}, 'mean')",
                "({'halflife': 1000}, 'std')",
                "({'halflife': '1 Day', 'times': DatetimeIndex(['1900-01-01 00:00:00', '1900-01-01 00:00:23',\n               '1900-01-01 00:00:46', '1900-01-01 00:01:09',\n               '1900-01-01 00:01:32', '1900-01-01 00:01:55',\n               '1900-01-01 00:02:18', '1900-01-01 00:02:41',\n               '1900-01-01 00:03:04', '1900-01-01 00:03:27',\n               ...\n               '1900-01-27 14:49:30', '1900-01-27 14:49:53',\n               '1900-01-27 14:50:16', '1900-01-27 14:50:39',\n               '1900-01-27 14:51:02', '1900-01-27 14:51:25',\n               '1900-01-27 14:51:48', '1900-01-27 14:52:11',\n               '1900-01-27 14:52:34', '1900-01-27 14:52:57'],\n              dtype='datetime64[ns]', length=100000, freq='23S')}, 'mean')"
            ],
            [
                "'int'",
                "'float'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bed46ecdfc05e4720f3463e324b3a3643e20b6e43e5cffcf9e2aa73f5e004660",
        "warmup_time": -1
    },
    "rolling.ForwardWindowMethods.peakmem_rolling": {
        "code": "class ForwardWindowMethods:\n    def peakmem_rolling(self, constructor, window_size, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ForwardWindowMethods:\n    def setup(self, constructor, window_size, dtype, method):\n        N = 10 ** 5\n        arr = np.random.random(N).astype(dtype)\n        indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=window_size)\n        self.roll = getattr(pd, constructor)(arr).rolling(window=indexer)",
        "name": "rolling.ForwardWindowMethods.peakmem_rolling",
        "param_names": [
            "constructor",
            "window_size",
            "dtype",
            "method"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "10",
                "1000"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "'median'",
                "'mean'",
                "'max'",
                "'min'",
                "'kurt'",
                "'sum'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "d833c0c4704e1ca5bf294de7a9d176a0dc425c2cc2e87a4bb5b45f7a0552f8f8"
    },
    "rolling.ForwardWindowMethods.time_rolling": {
        "code": "class ForwardWindowMethods:\n    def time_rolling(self, constructor, window_size, dtype, method):\n        getattr(self.roll, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ForwardWindowMethods:\n    def setup(self, constructor, window_size, dtype, method):\n        N = 10 ** 5\n        arr = np.random.random(N).astype(dtype)\n        indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=window_size)\n        self.roll = getattr(pd, constructor)(arr).rolling(window=indexer)",
        "min_run_count": 2,
        "name": "rolling.ForwardWindowMethods.time_rolling",
        "number": 0,
        "param_names": [
            "constructor",
            "window_size",
            "dtype",
            "method"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "10",
                "1000"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "'median'",
                "'mean'",
                "'max'",
                "'min'",
                "'kurt'",
                "'sum'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d73db6a725be9e2e87cfcc791686329b31a096fcacce9943ff138cb672213f66",
        "warmup_time": -1
    },
    "rolling.Groupby.time_method": {
        "code": "class Groupby:\n    def time_method(self, method, window_kwargs):\n        getattr(self.groupby_window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Groupby:\n    def setup(self, method, window_kwargs):\n        N = 1000\n        window, kwargs = window_kwargs\n        df = pd.DataFrame(\n            {\n                \"A\": [str(i) for i in range(N)] * 10,\n                \"B\": list(range(N)) * 10,\n                \"C\": pd.date_range(start=\"1900-01-01\", freq=\"1min\", periods=N * 10),\n            }\n        )\n        self.groupby_window = getattr(df.groupby(\"A\"), window)(**kwargs)",
        "min_run_count": 2,
        "name": "rolling.Groupby.time_method",
        "number": 0,
        "param_names": [
            "param1",
            "param2"
        ],
        "params": [
            [
                "'sum' (0)",
                "'median'",
                "'mean'",
                "'max'",
                "'min'",
                "'kurt'",
                "'sum' (1)"
            ],
            [
                "('rolling', {'window': 2})",
                "('rolling', {'window': '30s', 'on': 'C'})",
                "('expanding', {})"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2c03af03887e4ced844b889037c828cde675ebcd62c97d9883f3842f8b047ac8",
        "warmup_time": -1
    },
    "rolling.GroupbyEWM.time_groupby_method": {
        "code": "class GroupbyEWM:\n    def time_groupby_method(self, method):\n        getattr(self.gb_ewm, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupbyEWM:\n    def setup(self, method):\n        df = pd.DataFrame({\"A\": range(50), \"B\": range(50)})\n        self.gb_ewm = df.groupby(\"A\").ewm(com=1.0)",
        "min_run_count": 2,
        "name": "rolling.GroupbyEWM.time_groupby_method",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'var'",
                "'std'",
                "'cov'",
                "'corr'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ad6a51326eb042f1ee88615e2048d6bc92adf02dfecb26d43ba24834f3c61150",
        "warmup_time": -1
    },
    "rolling.GroupbyEWMEngine.time_groupby_mean": {
        "code": "class GroupbyEWMEngine:\n    def time_groupby_mean(self, engine):\n        self.gb_ewm.mean(engine=engine)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupbyEWMEngine:\n    def setup(self, engine):\n        df = pd.DataFrame({\"A\": range(50), \"B\": range(50)})\n        self.gb_ewm = df.groupby(\"A\").ewm(com=1.0)",
        "min_run_count": 2,
        "name": "rolling.GroupbyEWMEngine.time_groupby_mean",
        "number": 0,
        "param_names": [
            "engine"
        ],
        "params": [
            [
                "'cython'",
                "'numba'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d69e116193dcb411ee111f0a146b8d596d2d73236f686eb16ef4e9221bd2bd52",
        "warmup_time": -1
    },
    "rolling.GroupbyLargeGroups.time_rolling_multiindex_creation": {
        "code": "class GroupbyLargeGroups:\n    def time_rolling_multiindex_creation(self):\n        self.df.groupby(\"A\").rolling(3).mean()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GroupbyLargeGroups:\n    def setup(self):\n        N = 100000\n        self.df = pd.DataFrame({\"A\": [1, 2] * (N // 2), \"B\": np.random.randn(N)})",
        "min_run_count": 2,
        "name": "rolling.GroupbyLargeGroups.time_rolling_multiindex_creation",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "31a34a6b020d62e4c7b595aeb804a131f135c1fd1497365577c3bbf2fe7c511c",
        "warmup_time": -1
    },
    "rolling.Methods.peakmem_method": {
        "code": "class Methods:\n    def peakmem_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Methods:\n    def setup(self, constructor, window_kwargs, dtype, method):\n        N = 10 ** 5\n        window, kwargs = window_kwargs\n        arr = (100 * np.random.random(N)).astype(dtype)\n        obj = getattr(pd, constructor)(arr)\n        self.window = getattr(obj, window)(**kwargs)",
        "name": "rolling.Methods.peakmem_method",
        "param_names": [
            "constructor",
            "window_kwargs",
            "dtype",
            "method"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "('rolling', {'window': 10})",
                "('rolling', {'window': 1000})",
                "('expanding', {})"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "'median'",
                "'mean'",
                "'max'",
                "'min'",
                "'std'",
                "'count'",
                "'skew'",
                "'kurt'",
                "'sum'",
                "'sem'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "f1003300698d8b144087b4c19730c40dd6f30d30a0e747037d7d7e348442349f"
    },
    "rolling.Methods.time_method": {
        "code": "class Methods:\n    def time_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Methods:\n    def setup(self, constructor, window_kwargs, dtype, method):\n        N = 10 ** 5\n        window, kwargs = window_kwargs\n        arr = (100 * np.random.random(N)).astype(dtype)\n        obj = getattr(pd, constructor)(arr)\n        self.window = getattr(obj, window)(**kwargs)",
        "min_run_count": 2,
        "name": "rolling.Methods.time_method",
        "number": 0,
        "param_names": [
            "constructor",
            "window_kwargs",
            "dtype",
            "method"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "('rolling', {'window': 10})",
                "('rolling', {'window': 1000})",
                "('expanding', {})"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "'median'",
                "'mean'",
                "'max'",
                "'min'",
                "'std'",
                "'count'",
                "'skew'",
                "'kurt'",
                "'sum'",
                "'sem'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8326fb0b91007e94f867d4a8e4415e63df2823c265525e17afb6f14255673c93",
        "warmup_time": -1
    },
    "rolling.Pairwise.time_groupby": {
        "code": "class Pairwise:\n    def time_groupby(self, kwargs_window, method, pairwise):\n        getattr(self.window_group, method)(self.df, pairwise=pairwise)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pairwise:\n    def setup(self, kwargs_window, method, pairwise):\n        N = 10 ** 4\n        n_groups = 20\n        kwargs, window = kwargs_window\n        groups = [i for _ in range(N // n_groups) for i in range(n_groups)]\n        arr = np.random.random(N)\n        self.df = pd.DataFrame(arr)\n        self.window = getattr(self.df, window)(**kwargs)\n        self.window_group = getattr(\n            pd.DataFrame({\"A\": groups, \"B\": arr}).groupby(\"A\"), window\n        )(**kwargs)",
        "min_run_count": 2,
        "name": "rolling.Pairwise.time_groupby",
        "number": 0,
        "param_names": [
            "window_kwargs",
            "method",
            "pairwise"
        ],
        "params": [
            [
                "({'window': 10}, 'rolling')",
                "({'window': 1000}, 'rolling')",
                "({}, 'expanding')"
            ],
            [
                "'corr'",
                "'cov'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7ad59a65224d38be0a7399006354776e5e301b537862f3041ccdf793f044b2ea",
        "warmup_time": -1
    },
    "rolling.Pairwise.time_pairwise": {
        "code": "class Pairwise:\n    def time_pairwise(self, kwargs_window, method, pairwise):\n        getattr(self.window, method)(self.df, pairwise=pairwise)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Pairwise:\n    def setup(self, kwargs_window, method, pairwise):\n        N = 10 ** 4\n        n_groups = 20\n        kwargs, window = kwargs_window\n        groups = [i for _ in range(N // n_groups) for i in range(n_groups)]\n        arr = np.random.random(N)\n        self.df = pd.DataFrame(arr)\n        self.window = getattr(self.df, window)(**kwargs)\n        self.window_group = getattr(\n            pd.DataFrame({\"A\": groups, \"B\": arr}).groupby(\"A\"), window\n        )(**kwargs)",
        "min_run_count": 2,
        "name": "rolling.Pairwise.time_pairwise",
        "number": 0,
        "param_names": [
            "window_kwargs",
            "method",
            "pairwise"
        ],
        "params": [
            [
                "({'window': 10}, 'rolling')",
                "({'window': 1000}, 'rolling')",
                "({}, 'expanding')"
            ],
            [
                "'corr'",
                "'cov'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "169ca723fe6ce3bb1810336c4b66a0a0280091d09400cd151af3a219937aaa35",
        "warmup_time": -1
    },
    "rolling.PeakMemFixedWindowMinMax.peakmem_fixed": {
        "code": "class PeakMemFixedWindowMinMax:\n    def peakmem_fixed(self, operation):\n        for x in range(5):\n            getattr(self.roll, operation)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass PeakMemFixedWindowMinMax:\n    def setup(self, operation):\n        N = 10 ** 6\n        arr = np.random.random(N)\n        self.roll = pd.Series(arr).rolling(2)",
        "name": "rolling.PeakMemFixedWindowMinMax.peakmem_fixed",
        "param_names": [
            "param1"
        ],
        "params": [
            [
                "'min'",
                "'max'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "9bac7bda735369972fd9c00eece23910c99c71173f96299e11cfab850658f8c5"
    },
    "rolling.Quantile.time_quantile": {
        "code": "class Quantile:\n    def time_quantile(self, constructor, window, dtype, percentile, interpolation):\n        self.roll.quantile(percentile, interpolation=interpolation)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Quantile:\n    def setup(self, constructor, window, dtype, percentile, interpolation):\n        N = 10 ** 5\n        arr = np.random.random(N).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)",
        "min_run_count": 2,
        "name": "rolling.Quantile.time_quantile",
        "number": 0,
        "param_names": [
            "constructor",
            "window",
            "dtype",
            "percentile",
            "param5"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "10",
                "1000"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "0",
                "0.5",
                "1"
            ],
            [
                "'linear'",
                "'nearest'",
                "'lower'",
                "'higher'",
                "'midpoint'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c5bc3e62eee5afb0b65a12c1d8f0ecf2412c8e8f4ff0739467723caad469392a",
        "warmup_time": -1
    },
    "rolling.Rank.time_rank": {
        "code": "class Rank:\n    def time_rank(self, constructor, window, dtype, percentile, ascending, method):\n        self.roll.rank(pct=percentile, ascending=ascending, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, window, dtype, percentile, ascending, method):\n        N = 10 ** 5\n        arr = np.random.random(N).astype(dtype)\n        self.roll = getattr(pd, constructor)(arr).rolling(window)",
        "min_run_count": 2,
        "name": "rolling.Rank.time_rank",
        "number": 0,
        "param_names": [
            "constructor",
            "window",
            "dtype",
            "percentile",
            "ascending",
            "method"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "10",
                "1000"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "True",
                "False"
            ],
            [
                "True",
                "False"
            ],
            [
                "'min'",
                "'max'",
                "'average'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b66f0211815db9f94af591c45909526cedcf7941237b565156c279d6470e06f9",
        "warmup_time": -1
    },
    "rolling.TableMethod.time_apply": {
        "code": "class TableMethod:\n    def time_apply(self, method):\n        self.df.rolling(2, method=method).apply(\n            table_method_func, raw=True, engine=\"numba\"\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TableMethod:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(10, 1000))",
        "min_run_count": 2,
        "name": "rolling.TableMethod.time_apply",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'single'",
                "'table'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "30880eb453b9d41a953d95fc25ba24088b0a48b94ab49ea12406e4abc0b976ac",
        "warmup_time": -1
    },
    "rolling.TableMethod.time_ewm_mean": {
        "code": "class TableMethod:\n    def time_ewm_mean(self, method):\n        self.df.ewm(1, method=method).mean(engine=\"numba\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TableMethod:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(10, 1000))",
        "min_run_count": 2,
        "name": "rolling.TableMethod.time_ewm_mean",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'single'",
                "'table'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "446dcdc251bda1381a3cf943305e8a6a22ea15ca4513ec2dc7454a8692ab99ad",
        "warmup_time": -1
    },
    "rolling.VariableWindowMethods.peakmem_method": {
        "code": "class Methods:\n    def peakmem_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass VariableWindowMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10 ** 5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        index = pd.date_range(\"2017-01-01\", periods=N, freq=\"5s\")\n        self.window = getattr(pd, constructor)(arr, index=index).rolling(window)",
        "name": "rolling.VariableWindowMethods.peakmem_method",
        "param_names": [
            "constructor",
            "window",
            "dtype",
            "method"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "'50s'",
                "'1h'",
                "'1d'"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "'median'",
                "'mean'",
                "'max'",
                "'min'",
                "'std'",
                "'count'",
                "'skew'",
                "'kurt'",
                "'sum'",
                "'sem'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "31f6b5028bb8381d30a34ff49ab844733784a43601109f71d1545676cd073b68"
    },
    "rolling.VariableWindowMethods.time_method": {
        "code": "class Methods:\n    def time_method(self, constructor, window_kwargs, dtype, method):\n        getattr(self.window, method)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass VariableWindowMethods:\n    def setup(self, constructor, window, dtype, method):\n        N = 10 ** 5\n        arr = (100 * np.random.random(N)).astype(dtype)\n        index = pd.date_range(\"2017-01-01\", periods=N, freq=\"5s\")\n        self.window = getattr(pd, constructor)(arr, index=index).rolling(window)",
        "min_run_count": 2,
        "name": "rolling.VariableWindowMethods.time_method",
        "number": 0,
        "param_names": [
            "constructor",
            "window",
            "dtype",
            "method"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "'50s'",
                "'1h'",
                "'1d'"
            ],
            [
                "'int'",
                "'float'"
            ],
            [
                "'median'",
                "'mean'",
                "'max'",
                "'min'",
                "'std'",
                "'count'",
                "'skew'",
                "'kurt'",
                "'sum'",
                "'sem'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2bb7c4c9d85c55f5d5ec773fe661fbe3c31552dbc50360e7df1b367027320089",
        "warmup_time": -1
    },
    "series_methods.All.time_all": {
        "code": "class All:\n    def time_all(self, N, case, dtype):\n        self.s.all()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass All:\n    def setup(self, N, case, dtype):\n        val = case != \"fast\"\n        self.s = Series([val] * N, dtype=dtype)",
        "min_run_count": 2,
        "name": "series_methods.All.time_all",
        "number": 0,
        "param_names": [
            "N",
            "case",
            "dtype"
        ],
        "params": [
            [
                "1000",
                "1000000"
            ],
            [
                "'fast'",
                "'slow'"
            ],
            [
                "'bool'",
                "'boolean'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "45f86547ce03394cb299551fd376fc8a763de3a613d475e1b9b2e71852b8c4f9",
        "warmup_time": -1
    },
    "series_methods.Any.time_any": {
        "code": "class Any:\n    def time_any(self, N, case, dtype):\n        self.s.any()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Any:\n    def setup(self, N, case, dtype):\n        val = case == \"fast\"\n        self.s = Series([val] * N, dtype=dtype)",
        "min_run_count": 2,
        "name": "series_methods.Any.time_any",
        "number": 0,
        "param_names": [
            "N",
            "case",
            "dtype"
        ],
        "params": [
            [
                "1000",
                "1000000"
            ],
            [
                "'fast'",
                "'slow'"
            ],
            [
                "'bool'",
                "'boolean'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2e53bbc75704910ed273c169cc5a41b3037436503911ac1dd4fa9a62a7261c44",
        "warmup_time": -1
    },
    "series_methods.Clip.time_clip": {
        "code": "class Clip:\n    def time_clip(self, n):\n        self.s.clip(0, 1)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Clip:\n    def setup(self, n):\n        self.s = Series(np.random.randn(n))",
        "min_run_count": 2,
        "name": "series_methods.Clip.time_clip",
        "number": 0,
        "param_names": [
            "n"
        ],
        "params": [
            [
                "50",
                "1000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8179a96510fbe69a1326ac0c3cdb1466db7b5719d20b59a243564362d9b56a4a",
        "warmup_time": -1
    },
    "series_methods.Dir.time_dir_strings": {
        "code": "class Dir:\n    def time_dir_strings(self):\n        dir(self.s)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dir:\n    def setup(self):\n        self.s = Series(index=tm.makeStringIndex(10000))",
        "min_run_count": 2,
        "name": "series_methods.Dir.time_dir_strings",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cebc60823e26e6539c07906cb467feba1e35568d660a21659f8de8c992dc4904",
        "warmup_time": -1
    },
    "series_methods.Dropna.time_dropna": {
        "code": "class Dropna:\n    def time_dropna(self, dtype):\n        self.s.dropna()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Dropna:\n    def setup(self, dtype):\n        N = 10 ** 6\n        data = {\n            \"int\": np.random.randint(1, 10, N),\n            \"datetime\": date_range(\"2000-01-01\", freq=\"S\", periods=N),\n        }\n        self.s = Series(data[dtype])\n        if dtype == \"datetime\":\n            self.s[np.random.randint(1, N, 100)] = NaT",
        "min_run_count": 2,
        "name": "series_methods.Dropna.time_dropna",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int'",
                "'datetime'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a4579201a1d57ad8ec7e05d626a9f0aa9a59523f5f542c1fcc9e062574060aaf",
        "warmup_time": -1
    },
    "series_methods.Map.time_map": {
        "code": "class Map:\n    def time_map(self, mapper, *args, **kwargs):\n        self.s.map(self.map_data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Map:\n    def setup(self, mapper, dtype):\n        map_size = 1000\n        map_data = Series(map_size - np.arange(map_size), dtype=dtype)\n    \n        # construct mapper\n        if mapper == \"Series\":\n            self.map_data = map_data\n        elif mapper == \"dict\":\n            self.map_data = map_data.to_dict()\n        elif mapper == \"lambda\":\n            map_dict = map_data.to_dict()\n            self.map_data = lambda x: map_dict[x]\n        else:\n            raise NotImplementedError\n    \n        self.s = Series(np.random.randint(0, map_size, 10000), dtype=dtype)",
        "min_run_count": 2,
        "name": "series_methods.Map.time_map",
        "number": 0,
        "param_names": [
            "m",
            "a"
        ],
        "params": [
            [
                "'dict'",
                "'Series'",
                "'lambda'"
            ],
            [
                "'object'",
                "'category'",
                "'int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fc78503b1588b9f3f6ca02d55c628c9cf0ea126fdb6ebdcec3080a88d01028bd",
        "warmup_time": -1
    },
    "series_methods.Mode.time_mode": {
        "code": "class Mode:\n    def time_mode(self, N, dtype):\n        self.s.mode()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Mode:\n    def setup(self, N, dtype):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(dtype)",
        "min_run_count": 2,
        "name": "series_methods.Mode.time_mode",
        "number": 0,
        "param_names": [
            "N",
            "dtype"
        ],
        "params": [
            [
                "1000",
                "10000",
                "100000"
            ],
            [
                "'int'",
                "'uint'",
                "'float'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "293b41b446df29f5e77e19b14540c5af87a0168e4710d64dbb12037435ef4202",
        "warmup_time": -1
    },
    "series_methods.ModeObjectDropNAFalse.time_mode": {
        "code": "class ModeObjectDropNAFalse:\n    def time_mode(self, N):\n        self.s.mode(dropna=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ModeObjectDropNAFalse:\n    def setup(self, N):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(\"object\")",
        "min_run_count": 2,
        "name": "series_methods.ModeObjectDropNAFalse.time_mode",
        "number": 0,
        "param_names": [
            "N"
        ],
        "params": [
            [
                "1000",
                "10000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e2488dac5c2fdbcfe29cc7e9e32e32b33227ebda39debbcf7e35dbc59aea3f4a",
        "warmup_time": -1
    },
    "series_methods.NSort.time_nlargest": {
        "code": "class NSort:\n    def time_nlargest(self, keep):\n        self.s.nlargest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))",
        "min_run_count": 2,
        "name": "series_methods.NSort.time_nlargest",
        "number": 0,
        "param_names": [
            "keep"
        ],
        "params": [
            [
                "'first'",
                "'last'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b2d7318a10dc119adee969b91b3e8224c14af04542e29aea061c0c549cfbe264",
        "warmup_time": -1
    },
    "series_methods.NSort.time_nsmallest": {
        "code": "class NSort:\n    def time_nsmallest(self, keep):\n        self.s.nsmallest(3, keep=keep)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NSort:\n    def setup(self, keep):\n        self.s = Series(np.random.randint(1, 10, 100000))",
        "min_run_count": 2,
        "name": "series_methods.NSort.time_nsmallest",
        "number": 0,
        "param_names": [
            "keep"
        ],
        "params": [
            [
                "'first'",
                "'last'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8b1f411ecb151ecb227a739c4be77e69ccde5647917c3adb93dca8fbcae978e1",
        "warmup_time": -1
    },
    "series_methods.NanOps.time_func": {
        "code": "class NanOps:\n    def time_func(self, func, N, dtype):\n        self.func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass NanOps:\n    def setup(self, func, N, dtype):\n        if func == \"argmax\" and dtype in {\"Int64\", \"boolean\"}:\n            # Skip argmax for nullable int since this doesn't work yet (GH-24382)\n            raise NotImplementedError\n        self.s = Series([1] * N, dtype=dtype)\n        self.func = getattr(self.s, func)",
        "min_run_count": 2,
        "name": "series_methods.NanOps.time_func",
        "number": 0,
        "param_names": [
            "func",
            "N",
            "dtype"
        ],
        "params": [
            [
                "'var'",
                "'mean'",
                "'median'",
                "'max'",
                "'min'",
                "'sum'",
                "'std'",
                "'sem'",
                "'argmax'",
                "'skew'",
                "'kurt'",
                "'prod'"
            ],
            [
                "1000",
                "1000000"
            ],
            [
                "'int8'",
                "'int32'",
                "'int64'",
                "'float64'",
                "'Int64'",
                "'boolean'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "13a058b93e316c8d60340bbe9a4966cf10a61120c7b885f40c8424029be388d8",
        "warmup_time": -1
    },
    "series_methods.Rank.time_rank": {
        "code": "class Rank:\n    def time_rank(self, dtype):\n        self.s.rank()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, dtype):\n        self.s = Series(np.random.randint(0, 1000, size=100000), dtype=dtype)",
        "min_run_count": 2,
        "name": "series_methods.Rank.time_rank",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int'",
                "'uint'",
                "'float'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cf912b236884d1fded0314151a2a53dce2cf23529a155f2103666ee9d002bff7",
        "warmup_time": -1
    },
    "series_methods.SearchSorted.time_searchsorted": {
        "code": "class SearchSorted:\n    def time_searchsorted(self, dtype):\n        key = \"2\" if dtype == \"str\" else 2\n        self.s.searchsorted(key)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SearchSorted:\n    def setup(self, dtype):\n        N = 10 ** 5\n        data = np.array([1] * N + [2] * N + [3] * N).astype(dtype)\n        self.s = Series(data)",
        "min_run_count": 2,
        "name": "series_methods.SearchSorted.time_searchsorted",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'int8'",
                "'int16'",
                "'int32'",
                "'int64'",
                "'uint8'",
                "'uint16'",
                "'uint32'",
                "'uint64'",
                "'float16'",
                "'float32'",
                "'float64'",
                "'str'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1f3b310ee05b9f43035ec5585238aba3e7f1b4edf981117f06619a0582a2c09e",
        "warmup_time": -1
    },
    "series_methods.SeriesConstructor.time_constructor": {
        "code": "class SeriesConstructor:\n    def time_constructor(self, data):\n        Series(data=self.data, index=self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesConstructor:\n    def setup(self, data):\n        self.idx = date_range(\n            start=datetime(2015, 10, 26), end=datetime(2016, 1, 1), freq=\"50s\"\n        )\n        dict_data = dict(zip(self.idx, range(len(self.idx))))\n        self.data = None if data is None else dict_data",
        "min_run_count": 2,
        "name": "series_methods.SeriesConstructor.time_constructor",
        "number": 0,
        "param_names": [
            "data"
        ],
        "params": [
            [
                "None",
                "'dict'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "247652f83776105ec50b8e9166e00ffaf13dd75a67a1b295ee407c19fc811b91",
        "warmup_time": -1
    },
    "series_methods.SeriesGetattr.time_series_datetimeindex_repr": {
        "code": "class SeriesGetattr:\n    def time_series_datetimeindex_repr(self):\n        getattr(self.s, \"a\", None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesGetattr:\n    def setup(self):\n        self.s = Series(1, index=date_range(\"2012-01-01\", freq=\"s\", periods=10 ** 6))",
        "min_run_count": 2,
        "name": "series_methods.SeriesGetattr.time_series_datetimeindex_repr",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9d0c98e7b0a82a43867823927e4df7fa792b8a8b8fc84b81b10f279204be915f",
        "warmup_time": -1
    },
    "series_methods.ToFrame.time_to_frame": {
        "code": "class ToFrame:\n    def time_to_frame(self, dtype, name):\n        self.ser.to_frame(name)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToFrame:\n    def setup(self, dtype, name):\n        arr = np.arange(10 ** 5)\n        ser = Series(arr, dtype=dtype)\n        self.ser = ser",
        "min_run_count": 2,
        "name": "series_methods.ToFrame.time_to_frame",
        "number": 0,
        "param_names": [
            "dtype",
            "name"
        ],
        "params": [
            [
                "'int64'",
                "'datetime64[ns]'",
                "'category'",
                "'Int64'"
            ],
            [
                "None",
                "'foo'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "14942e3c2f7403420b6f836a981b1fb3a5fd6387e8a070b2ff0ce5c6f671804c",
        "warmup_time": -1
    },
    "series_methods.ValueCounts.time_value_counts": {
        "code": "class ValueCounts:\n    def time_value_counts(self, N, dtype):\n        self.s.value_counts()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCounts:\n    def setup(self, N, dtype):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(dtype)",
        "min_run_count": 2,
        "name": "series_methods.ValueCounts.time_value_counts",
        "number": 0,
        "param_names": [
            "N",
            "dtype"
        ],
        "params": [
            [
                "1000",
                "10000",
                "100000"
            ],
            [
                "'int'",
                "'uint'",
                "'float'",
                "'object'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1f5bd690b4a0f777032140a9e0c26ed03c57e4402268b2e8a64b3e1a88d4ee63",
        "warmup_time": -1
    },
    "series_methods.ValueCountsObjectDropNAFalse.time_value_counts": {
        "code": "class ValueCountsObjectDropNAFalse:\n    def time_value_counts(self, N):\n        self.s.value_counts(dropna=False)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ValueCountsObjectDropNAFalse:\n    def setup(self, N):\n        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(\"object\")",
        "min_run_count": 2,
        "name": "series_methods.ValueCountsObjectDropNAFalse.time_value_counts",
        "number": 0,
        "param_names": [
            "N"
        ],
        "params": [
            [
                "1000",
                "10000",
                "100000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a95ddcf5298c1d0d3e53729949f04ee80696bd4b75829dc18ba02781f93d57eb",
        "warmup_time": -1
    },
    "sparse.Arithmetic.time_add": {
        "code": "class Arithmetic:\n    def time_add(self, dense_proportion, fill_value):\n        self.array1 + self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10 ** 6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)",
        "min_run_count": 2,
        "name": "sparse.Arithmetic.time_add",
        "number": 0,
        "param_names": [
            "dense_proportion",
            "fill_value"
        ],
        "params": [
            [
                "0.1",
                "0.01"
            ],
            [
                "0",
                "nan"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "50a07d273cd840d2d64eda49e3b28423e5385b72dc2decccb5d4dba8e8e1f861",
        "warmup_time": -1
    },
    "sparse.Arithmetic.time_divide": {
        "code": "class Arithmetic:\n    def time_divide(self, dense_proportion, fill_value):\n        self.array1 / self.array2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10 ** 6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)",
        "min_run_count": 2,
        "name": "sparse.Arithmetic.time_divide",
        "number": 0,
        "param_names": [
            "dense_proportion",
            "fill_value"
        ],
        "params": [
            [
                "0.1",
                "0.01"
            ],
            [
                "0",
                "nan"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "202c122f8fd6f2013bc128eca5a248f8b52c9924bd1a5526bd508efb4ff8426c",
        "warmup_time": -1
    },
    "sparse.Arithmetic.time_intersect": {
        "code": "class Arithmetic:\n    def time_intersect(self, dense_proportion, fill_value):\n        self.array1.sp_index.intersect(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10 ** 6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)",
        "min_run_count": 2,
        "name": "sparse.Arithmetic.time_intersect",
        "number": 0,
        "param_names": [
            "dense_proportion",
            "fill_value"
        ],
        "params": [
            [
                "0.1",
                "0.01"
            ],
            [
                "0",
                "nan"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0f9b1f48574a4ab32087147f29a115d042ee1669a77cb0f31e9270aafc4ff10f",
        "warmup_time": -1
    },
    "sparse.Arithmetic.time_make_union": {
        "code": "class Arithmetic:\n    def time_make_union(self, dense_proportion, fill_value):\n        self.array1.sp_index.make_union(self.array2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Arithmetic:\n    def setup(self, dense_proportion, fill_value):\n        N = 10 ** 6\n        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array1 = SparseArray(arr1, fill_value=fill_value)\n        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\n        self.array2 = SparseArray(arr2, fill_value=fill_value)",
        "min_run_count": 2,
        "name": "sparse.Arithmetic.time_make_union",
        "number": 0,
        "param_names": [
            "dense_proportion",
            "fill_value"
        ],
        "params": [
            [
                "0.1",
                "0.01"
            ],
            [
                "0",
                "nan"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "428fa08da4e38f798c02e2805a659bd389fd9fdad5d08d5ce106a0acfe3f4894",
        "warmup_time": -1
    },
    "sparse.ArithmeticBlock.time_addition": {
        "code": "class ArithmeticBlock:\n    def time_addition(self, fill_value):\n        self.arr1 + self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10 ** 6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )",
        "min_run_count": 2,
        "name": "sparse.ArithmeticBlock.time_addition",
        "number": 0,
        "param_names": [
            "fill_value"
        ],
        "params": [
            [
                "nan",
                "0"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9aa7456d8231046f4018dfc0ab2ca232e8b4b7c072bafddc26a2c2bfdda45582",
        "warmup_time": -1
    },
    "sparse.ArithmeticBlock.time_division": {
        "code": "class ArithmeticBlock:\n    def time_division(self, fill_value):\n        self.arr1 / self.arr2\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10 ** 6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )",
        "min_run_count": 2,
        "name": "sparse.ArithmeticBlock.time_division",
        "number": 0,
        "param_names": [
            "fill_value"
        ],
        "params": [
            [
                "nan",
                "0"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fa3c59a173cde96c1be380109f21c29633aba022d053a229c051ddb5d23f67a7",
        "warmup_time": -1
    },
    "sparse.ArithmeticBlock.time_intersect": {
        "code": "class ArithmeticBlock:\n    def time_intersect(self, fill_value):\n        self.arr2.sp_index.intersect(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10 ** 6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )",
        "min_run_count": 2,
        "name": "sparse.ArithmeticBlock.time_intersect",
        "number": 0,
        "param_names": [
            "fill_value"
        ],
        "params": [
            [
                "nan",
                "0"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "01cf06f7ede3046f484ec73e8bf0393ab9ed6380768e16b9d55d936d040d6141",
        "warmup_time": -1
    },
    "sparse.ArithmeticBlock.time_make_union": {
        "code": "class ArithmeticBlock:\n    def time_make_union(self, fill_value):\n        self.arr1.sp_index.make_union(self.arr2.sp_index)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ArithmeticBlock:\n    def setup(self, fill_value):\n        N = 10 ** 6\n        self.arr1 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )\n        self.arr2 = self.make_block_array(\n            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\n        )",
        "min_run_count": 2,
        "name": "sparse.ArithmeticBlock.time_make_union",
        "number": 0,
        "param_names": [
            "fill_value"
        ],
        "params": [
            [
                "nan",
                "0"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c745ab8dd8ff3616362efe3e0fbc800f03b64ae5eed805d11c170cd9881bb096",
        "warmup_time": -1
    },
    "sparse.FromCoo.time_sparse_series_from_coo": {
        "code": "class FromCoo:\n    def time_sparse_series_from_coo(self):\n        Series.sparse.from_coo(self.matrix)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FromCoo:\n    def setup(self):\n        self.matrix = scipy.sparse.coo_matrix(\n            ([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])), shape=(100, 100)\n        )",
        "min_run_count": 2,
        "name": "sparse.FromCoo.time_sparse_series_from_coo",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "195924096fa77c5284cc4c2886c3e4e1ec58441bb83c1afe52ee2d94f9987a1a",
        "warmup_time": -1
    },
    "sparse.GetItem.time_integer_indexing": {
        "code": "class GetItem:\n    def time_integer_indexing(self):\n        self.sp_arr[78]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItem:\n    def setup(self):\n        N = 1_000_000\n        arr = make_array(N, 1e-5, np.nan, np.float64)\n        self.sp_arr = SparseArray(arr)",
        "min_run_count": 2,
        "name": "sparse.GetItem.time_integer_indexing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e693094705bcdbac0543eabef058bd7a4cbd47fa0f6e21bf78c7888f6e3881a8",
        "warmup_time": -1
    },
    "sparse.GetItem.time_slice": {
        "code": "class GetItem:\n    def time_slice(self):\n        self.sp_arr[1:]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass GetItem:\n    def setup(self):\n        N = 1_000_000\n        arr = make_array(N, 1e-5, np.nan, np.float64)\n        self.sp_arr = SparseArray(arr)",
        "min_run_count": 2,
        "name": "sparse.GetItem.time_slice",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f08f2a3702730e36e464dd91fd27b15ba36ebd3cadb746b6520fb810362a6663",
        "warmup_time": -1
    },
    "sparse.MinMax.time_min_max": {
        "code": "class MinMax:\n    def time_min_max(self, func, fill_value):\n        getattr(self.sp_arr, func)()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass MinMax:\n    def setup(self, func, fill_value):\n        N = 1_000_000\n        arr = make_array(N, 1e-5, fill_value, np.float64)\n        self.sp_arr = SparseArray(arr, fill_value=fill_value)",
        "min_run_count": 2,
        "name": "sparse.MinMax.time_min_max",
        "number": 0,
        "param_names": [
            "func",
            "fill_value"
        ],
        "params": [
            [
                "'min'",
                "'max'"
            ],
            [
                "0.0",
                "nan"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5666067aa9bdd3647031cbff0f601ab81231b8c4dc791adc44067a9f361d169a",
        "warmup_time": -1
    },
    "sparse.SparseArrayConstructor.time_sparse_array": {
        "code": "class SparseArrayConstructor:\n    def time_sparse_array(self, dense_proportion, fill_value, dtype):\n        SparseArray(self.array, fill_value=fill_value, dtype=dtype)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseArrayConstructor:\n    def setup(self, dense_proportion, fill_value, dtype):\n        N = 10 ** 6\n        self.array = make_array(N, dense_proportion, fill_value, dtype)",
        "min_run_count": 2,
        "name": "sparse.SparseArrayConstructor.time_sparse_array",
        "number": 0,
        "param_names": [
            "dense_proportion",
            "fill_value",
            "dtype"
        ],
        "params": [
            [
                "0.1",
                "0.01"
            ],
            [
                "0",
                "nan"
            ],
            [
                "<class 'numpy.int64'>",
                "<class 'numpy.float64'>",
                "<class 'object'>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1b11717b655d22ab20e971cb29f9f7b1508926f803e0a258cb13f6ad57ab2087",
        "warmup_time": -1
    },
    "sparse.SparseDataFrameConstructor.time_from_scipy": {
        "code": "class SparseDataFrameConstructor:\n    def time_from_scipy(self):\n        pd.DataFrame.sparse.from_spmatrix(self.sparse)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseDataFrameConstructor:\n    def setup(self):\n        N = 1000\n        self.sparse = scipy.sparse.rand(N, N, 0.005)",
        "min_run_count": 2,
        "name": "sparse.SparseDataFrameConstructor.time_from_scipy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "177d56dfb0c583f7adb94c9adb8e996066558bf79bf5c7600620c4d85eac136f",
        "warmup_time": -1
    },
    "sparse.SparseSeriesToFrame.time_series_to_frame": {
        "code": "class SparseSeriesToFrame:\n    def time_series_to_frame(self):\n        pd.DataFrame(self.series)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SparseSeriesToFrame:\n    def setup(self):\n        K = 50\n        N = 50001\n        rng = date_range(\"1/1/2000\", periods=N, freq=\"T\")\n        self.series = {}\n        for i in range(1, K):\n            data = np.random.randn(N)[:-i]\n            idx = rng[:-i]\n            data[100:] = np.nan\n            self.series[i] = Series(SparseArray(data), index=idx)",
        "min_run_count": 2,
        "name": "sparse.SparseSeriesToFrame.time_series_to_frame",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "958fc2dfe9fbb7797c443ce83b375465a50d39572756f392d84591271d225ee5",
        "warmup_time": -1
    },
    "sparse.Take.time_take": {
        "code": "class Take:\n    def time_take(self, indices, allow_fill):\n        self.sp_arr.take(indices, allow_fill=allow_fill)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Take:\n    def setup(self, indices, allow_fill):\n        N = 1_000_000\n        fill_value = 0.0\n        arr = make_array(N, 1e-5, fill_value, np.float64)\n        self.sp_arr = SparseArray(arr, fill_value=fill_value)",
        "min_run_count": 2,
        "name": "sparse.Take.time_take",
        "number": 0,
        "param_names": [
            "indices",
            "allow_fill"
        ],
        "params": [
            [
                "array([0])",
                "array([    0,     1,     2, ..., 99997, 99998, 99999])",
                "array([-1, -1, -1, ..., -1, -1, -1])"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "de40b85a6b156eead56c80f2a8a02564cec85e5cda7f49c947f0385fc4552dbb",
        "warmup_time": -1
    },
    "sparse.ToCoo.time_sparse_series_to_coo": {
        "code": "class ToCoo:\n    def time_sparse_series_to_coo(self, sort_labels):\n        self.ss_mult_lvl.sparse.to_coo(\n            row_levels=[0, 1], column_levels=[2, 3], sort_labels=sort_labels\n        )\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCoo:\n    def setup(self, sort_labels):\n        s = Series([np.nan] * 10000)\n        s[0] = 3.0\n        s[100] = -1.0\n        s[999] = 12.1\n    \n        s_mult_lvl = s.set_axis(MultiIndex.from_product([range(10)] * 4))\n        self.ss_mult_lvl = s_mult_lvl.astype(\"Sparse\")\n    \n        s_two_lvl = s.set_axis(MultiIndex.from_product([range(100)] * 2))\n        self.ss_two_lvl = s_two_lvl.astype(\"Sparse\")",
        "min_run_count": 2,
        "name": "sparse.ToCoo.time_sparse_series_to_coo",
        "number": 0,
        "param_names": [
            "sort_labels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "30ca6ac73768cb7fe0d759bfd836f6ccc90dbdfcd666842cfe90d333c4063300",
        "warmup_time": -1
    },
    "sparse.ToCoo.time_sparse_series_to_coo_single_level": {
        "code": "class ToCoo:\n    def time_sparse_series_to_coo_single_level(self, sort_labels):\n        self.ss_two_lvl.sparse.to_coo(sort_labels=sort_labels)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCoo:\n    def setup(self, sort_labels):\n        s = Series([np.nan] * 10000)\n        s[0] = 3.0\n        s[100] = -1.0\n        s[999] = 12.1\n    \n        s_mult_lvl = s.set_axis(MultiIndex.from_product([range(10)] * 4))\n        self.ss_mult_lvl = s_mult_lvl.astype(\"Sparse\")\n    \n        s_two_lvl = s.set_axis(MultiIndex.from_product([range(100)] * 2))\n        self.ss_two_lvl = s_two_lvl.astype(\"Sparse\")",
        "min_run_count": 2,
        "name": "sparse.ToCoo.time_sparse_series_to_coo_single_level",
        "number": 0,
        "param_names": [
            "sort_labels"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9f146457117b9ef50ec361711446aad79f7c706f074b3b9d901b5536c47680c0",
        "warmup_time": -1
    },
    "sparse.ToCooFrame.time_to_coo": {
        "code": "class ToCooFrame:\n    def time_to_coo(self):\n        self.df.sparse.to_coo()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ToCooFrame:\n    def setup(self):\n        N = 10000\n        k = 10\n        arr = np.zeros((N, k), dtype=float)\n        arr[0, 0] = 3.0\n        arr[12, 7] = -1.0\n        arr[0, 9] = 11.2\n        self.df = pd.DataFrame(arr, dtype=pd.SparseDtype(\"float\", fill_value=0.0))",
        "min_run_count": 2,
        "name": "sparse.ToCooFrame.time_to_coo",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "aa52b43e43b97a10066b7eb8a13b85c06203c3660e6293bf051b23418b51d48a",
        "warmup_time": -1
    },
    "stat_ops.Correlation.peakmem_corr_wide": {
        "code": "class Correlation:\n    def peakmem_corr_wide(self, method):\n        self.df_wide.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))",
        "name": "stat_ops.Correlation.peakmem_corr_wide",
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'spearman'",
                "'kendall'",
                "'pearson'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "3ee8f436749f1f2d1f0a071b811c2fa8f22e5b7bfa05919d0449957533179b9a"
    },
    "stat_ops.Correlation.time_corr": {
        "code": "class Correlation:\n    def time_corr(self, method):\n        self.df.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))",
        "min_run_count": 2,
        "name": "stat_ops.Correlation.time_corr",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'spearman'",
                "'kendall'",
                "'pearson'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "985b3d9669fc0dfe69164a9a3e932c4cab6585326d0af33ff34da7dcfcc72ecd",
        "warmup_time": -1
    },
    "stat_ops.Correlation.time_corr_series": {
        "code": "class Correlation:\n    def time_corr_series(self, method):\n        self.s.corr(self.s2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))",
        "min_run_count": 2,
        "name": "stat_ops.Correlation.time_corr_series",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'spearman'",
                "'kendall'",
                "'pearson'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "15f8a4d1a6ad3002de031f6c6188e46257f89004dd83e0efb0133cda90ddfa33",
        "warmup_time": -1
    },
    "stat_ops.Correlation.time_corr_wide": {
        "code": "class Correlation:\n    def time_corr_wide(self, method):\n        self.df_wide.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))",
        "min_run_count": 2,
        "name": "stat_ops.Correlation.time_corr_wide",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'spearman'",
                "'kendall'",
                "'pearson'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "54637cc9be24613ba7ed8eb9724167b189a287c89fc91fcc80840fa02444d657",
        "warmup_time": -1
    },
    "stat_ops.Correlation.time_corr_wide_nans": {
        "code": "class Correlation:\n    def time_corr_wide_nans(self, method):\n        self.df_wide_nans.corr(method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))",
        "min_run_count": 2,
        "name": "stat_ops.Correlation.time_corr_wide_nans",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'spearman'",
                "'kendall'",
                "'pearson'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "07c00330d5c6a030d9e77e6aaec677ed606490cdf7f574cf00748a8a8d00c6b9",
        "warmup_time": -1
    },
    "stat_ops.Correlation.time_corrwith_cols": {
        "code": "class Correlation:\n    def time_corrwith_cols(self, method):\n        self.df.corrwith(self.df2, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))",
        "min_run_count": 2,
        "name": "stat_ops.Correlation.time_corrwith_cols",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'spearman'",
                "'kendall'",
                "'pearson'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5d0002de6d691b52406c99ef171a6bef8d6f9569a32c8223c1544b748f1cee3f",
        "warmup_time": -1
    },
    "stat_ops.Correlation.time_corrwith_rows": {
        "code": "class Correlation:\n    def time_corrwith_rows(self, method):\n        self.df.corrwith(self.df2, axis=1, method=method)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Correlation:\n    def setup(self, method):\n        self.df = pd.DataFrame(np.random.randn(500, 15))\n        self.df2 = pd.DataFrame(np.random.randn(500, 15))\n        self.df_wide = pd.DataFrame(np.random.randn(500, 100))\n        self.df_wide_nans = self.df_wide.where(np.random.random((500, 100)) < 0.9)\n        self.s = pd.Series(np.random.randn(500))\n        self.s2 = pd.Series(np.random.randn(500))",
        "min_run_count": 2,
        "name": "stat_ops.Correlation.time_corrwith_rows",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'spearman'",
                "'kendall'",
                "'pearson'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "537c1ca1a5384e46898eef91e2a713efab1b5f27bece96d73baa8c1084a319eb",
        "warmup_time": -1
    },
    "stat_ops.Covariance.time_cov_series": {
        "code": "class Covariance:\n    def time_cov_series(self):\n        self.s.cov(self.s2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Covariance:\n    def setup(self):\n        self.s = pd.Series(np.random.randn(100000))\n        self.s2 = pd.Series(np.random.randn(100000))",
        "min_run_count": 2,
        "name": "stat_ops.Covariance.time_cov_series",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5127b263e3a6473e609cbc77952bf516e224e61656efd15280caf5a2bd93ac5f",
        "warmup_time": -1
    },
    "stat_ops.FrameMultiIndexOps.time_op": {
        "code": "class FrameMultiIndexOps:\n    def time_op(self, level, op):\n        self.df_func(level=level)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameMultiIndexOps:\n    def setup(self, level, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [\n            np.arange(10).repeat(10000),\n            np.tile(np.arange(100).repeat(100), 10),\n            np.tile(np.tile(np.arange(100), 100), 10),\n        ]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        df = pd.DataFrame(np.random.randn(len(index), 4), index=index)\n        self.df_func = getattr(df, op)",
        "min_run_count": 2,
        "name": "stat_ops.FrameMultiIndexOps.time_op",
        "number": 0,
        "param_names": [
            "level",
            "op"
        ],
        "params": [
            [
                "0",
                "1",
                "[0, 1]"
            ],
            [
                "'mean'",
                "'sum'",
                "'median'",
                "'std'",
                "'skew'",
                "'kurt'",
                "'mad'",
                "'prod'",
                "'sem'",
                "'var'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6a68377455dbf105dab9d22b0d5b16b7dccd45318f92080ed3812c059da9913c",
        "warmup_time": -1
    },
    "stat_ops.FrameOps.time_op": {
        "code": "class FrameOps:\n    def time_op(self, op, dtype, axis):\n        self.df_func(axis=axis)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass FrameOps:\n    def setup(self, op, dtype, axis):\n        if op == \"mad\" and dtype == \"Int64\":\n            # GH-33036, GH#33600\n            raise NotImplementedError\n        values = np.random.randn(100000, 4)\n        if dtype == \"Int64\":\n            values = values.astype(int)\n        df = pd.DataFrame(values).astype(dtype)\n        self.df_func = getattr(df, op)",
        "min_run_count": 2,
        "name": "stat_ops.FrameOps.time_op",
        "number": 0,
        "param_names": [
            "op",
            "dtype",
            "axis"
        ],
        "params": [
            [
                "'mean'",
                "'sum'",
                "'median'",
                "'std'",
                "'skew'",
                "'kurt'",
                "'mad'",
                "'prod'",
                "'sem'",
                "'var'"
            ],
            [
                "'float'",
                "'int'",
                "'Int64'"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0541c291a5dc102df2b71c56c12b0f0396bfab5fdb92db2cef2e86f73f565700",
        "warmup_time": -1
    },
    "stat_ops.Rank.time_average_old": {
        "code": "class Rank:\n    def time_average_old(self, constructor, pct):\n        self.data.rank(pct=pct) / len(self.data)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10 ** 5)\n        self.data = getattr(pd, constructor)(values)",
        "min_run_count": 2,
        "name": "stat_ops.Rank.time_average_old",
        "number": 0,
        "param_names": [
            "constructor",
            "pct"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "00a179722cc381288014eed63c8091c86059d4c06852e43c9ac20102351f5823",
        "warmup_time": -1
    },
    "stat_ops.Rank.time_rank": {
        "code": "class Rank:\n    def time_rank(self, constructor, pct):\n        self.data.rank(pct=pct)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Rank:\n    def setup(self, constructor, pct):\n        values = np.random.randn(10 ** 5)\n        self.data = getattr(pd, constructor)(values)",
        "min_run_count": 2,
        "name": "stat_ops.Rank.time_rank",
        "number": 0,
        "param_names": [
            "constructor",
            "pct"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b7e9c2d8abcf7eb11378659098c57ab702c80090bf15b137cf5df66a4f229b64",
        "warmup_time": -1
    },
    "stat_ops.SeriesMultiIndexOps.time_op": {
        "code": "class SeriesMultiIndexOps:\n    def time_op(self, level, op):\n        self.s_func(level=level)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesMultiIndexOps:\n    def setup(self, level, op):\n        levels = [np.arange(10), np.arange(100), np.arange(100)]\n        codes = [\n            np.arange(10).repeat(10000),\n            np.tile(np.arange(100).repeat(100), 10),\n            np.tile(np.tile(np.arange(100), 100), 10),\n        ]\n        index = pd.MultiIndex(levels=levels, codes=codes)\n        s = pd.Series(np.random.randn(len(index)), index=index)\n        self.s_func = getattr(s, op)",
        "min_run_count": 2,
        "name": "stat_ops.SeriesMultiIndexOps.time_op",
        "number": 0,
        "param_names": [
            "level",
            "op"
        ],
        "params": [
            [
                "0",
                "1",
                "[0, 1]"
            ],
            [
                "'mean'",
                "'sum'",
                "'median'",
                "'std'",
                "'skew'",
                "'kurt'",
                "'mad'",
                "'prod'",
                "'sem'",
                "'var'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "403631c7ed770ca35058b178411449eb532739a58c28c5937e4d7d936c93fa67",
        "warmup_time": -1
    },
    "stat_ops.SeriesOps.time_op": {
        "code": "class SeriesOps:\n    def time_op(self, op, dtype):\n        self.s_func()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SeriesOps:\n    def setup(self, op, dtype):\n        s = pd.Series(np.random.randn(100000)).astype(dtype)\n        self.s_func = getattr(s, op)",
        "min_run_count": 2,
        "name": "stat_ops.SeriesOps.time_op",
        "number": 0,
        "param_names": [
            "op",
            "dtype"
        ],
        "params": [
            [
                "'mean'",
                "'sum'",
                "'median'",
                "'std'",
                "'skew'",
                "'kurt'",
                "'mad'",
                "'prod'",
                "'sem'",
                "'var'"
            ],
            [
                "'float'",
                "'int'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "32cfffab59594606bcaccdcd64c3521e5ffec20c0dcf9b1c864e4d0a6dc41bd4",
        "warmup_time": -1
    },
    "strings.Cat.time_cat": {
        "code": "class Cat:\n    def time_cat(self, other_cols, sep, na_rep, na_frac):\n        # before the concatenation (one caller + other_cols columns), the total\n        # expected fraction of rows containing any NaN is:\n        # reduce(lambda t, _: t + (1 - t) * na_frac, range(other_cols + 1), 0)\n        # for other_cols=3 and na_frac=0.15, this works out to ~48%\n        self.s.str.cat(others=self.others, sep=sep, na_rep=na_rep)\n\n    def setup(self, other_cols, sep, na_rep, na_frac):\n        N = 10 ** 5\n        mask_gen = lambda: np.random.choice([True, False], N, p=[1 - na_frac, na_frac])\n        self.s = Series(tm.makeStringIndex(N)).where(mask_gen())\n        if other_cols == 0:\n            # str.cat self-concatenates only for others=None\n            self.others = None\n        else:\n            self.others = DataFrame(\n                {i: tm.makeStringIndex(N).where(mask_gen()) for i in range(other_cols)}\n            )",
        "min_run_count": 2,
        "name": "strings.Cat.time_cat",
        "number": 0,
        "param_names": [
            "other_cols",
            "sep",
            "na_rep",
            "na_frac"
        ],
        "params": [
            [
                "0",
                "3"
            ],
            [
                "None",
                "','"
            ],
            [
                "None",
                "'-'"
            ],
            [
                "0.0",
                "0.001",
                "0.15"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8eb58a182e7e599789eb81b837dc2769e0d6f0cb6088f85682e60acb166ccac0",
        "warmup_time": -1
    },
    "strings.Construction.peakmem_cat_frame_construction": {
        "code": "class Construction:\n    def peakmem_cat_frame_construction(self, dtype):\n        DataFrame(self.frame_cat_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10 ** 5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)",
        "name": "strings.Construction.peakmem_cat_frame_construction",
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "f785a6415575ad8a2e8e5106afb6ca8a122ec9bf6bef32656f4b73967c102cd1"
    },
    "strings.Construction.peakmem_cat_series_construction": {
        "code": "class Construction:\n    def peakmem_cat_series_construction(self, dtype):\n        Series(self.series_cat_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10 ** 5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)",
        "name": "strings.Construction.peakmem_cat_series_construction",
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "3db8edec32f863e25dac92a9d33c9bb31e2afb701271ef27f547836ed0f4cf4a"
    },
    "strings.Construction.peakmem_frame_construction": {
        "code": "class Construction:\n    def peakmem_frame_construction(self, dtype):\n        DataFrame(self.frame_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10 ** 5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)",
        "name": "strings.Construction.peakmem_frame_construction",
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "50f67bea76577538b95d203479591c3f093ffc77152739bbf62d95b8a7ac6159"
    },
    "strings.Construction.peakmem_series_construction": {
        "code": "class Construction:\n    def peakmem_series_construction(self, dtype):\n        Series(self.series_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10 ** 5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)",
        "name": "strings.Construction.peakmem_series_construction",
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string'"
            ]
        ],
        "timeout": 60.0,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "e18aec30bdec3a5a1f9111699dae97ae81866a587ad3ca4cd22076a646d81786"
    },
    "strings.Construction.time_cat_frame_construction": {
        "code": "class Construction:\n    def time_cat_frame_construction(self, dtype):\n        DataFrame(self.frame_cat_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10 ** 5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)",
        "min_run_count": 2,
        "name": "strings.Construction.time_cat_frame_construction",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ed04dc0b495306ba2b3787b65a713c06c19d8aa5018011e6064ed7904a337e25",
        "warmup_time": -1
    },
    "strings.Construction.time_cat_series_construction": {
        "code": "class Construction:\n    def time_cat_series_construction(self, dtype):\n        Series(self.series_cat_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10 ** 5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)",
        "min_run_count": 2,
        "name": "strings.Construction.time_cat_series_construction",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "161c222af738625ceb71fe610098dacd6802a86001b8d613b537b59778288699",
        "warmup_time": -1
    },
    "strings.Construction.time_frame_construction": {
        "code": "class Construction:\n    def time_frame_construction(self, dtype):\n        DataFrame(self.frame_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10 ** 5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)",
        "min_run_count": 2,
        "name": "strings.Construction.time_frame_construction",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "19ca3444773a6d959de45ca4631b2c13b4d314562a8ffec9ac57aa8c543ad032",
        "warmup_time": -1
    },
    "strings.Construction.time_series_construction": {
        "code": "class Construction:\n    def time_series_construction(self, dtype):\n        Series(self.series_arr, dtype=dtype)\n\n    def setup(self, dtype):\n        self.series_arr = tm.rands_array(nchars=10, size=10 ** 5)\n        self.frame_arr = self.series_arr.reshape((50_000, 2)).copy()\n    \n        # GH37371. Testing construction of string series/frames from ExtensionArrays\n        self.series_cat_arr = Categorical(self.series_arr)\n        self.frame_cat_arr = Categorical(self.frame_arr)",
        "min_run_count": 2,
        "name": "strings.Construction.time_series_construction",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "437b54d7f9293b3c7828e92a7be1d2fada6664e11182b6eeb2e2589d6fd46543",
        "warmup_time": -1
    },
    "strings.Contains.time_contains": {
        "code": "class Contains:\n    def time_contains(self, dtype, regex):\n        self.s.str.contains(\"A\", regex=regex)\n\n    def setup(self, dtype, regex):\n        super().setup(dtype)",
        "min_run_count": 2,
        "name": "strings.Contains.time_contains",
        "number": 0,
        "param_names": [
            "dtype",
            "regex"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "059d755b738e508f2767456a3bcb5561731b1d7d8ac1ad2e92fddc4828e30270",
        "warmup_time": -1
    },
    "strings.Dummies.time_get_dummies": {
        "code": "class Dummies:\n    def time_get_dummies(self, dtype):\n        self.s.str.get_dummies(\"|\")\n\n    def setup(self, dtype):\n        super().setup(dtype)\n        self.s = self.s.str.join(\"|\")",
        "min_run_count": 2,
        "name": "strings.Dummies.time_get_dummies",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "05a8b467626fc1ca2b62daa6ea86653c41533ff9cba30dddb51f622ecbe0e6e6",
        "warmup_time": -1
    },
    "strings.Encode.time_encode_decode": {
        "code": "class Encode:\n    def time_encode_decode(self):\n        self.ser.str.encode(\"utf-8\").str.decode(\"utf-8\")\n\n    def setup(self):\n        self.ser = Series(tm.makeUnicodeIndex())",
        "min_run_count": 2,
        "name": "strings.Encode.time_encode_decode",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7991afc08fb85f2e7a8a10a61fdf3f06df4a2d94f48fe9cd517f60f1b2a56a99",
        "warmup_time": -1
    },
    "strings.Extract.time_extract_single_group": {
        "code": "class Extract:\n    def time_extract_single_group(self, dtype, expand):\n        with warnings.catch_warnings(record=True):\n            self.s.str.extract(\"(\\\\w*)A\", expand=expand)\n\n    def setup(self, dtype, expand):\n        super().setup(dtype)",
        "min_run_count": 2,
        "name": "strings.Extract.time_extract_single_group",
        "number": 0,
        "param_names": [
            "dtype",
            "expand"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4a4c5c7bdd1645c137d0f4bcafc4eb9b92be955e5bb27fd6fe7994d2466c32e7",
        "warmup_time": -1
    },
    "strings.Iter.time_iter": {
        "code": "class Iter:\n    def time_iter(self, dtype):\n        for i in self.s:\n            pass\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Iter.time_iter",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4d15a54cf324d7b6be14a1f4043978218afb00a8020ad142a95f929196fe12e8",
        "warmup_time": -1
    },
    "strings.Methods.time_center": {
        "code": "class Methods:\n    def time_center(self, dtype):\n        self.s.str.center(100)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_center",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7a7f2cf584fcc50e2f328c21435138c1b401beb8524d976bf7b00598e990b686",
        "warmup_time": -1
    },
    "strings.Methods.time_count": {
        "code": "class Methods:\n    def time_count(self, dtype):\n        self.s.str.count(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_count",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "902f68f169d6634211bdcad4fa69acffd0a36d7a1c374d9cc9a99995b7d81bae",
        "warmup_time": -1
    },
    "strings.Methods.time_endswith": {
        "code": "class Methods:\n    def time_endswith(self, dtype):\n        self.s.str.endswith(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_endswith",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2c979ce21931d014571b446bf36c590da34c1df693a1e12ca0c6ce62fcb1e731",
        "warmup_time": -1
    },
    "strings.Methods.time_extract": {
        "code": "class Methods:\n    def time_extract(self, dtype):\n        with warnings.catch_warnings(record=True):\n            self.s.str.extract(\"(\\\\w*)A(\\\\w*)\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_extract",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b72781221e7284e96000a80bba9ad2fbfb927a84359a16758cc8620400059d72",
        "warmup_time": -1
    },
    "strings.Methods.time_find": {
        "code": "class Methods:\n    def time_find(self, dtype):\n        self.s.str.find(\"[A-Z]+\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_find",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1affc9a899eab2dac712d60b6213e14262e026bd0c218f357bafe2ea6ccead72",
        "warmup_time": -1
    },
    "strings.Methods.time_findall": {
        "code": "class Methods:\n    def time_findall(self, dtype):\n        self.s.str.findall(\"[A-Z]+\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_findall",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5d78272de414065e71b12302153845570e9a9113ec64d91c90e7a736203877a1",
        "warmup_time": -1
    },
    "strings.Methods.time_fullmatch": {
        "code": "class Methods:\n    def time_fullmatch(self, dtype):\n        self.s.str.fullmatch(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_fullmatch",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "764956d315bf83b0af4d9fa75f78e9c9247c5f517fcaa6e7be06f47a92d0e2e2",
        "warmup_time": -1
    },
    "strings.Methods.time_get": {
        "code": "class Methods:\n    def time_get(self, dtype):\n        self.s.str.get(0)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_get",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f5501f5deb099602e5199b2ec4e63758d4dfe04e6320f0ee9ba220d0a43183c9",
        "warmup_time": -1
    },
    "strings.Methods.time_isalnum": {
        "code": "class Methods:\n    def time_isalnum(self, dtype):\n        self.s.str.isalnum()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_isalnum",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "219ee7320adc247e3c99b99ad118ba2aab3da4333b0903a31e9e0d2fa27a3f43",
        "warmup_time": -1
    },
    "strings.Methods.time_isalpha": {
        "code": "class Methods:\n    def time_isalpha(self, dtype):\n        self.s.str.isalpha()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_isalpha",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "20944810c059690bd60695c06195842d4563af3b76b78cf27be33558a23a1664",
        "warmup_time": -1
    },
    "strings.Methods.time_isdecimal": {
        "code": "class Methods:\n    def time_isdecimal(self, dtype):\n        self.s.str.isdecimal()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_isdecimal",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eccf8243af014ebfe11ce7ef9cafb44f0aac9e6b42e5285460d571d783ec2c83",
        "warmup_time": -1
    },
    "strings.Methods.time_isdigit": {
        "code": "class Methods:\n    def time_isdigit(self, dtype):\n        self.s.str.isdigit()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_isdigit",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4c65917e40f06f8d6fcd09dd6722837bd096c6c14311ae58183e45f17a0c9d5e",
        "warmup_time": -1
    },
    "strings.Methods.time_islower": {
        "code": "class Methods:\n    def time_islower(self, dtype):\n        self.s.str.islower()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_islower",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8f09d20e6c490d30e5e6b3d3a41d10eae4a6efd9b6d64b6cb3aadcf82dacc863",
        "warmup_time": -1
    },
    "strings.Methods.time_isnumeric": {
        "code": "class Methods:\n    def time_isnumeric(self, dtype):\n        self.s.str.isnumeric()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_isnumeric",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "be9790062d31abaa74a163652972c55b5a61bfec0134bcafdbacb575bb4911a9",
        "warmup_time": -1
    },
    "strings.Methods.time_isspace": {
        "code": "class Methods:\n    def time_isspace(self, dtype):\n        self.s.str.isspace()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_isspace",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3d07dc1aabbbc6c3a0441c1e2b148ee44ee3e5b4bb6ee80203e43c5ea0b41ae3",
        "warmup_time": -1
    },
    "strings.Methods.time_istitle": {
        "code": "class Methods:\n    def time_istitle(self, dtype):\n        self.s.str.istitle()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_istitle",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "20f8091f7e76b4236271efaf120b5a156c3dd1a25b74e6a6db9c5116f42be48d",
        "warmup_time": -1
    },
    "strings.Methods.time_isupper": {
        "code": "class Methods:\n    def time_isupper(self, dtype):\n        self.s.str.isupper()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_isupper",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "be2ff160b2c928b42882607c8b78389c12a68efa268ed07dad86ac97fb139192",
        "warmup_time": -1
    },
    "strings.Methods.time_join": {
        "code": "class Methods:\n    def time_join(self, dtype):\n        self.s.str.join(\" \")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_join",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "435f1452d7afd6dbc93aec8d8c7a3dfc18692db5ec5b1a6098445f05c715fb4b",
        "warmup_time": -1
    },
    "strings.Methods.time_len": {
        "code": "class Methods:\n    def time_len(self, dtype):\n        self.s.str.len()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_len",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "561181a41997a60d2f194c782e6b156e0b81dcbf34a070c0cd535c488ac5e29e",
        "warmup_time": -1
    },
    "strings.Methods.time_lower": {
        "code": "class Methods:\n    def time_lower(self, dtype):\n        self.s.str.lower()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_lower",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6f6cea1ab63d6a90b6b2526cd404015dab1bdf42059b9380cdb3545a34443e31",
        "warmup_time": -1
    },
    "strings.Methods.time_lstrip": {
        "code": "class Methods:\n    def time_lstrip(self, dtype):\n        self.s.str.lstrip(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_lstrip",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a4b7141e791cac94087c92a051b4ff36c2a40f7b59bf701e9b24f27ced8a87a7",
        "warmup_time": -1
    },
    "strings.Methods.time_match": {
        "code": "class Methods:\n    def time_match(self, dtype):\n        self.s.str.match(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_match",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "86677ae7b0ef994bbf7dcae5583a873e585e0fbf45e337a7d10ae9c079f2b8bd",
        "warmup_time": -1
    },
    "strings.Methods.time_normalize": {
        "code": "class Methods:\n    def time_normalize(self, dtype):\n        self.s.str.normalize(\"NFC\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_normalize",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7fd8675b89b4a376e2605f60a126b273204d0866572de6ae516a66d73bf97538",
        "warmup_time": -1
    },
    "strings.Methods.time_pad": {
        "code": "class Methods:\n    def time_pad(self, dtype):\n        self.s.str.pad(100, side=\"both\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_pad",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bbb44ad28fbfb63ff71da58b54ef63191c9eaccc89d28c8921aa965b32540cb3",
        "warmup_time": -1
    },
    "strings.Methods.time_partition": {
        "code": "class Methods:\n    def time_partition(self, dtype):\n        self.s.str.partition(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_partition",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d6c9298f66dfbdae67c7b62025dbf206d4f9f32f1a2a02bd53e3411b58255184",
        "warmup_time": -1
    },
    "strings.Methods.time_replace": {
        "code": "class Methods:\n    def time_replace(self, dtype):\n        self.s.str.replace(\"A\", \"\\x01\\x01\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_replace",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8e8b7fd39589c65815b5bfa41f6d6f6918e0a665d9d337d770c8c195a8bef3bf",
        "warmup_time": -1
    },
    "strings.Methods.time_rfind": {
        "code": "class Methods:\n    def time_rfind(self, dtype):\n        self.s.str.rfind(\"[A-Z]+\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_rfind",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "740dedeb1f2e5356d7c7d835f71838b00294ad4b059bd8ccbb5bafe6eb1810fe",
        "warmup_time": -1
    },
    "strings.Methods.time_rpartition": {
        "code": "class Methods:\n    def time_rpartition(self, dtype):\n        self.s.str.rpartition(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_rpartition",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4b8493eb6af8cc594f673afd6713e7b260bb8af7f17a0e7ea93b5f7eedb33116",
        "warmup_time": -1
    },
    "strings.Methods.time_rstrip": {
        "code": "class Methods:\n    def time_rstrip(self, dtype):\n        self.s.str.rstrip(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_rstrip",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5013724b5f8e43b609681412f5ed00a1199f48b37c508d0b7a56b9b0f1694efd",
        "warmup_time": -1
    },
    "strings.Methods.time_slice": {
        "code": "class Methods:\n    def time_slice(self, dtype):\n        self.s.str.slice(5, 15, 2)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_slice",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fd25432e8413c851228736aed1f22d6d762b9c62dbb9727a63f37d7099a150b6",
        "warmup_time": -1
    },
    "strings.Methods.time_startswith": {
        "code": "class Methods:\n    def time_startswith(self, dtype):\n        self.s.str.startswith(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_startswith",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f581d64c86db51224383ce6f416ecf26fd6d8f14f715fb22a9a7ee4eed451393",
        "warmup_time": -1
    },
    "strings.Methods.time_strip": {
        "code": "class Methods:\n    def time_strip(self, dtype):\n        self.s.str.strip(\"A\")\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_strip",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d610c994010f8b500f34f12e30baa599c4eb8a9e28efea9c87427b731079ea05",
        "warmup_time": -1
    },
    "strings.Methods.time_title": {
        "code": "class Methods:\n    def time_title(self, dtype):\n        self.s.str.title()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_title",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5ecb2d5fea0b7d7ffd93fe5d47fc88f40aaa882b8f1ba3e899c7304f0dba9a5d",
        "warmup_time": -1
    },
    "strings.Methods.time_translate": {
        "code": "class Methods:\n    def time_translate(self, dtype):\n        self.s.str.translate({\"A\": \"\\x01\\x01\"})\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_translate",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e7f29c2170cf1dae472b2cbbef6910e1b9b83219435a78926d263e07dec27b7d",
        "warmup_time": -1
    },
    "strings.Methods.time_upper": {
        "code": "class Methods:\n    def time_upper(self, dtype):\n        self.s.str.upper()\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_upper",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "273a969b6b4c93b54318cdfbfd2ca3b603bb790b6d2e4666a232b9a5a10a165c",
        "warmup_time": -1
    },
    "strings.Methods.time_wrap": {
        "code": "class Methods:\n    def time_wrap(self, dtype):\n        self.s.str.wrap(10)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_wrap",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c9329b6d87f59f5a2c9211417118ab998abf81e2064967f215474970613139fc",
        "warmup_time": -1
    },
    "strings.Methods.time_zfill": {
        "code": "class Methods:\n    def time_zfill(self, dtype):\n        self.s.str.zfill(10)\n\nclass Dtypes:\n    def setup(self, dtype):\n        try:\n            self.s = Series(tm.makeStringIndex(10 ** 5), dtype=dtype)\n        except ImportError:\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "strings.Methods.time_zfill",
        "number": 0,
        "param_names": [
            "dtype"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c042a289f96afca444b3f7adbd20eaaa5a3180dfdde394f3da9d651183e0a7d3",
        "warmup_time": -1
    },
    "strings.Repeat.time_repeat": {
        "code": "class Repeat:\n    def time_repeat(self, repeats):\n        self.s.str.repeat(self.values)\n\n    def setup(self, repeats):\n        N = 10 ** 5\n        self.s = Series(tm.makeStringIndex(N))\n        repeat = {\"int\": 1, \"array\": np.random.randint(1, 3, N)}\n        self.values = repeat[repeats]",
        "min_run_count": 2,
        "name": "strings.Repeat.time_repeat",
        "number": 0,
        "param_names": [
            "repeats"
        ],
        "params": [
            [
                "'int'",
                "'array'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d1c054ab32273dc4270ccb7ade724c83ebaa9472afd7c7248dc3b28a6167ab3c",
        "warmup_time": -1
    },
    "strings.Slice.time_vector_slice": {
        "code": "class Slice:\n    def time_vector_slice(self):\n        # GH 2602\n        self.s.str[:5]\n\n    def setup(self):\n        self.s = Series([\"abcdefg\", np.nan] * 500000)",
        "min_run_count": 2,
        "name": "strings.Slice.time_vector_slice",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "aaf1ec9c90cc2539c76cae9af1c26b6b5ffb1d0311ec7d6dafe7d228d106ef86",
        "warmup_time": -1
    },
    "strings.Split.time_rsplit": {
        "code": "class Split:\n    def time_rsplit(self, dtype, expand):\n        self.s.str.rsplit(\"--\", expand=expand)\n\n    def setup(self, dtype, expand):\n        super().setup(dtype)\n        self.s = self.s.str.join(\"--\")",
        "min_run_count": 2,
        "name": "strings.Split.time_rsplit",
        "number": 0,
        "param_names": [
            "dtype",
            "expand"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c748bf724293b4083adf3d91ce7a5255043bddcd7ecaba38777cac47767ad1f0",
        "warmup_time": -1
    },
    "strings.Split.time_split": {
        "code": "class Split:\n    def time_split(self, dtype, expand):\n        self.s.str.split(\"--\", expand=expand)\n\n    def setup(self, dtype, expand):\n        super().setup(dtype)\n        self.s = self.s.str.join(\"--\")",
        "min_run_count": 2,
        "name": "strings.Split.time_split",
        "number": 0,
        "param_names": [
            "dtype",
            "expand"
        ],
        "params": [
            [
                "'str'",
                "'string[python]'",
                "'string[pyarrow]'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "abecb3cbc4195a6fedc3bc41353ecd447d36060b1cd5e43944cda06edfa8a2e6",
        "warmup_time": -1
    },
    "timedelta.DatetimeAccessor.time_dt_accessor": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor(self, series):\n        series.dt\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series",
        "min_run_count": 2,
        "name": "timedelta.DatetimeAccessor.time_dt_accessor",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "timedelta:14",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "56ad9655f66a0485943ce9ca9547af9c97e48f5b12779c60896c3147c5422526",
        "warmup_time": -1
    },
    "timedelta.DatetimeAccessor.time_timedelta_days": {
        "code": "class DatetimeAccessor:\n    def time_timedelta_days(self, series):\n        series.dt.days\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series",
        "min_run_count": 2,
        "name": "timedelta.DatetimeAccessor.time_timedelta_days",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "timedelta:14",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "06c603c515e826893772c4d64fe4de8ff76367d3c422060262604d4917fbec03",
        "warmup_time": -1
    },
    "timedelta.DatetimeAccessor.time_timedelta_microseconds": {
        "code": "class DatetimeAccessor:\n    def time_timedelta_microseconds(self, series):\n        series.dt.microseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series",
        "min_run_count": 2,
        "name": "timedelta.DatetimeAccessor.time_timedelta_microseconds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "timedelta:14",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6504e61d63ba227783a76d2cab32c1d791b1af813406a8c384fc386ca60b1898",
        "warmup_time": -1
    },
    "timedelta.DatetimeAccessor.time_timedelta_nanoseconds": {
        "code": "class DatetimeAccessor:\n    def time_timedelta_nanoseconds(self, series):\n        series.dt.nanoseconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series",
        "min_run_count": 2,
        "name": "timedelta.DatetimeAccessor.time_timedelta_nanoseconds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "timedelta:14",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c1cc39aec7c93cb50ced4bf81ec26506de8bfddaaee6968142c0c018f91e296a",
        "warmup_time": -1
    },
    "timedelta.DatetimeAccessor.time_timedelta_seconds": {
        "code": "class DatetimeAccessor:\n    def time_timedelta_seconds(self, series):\n        series.dt.seconds\n\n    def setup_cache(self):\n        N = 100000\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\n        return series",
        "min_run_count": 2,
        "name": "timedelta.DatetimeAccessor.time_timedelta_seconds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "timedelta:14",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0514e9978f000e47c609125255de6d9536aed804334d426a9222e1347183702d",
        "warmup_time": -1
    },
    "timedelta.TimedeltaIndexing.time_align": {
        "code": "class TimedeltaIndexing:\n    def time_align(self):\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]",
        "min_run_count": 2,
        "name": "timedelta.TimedeltaIndexing.time_align",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f5833d39497fb06bb05cac21fd9feeebace738d8e1cb626bea9fb0bbd86049ce",
        "warmup_time": -1
    },
    "timedelta.TimedeltaIndexing.time_get_loc": {
        "code": "class TimedeltaIndexing:\n    def time_get_loc(self):\n        self.index.get_loc(self.timedelta)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]",
        "min_run_count": 2,
        "name": "timedelta.TimedeltaIndexing.time_get_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "25e9df433acdb6dcf3c1df99f789a41f9c774fba04d175a24c5b8688dad9a7f3",
        "warmup_time": -1
    },
    "timedelta.TimedeltaIndexing.time_intersection": {
        "code": "class TimedeltaIndexing:\n    def time_intersection(self):\n        self.index.intersection(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]",
        "min_run_count": 2,
        "name": "timedelta.TimedeltaIndexing.time_intersection",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c3f027dc76eb6a9ef0eff1bc06dd59ee562b54fbdb029d2a6a6c4865601424c1",
        "warmup_time": -1
    },
    "timedelta.TimedeltaIndexing.time_series_loc": {
        "code": "class TimedeltaIndexing:\n    def time_series_loc(self):\n        self.series.loc[self.timedelta]\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]",
        "min_run_count": 2,
        "name": "timedelta.TimedeltaIndexing.time_series_loc",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5902b5b4b32fc27d85bee9808b6014b1f9664e7f28f444e498a7d04083c92e05",
        "warmup_time": -1
    },
    "timedelta.TimedeltaIndexing.time_shallow_copy": {
        "code": "class TimedeltaIndexing:\n    def time_shallow_copy(self):\n        self.index._view()\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]",
        "min_run_count": 2,
        "name": "timedelta.TimedeltaIndexing.time_shallow_copy",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fae422a896cb1cff9173dd94eb799be107e0957d5845004660eed3d30e0540ba",
        "warmup_time": -1
    },
    "timedelta.TimedeltaIndexing.time_union": {
        "code": "class TimedeltaIndexing:\n    def time_union(self):\n        self.index.union(self.index2)\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]",
        "min_run_count": 2,
        "name": "timedelta.TimedeltaIndexing.time_union",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "266034126c423f3e411bf2195dc68cd983b6a181466b383df54ba9341232ad71",
        "warmup_time": -1
    },
    "timedelta.TimedeltaIndexing.time_unique": {
        "code": "class TimedeltaIndexing:\n    def time_unique(self):\n        self.index.unique()\n\n    def setup(self):\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\n        self.series = Series(range(1000), index=self.index)\n        self.timedelta = self.index[500]",
        "min_run_count": 2,
        "name": "timedelta.TimedeltaIndexing.time_unique",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "17ea4667001a64a4f9df8c9594ca120a6491a18edd28102cd5712c88535ac416",
        "warmup_time": -1
    },
    "timeseries.AsOf.time_asof": {
        "code": "class AsOf:\n    def time_asof(self, constructor):\n        self.ts.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)",
        "min_run_count": 2,
        "name": "timeseries.AsOf.time_asof",
        "number": 0,
        "param_names": [
            "constructor"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "37bd4ce5386fd0b7c34272d255acd943468380376dc1ee5dd9dea070fb806805",
        "warmup_time": -1
    },
    "timeseries.AsOf.time_asof_nan": {
        "code": "class AsOf:\n    def time_asof_nan(self, constructor):\n        self.ts2.asof(self.dates)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)",
        "min_run_count": 2,
        "name": "timeseries.AsOf.time_asof_nan",
        "number": 0,
        "param_names": [
            "constructor"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "501dd990a898123eb091528ad6846c32abada27e5834f83a86729b32c4a0bcde",
        "warmup_time": -1
    },
    "timeseries.AsOf.time_asof_nan_single": {
        "code": "class AsOf:\n    def time_asof_nan_single(self, constructor):\n        self.ts3.asof(self.date_last)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)",
        "min_run_count": 2,
        "name": "timeseries.AsOf.time_asof_nan_single",
        "number": 0,
        "param_names": [
            "constructor"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5607d6a56f2adf8c34116da998623d2111a97c21c45c0d1287f625a3ecda0055",
        "warmup_time": -1
    },
    "timeseries.AsOf.time_asof_single": {
        "code": "class AsOf:\n    def time_asof_single(self, constructor):\n        self.ts.asof(self.date)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)",
        "min_run_count": 2,
        "name": "timeseries.AsOf.time_asof_single",
        "number": 0,
        "param_names": [
            "constructor"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "afe0b338280acc8cfed3251b3ee2abf5e165c63fe746d8032f062675bf9021ac",
        "warmup_time": -1
    },
    "timeseries.AsOf.time_asof_single_early": {
        "code": "class AsOf:\n    def time_asof_single_early(self, constructor):\n        self.ts.asof(self.date_early)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass AsOf:\n    def setup(self, constructor):\n        N = 10000\n        M = 10\n        rng = date_range(start=\"1/1/1990\", periods=N, freq=\"53s\")\n        data = {\n            \"DataFrame\": DataFrame(np.random.randn(N, M)),\n            \"Series\": Series(np.random.randn(N)),\n        }\n        self.ts = data[constructor]\n        self.ts.index = rng\n        self.ts2 = self.ts.copy()\n        self.ts2.iloc[250:5000] = np.nan\n        self.ts3 = self.ts.copy()\n        self.ts3.iloc[-5000:] = np.nan\n        self.dates = date_range(start=\"1/1/1990\", periods=N * 10, freq=\"5s\")\n        self.date = self.dates[0]\n        self.date_last = self.dates[-1]\n        self.date_early = self.date - timedelta(10)",
        "min_run_count": 2,
        "name": "timeseries.AsOf.time_asof_single_early",
        "number": 0,
        "param_names": [
            "constructor"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2ce4002d656f7b5513c14e1e36605c59ff9c7a0c53ce76a87dc70c83c7052b1c",
        "warmup_time": -1
    },
    "timeseries.DatetimeAccessor.time_dt_accessor": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor(self, tz):\n        self.series.dt\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))",
        "min_run_count": 2,
        "name": "timeseries.DatetimeAccessor.time_dt_accessor",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9eda40bf3e2cda858467b080b0b610f6d285e3631568ecdc25e1f9f1161f31ef",
        "warmup_time": -1
    },
    "timeseries.DatetimeAccessor.time_dt_accessor_date": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor_date(self, tz):\n        self.series.dt.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))",
        "min_run_count": 2,
        "name": "timeseries.DatetimeAccessor.time_dt_accessor_date",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "021d8e2410da291a6ddb4c986c398ec7a1aaf57698cdbc2991383c1355ae220a",
        "warmup_time": -1
    },
    "timeseries.DatetimeAccessor.time_dt_accessor_day_name": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor_day_name(self, tz):\n        self.series.dt.day_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))",
        "min_run_count": 2,
        "name": "timeseries.DatetimeAccessor.time_dt_accessor_day_name",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0f5f97dd470f31efc26c498329b7f4601d6f799e98aebbe018ec372da49ff2f4",
        "warmup_time": -1
    },
    "timeseries.DatetimeAccessor.time_dt_accessor_month_name": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor_month_name(self, tz):\n        self.series.dt.month_name()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))",
        "min_run_count": 2,
        "name": "timeseries.DatetimeAccessor.time_dt_accessor_month_name",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a4c4b7dfb99541ee2947bfb3ace2049b3da113f054a4ff987286af80dc59fe9a",
        "warmup_time": -1
    },
    "timeseries.DatetimeAccessor.time_dt_accessor_normalize": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor_normalize(self, tz):\n        self.series.dt.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))",
        "min_run_count": 2,
        "name": "timeseries.DatetimeAccessor.time_dt_accessor_normalize",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ddee7a0133857e8e1e729ffad6e564f65ff9384c97556f810d8ec03339aaf569",
        "warmup_time": -1
    },
    "timeseries.DatetimeAccessor.time_dt_accessor_time": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor_time(self, tz):\n        self.series.dt.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))",
        "min_run_count": 2,
        "name": "timeseries.DatetimeAccessor.time_dt_accessor_time",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "115f61c5815f17b447493bbedc760db0e3ea862c2744122a5a3c92da010a1c42",
        "warmup_time": -1
    },
    "timeseries.DatetimeAccessor.time_dt_accessor_year": {
        "code": "class DatetimeAccessor:\n    def time_dt_accessor_year(self, tz):\n        self.series.dt.year\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeAccessor:\n    def setup(self, tz):\n        N = 100000\n        self.series = Series(date_range(start=\"1/1/2000\", periods=N, freq=\"T\", tz=tz))",
        "min_run_count": 2,
        "name": "timeseries.DatetimeAccessor.time_dt_accessor_year",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e7bb661cf32509918fc15c5b1e271eb8fe3eda146c2c9eb620f79e77d91127cd",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_add_timedelta": {
        "code": "class DatetimeIndex:\n    def time_add_timedelta(self, index_type):\n        self.index + timedelta(minutes=2)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_add_timedelta",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c2cc7bb231f62b1af6082eb786e15ab49f3b6a3383124906fb7f51a6f9f3b3f8",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_get": {
        "code": "class DatetimeIndex:\n    def time_get(self, index_type):\n        self.index[0]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_get",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d028d87ac258389493458452a57d6ff0de335941a2f81a7e8fced5b779c82e1f",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_is_dates_only": {
        "code": "class DatetimeIndex:\n    def time_is_dates_only(self, index_type):\n        self.index._is_dates_only\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_is_dates_only",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4264adc13db2d02dd5bd0c8c6648da44ec1c6a10f4e585bf9d71e6fc9805d1fb",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_normalize": {
        "code": "class DatetimeIndex:\n    def time_normalize(self, index_type):\n        self.index.normalize()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_normalize",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ba785e6016a90bf14d5bcc2e673f72889453cb6980b898364941febe2a69cec3",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_timeseries_is_month_start": {
        "code": "class DatetimeIndex:\n    def time_timeseries_is_month_start(self, index_type):\n        self.index.is_month_start\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_timeseries_is_month_start",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b20aef0d8246571897ac2e0e2e624272f493457afb96781e33da7ed766e2e996",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_to_date": {
        "code": "class DatetimeIndex:\n    def time_to_date(self, index_type):\n        self.index.date\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_to_date",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1ba2f305f5a3ae0f0458f5a33f937418f80a851bac7e9923999b3aeb8c00174d",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_to_pydatetime": {
        "code": "class DatetimeIndex:\n    def time_to_pydatetime(self, index_type):\n        self.index.to_pydatetime()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_to_pydatetime",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d62c041b2c720442d04ce8c5c6f855c4cd181f4bd098c0b90d587105a355a9d7",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_to_time": {
        "code": "class DatetimeIndex:\n    def time_to_time(self, index_type):\n        self.index.time\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_to_time",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2bf107f2a7faf94da14c2de8548f07d139c53d011f564729cff6ba2b64f2dd93",
        "warmup_time": -1
    },
    "timeseries.DatetimeIndex.time_unique": {
        "code": "class DatetimeIndex:\n    def time_unique(self, index_type):\n        self.index.unique()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass DatetimeIndex:\n    def setup(self, index_type):\n        N = 100000\n        dtidxes = {\n            \"dst\": date_range(\n                start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n            ),\n            \"repeated\": date_range(start=\"2000\", periods=N / 10, freq=\"s\").repeat(10),\n            \"tz_aware\": date_range(start=\"2000\", periods=N, freq=\"s\", tz=\"US/Eastern\"),\n            \"tz_local\": date_range(\n                start=\"2000\", periods=N, freq=\"s\", tz=dateutil.tz.tzlocal()\n            ),\n            \"tz_naive\": date_range(start=\"2000\", periods=N, freq=\"s\"),\n        }\n        self.index = dtidxes[index_type]",
        "min_run_count": 2,
        "name": "timeseries.DatetimeIndex.time_unique",
        "number": 0,
        "param_names": [
            "index_type"
        ],
        "params": [
            [
                "'dst'",
                "'repeated'",
                "'tz_aware'",
                "'tz_local'",
                "'tz_naive'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9f2f012235902e7df7a11bc6e21c6114209a9f94166ca322aae16d855884b425",
        "warmup_time": -1
    },
    "timeseries.InferFreq.time_infer_freq": {
        "code": "class InferFreq:\n    def time_infer_freq(self, freq):\n        infer_freq(self.idx)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass InferFreq:\n    def setup(self, freq):\n        if freq is None:\n            self.idx = date_range(start=\"1/1/1700\", freq=\"D\", periods=10000)\n            self.idx._data._freq = None\n        else:\n            self.idx = date_range(start=\"1/1/1700\", freq=freq, periods=10000)",
        "min_run_count": 2,
        "name": "timeseries.InferFreq.time_infer_freq",
        "number": 0,
        "param_names": [
            "freq"
        ],
        "params": [
            [
                "None",
                "'D'",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "52f02044de50a1a68041e7526ab41b12d85500472c7652ce485fa54cfe87ecc0",
        "warmup_time": -1
    },
    "timeseries.Iteration.time_iter": {
        "code": "class Iteration:\n    def time_iter(self, time_index):\n        for _ in self.idx:\n            pass\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10 ** 6\n        if time_index is timedelta_range:\n            self.idx = time_index(start=0, freq=\"T\", periods=N)\n        else:\n            self.idx = time_index(start=\"20140101\", freq=\"T\", periods=N)\n        self.exit = 10000",
        "min_run_count": 2,
        "name": "timeseries.Iteration.time_iter",
        "number": 0,
        "param_names": [
            "time_index"
        ],
        "params": [
            [
                "<function date_range>",
                "<function period_range>",
                "<function timedelta_range>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f6832aec9561964bb7f5328198eb9c426c10d048f732cb9f8150b2b008f032a0",
        "warmup_time": -1
    },
    "timeseries.Iteration.time_iter_preexit": {
        "code": "class Iteration:\n    def time_iter_preexit(self, time_index):\n        for i, _ in enumerate(self.idx):\n            if i > self.exit:\n                break\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Iteration:\n    def setup(self, time_index):\n        N = 10 ** 6\n        if time_index is timedelta_range:\n            self.idx = time_index(start=0, freq=\"T\", periods=N)\n        else:\n            self.idx = time_index(start=\"20140101\", freq=\"T\", periods=N)\n        self.exit = 10000",
        "min_run_count": 2,
        "name": "timeseries.Iteration.time_iter_preexit",
        "number": 0,
        "param_names": [
            "time_index"
        ],
        "params": [
            [
                "<function date_range>",
                "<function period_range>",
                "<function timedelta_range>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1b8b2b84a8d671bb6f47d7b68d00319b2db5148acce3053ee38d63dc764a9320",
        "warmup_time": -1
    },
    "timeseries.Lookup.time_lookup_and_cleanup": {
        "code": "class Lookup:\n    def time_lookup_and_cleanup(self):\n        self.ts[self.lookup_val]\n        self.ts.index._cleanup()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass Lookup:\n    def setup(self):\n        N = 1500000\n        rng = date_range(start=\"1/1/2000\", periods=N, freq=\"S\")\n        self.ts = Series(1, index=rng)\n        self.lookup_val = rng[N // 2]",
        "min_run_count": 2,
        "name": "timeseries.Lookup.time_lookup_and_cleanup",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4b60327696855c221b7a2493d4f99390b0834ebd26bcb40c0e4c4464486e0962",
        "warmup_time": -1
    },
    "timeseries.ResampleDataFrame.time_method": {
        "code": "class ResampleDataFrame:\n    def time_method(self, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDataFrame:\n    def setup(self, method):\n        rng = date_range(start=\"20130101\", periods=100000, freq=\"50L\")\n        df = DataFrame(np.random.randn(100000, 2), index=rng)\n        self.resample = getattr(df.resample(\"1s\"), method)",
        "min_run_count": 2,
        "name": "timeseries.ResampleDataFrame.time_method",
        "number": 0,
        "param_names": [
            "method"
        ],
        "params": [
            [
                "'max'",
                "'mean'",
                "'min'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b77feaa009ecc95f6bce04575055d274a9030f79685fe8ee8be8a935f84314ad",
        "warmup_time": -1
    },
    "timeseries.ResampleDatetetime64.time_resample": {
        "code": "class ResampleDatetetime64:\n    def time_resample(self):\n        self.dt_ts.resample(\"1S\").last()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleDatetetime64:\n    def setup(self):\n        rng3 = date_range(\n            start=\"2000-01-01 00:00:00\", end=\"2000-01-01 10:00:00\", freq=\"555000U\"\n        )\n        self.dt_ts = Series(5, rng3, dtype=\"datetime64[ns]\")",
        "min_run_count": 2,
        "name": "timeseries.ResampleDatetetime64.time_resample",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1fdc7e2f0bf233502eef6c6f2e93421664936d5e8e9d77f64bae068f87283caa",
        "warmup_time": -1
    },
    "timeseries.ResampleSeries.time_resample": {
        "code": "class ResampleSeries:\n    def time_resample(self, index, freq, method):\n        self.resample()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResampleSeries:\n    def setup(self, index, freq, method):\n        indexes = {\n            \"period\": period_range(start=\"1/1/2000\", end=\"1/1/2001\", freq=\"T\"),\n            \"datetime\": date_range(start=\"1/1/2000\", end=\"1/1/2001\", freq=\"T\"),\n        }\n        idx = indexes[index]\n        ts = Series(np.random.randn(len(idx)), index=idx)\n        self.resample = getattr(ts.resample(freq), method)",
        "min_run_count": 2,
        "name": "timeseries.ResampleSeries.time_resample",
        "number": 0,
        "param_names": [
            "index",
            "freq",
            "method"
        ],
        "params": [
            [
                "'period'",
                "'datetime'"
            ],
            [
                "'5min'",
                "'1D'"
            ],
            [
                "'mean'",
                "'ohlc'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cee7e74cfbe0838abaa9106ad441f336a5bf93883a4e58bab6e45f9184c501d7",
        "warmup_time": -1
    },
    "timeseries.ResetIndex.time_reset_datetimeindex": {
        "code": "class ResetIndex:\n    def time_reset_datetimeindex(self, tz):\n        self.df.reset_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass ResetIndex:\n    def setup(self, tz):\n        idx = date_range(start=\"1/1/2000\", periods=1000, freq=\"H\", tz=tz)\n        self.df = DataFrame(np.random.randn(1000, 2), index=idx)",
        "min_run_count": 2,
        "name": "timeseries.ResetIndex.time_reset_datetimeindex",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fa0f0e85752334f42a01033826f14cbf4e6872765dd7c16f825e7795eaa5dc2a",
        "warmup_time": -1
    },
    "timeseries.SortIndex.time_get_slice": {
        "code": "class SortIndex:\n    def time_get_slice(self, monotonic):\n        self.s[:10000]\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10 ** 5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)",
        "min_run_count": 2,
        "name": "timeseries.SortIndex.time_get_slice",
        "number": 0,
        "param_names": [
            "monotonic"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1f5a31215b0cc628b041cf63f25b2d7caa972665e40231b2b7ee5d0c3ba93034",
        "warmup_time": -1
    },
    "timeseries.SortIndex.time_sort_index": {
        "code": "class SortIndex:\n    def time_sort_index(self, monotonic):\n        self.s.sort_index()\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass SortIndex:\n    def setup(self, monotonic):\n        N = 10 ** 5\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\n        self.s = Series(np.random.randn(N), index=idx)\n        if not monotonic:\n            self.s = self.s.sample(frac=1)",
        "min_run_count": 2,
        "name": "timeseries.SortIndex.time_sort_index",
        "number": 0,
        "param_names": [
            "monotonic"
        ],
        "params": [
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "99127e1ac350ea6d8bd551fd50069cc912eada651666417fde4971bea5ea42e4",
        "warmup_time": -1
    },
    "timeseries.TimeDatetimeConverter.time_convert": {
        "code": "class TimeDatetimeConverter:\n    def time_convert(self):\n        DatetimeConverter.convert(self.rng, None, None)\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TimeDatetimeConverter:\n    def setup(self):\n        N = 100000\n        self.rng = date_range(start=\"1/1/2000\", periods=N, freq=\"T\")",
        "min_run_count": 2,
        "name": "timeseries.TimeDatetimeConverter.time_convert",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "37f67d4e4336e8d1ab8b3a815f3668ceb3a58cf9c8e254799cbfbed406fa949b",
        "warmup_time": -1
    },
    "timeseries.TzLocalize.time_infer_dst": {
        "code": "class TzLocalize:\n    def time_infer_dst(self, tz):\n        self.index.tz_localize(tz, ambiguous=\"infer\")\n\ndef setup(*args, **kwargs):\n    # This function just needs to be imported into each benchmark file to\n    # set up the random seed before each function.\n    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\n    np.random.seed(1234)\n\nclass TzLocalize:\n    def setup(self, tz):\n        dst_rng = date_range(\n            start=\"10/29/2000 1:00:00\", end=\"10/29/2000 1:59:59\", freq=\"S\"\n        )\n        self.index = date_range(start=\"10/29/2000\", end=\"10/29/2000 00:59:59\", freq=\"S\")\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(dst_rng)\n        self.index = self.index.append(\n            date_range(start=\"10/29/2000 2:00:00\", end=\"10/29/2000 3:00:00\", freq=\"S\")\n        )",
        "min_run_count": 2,
        "name": "timeseries.TzLocalize.time_infer_dst",
        "number": 0,
        "param_names": [
            "t"
        ],
        "params": [
            [
                "None",
                "'US/Eastern'",
                "'UTC'",
                "tzutc()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "867213627bf09b3b2955467bed535d2d2166e059579f56ac7797e6d62ebcd49e",
        "warmup_time": -1
    },
    "tslibs.fields.TimeGetDateField.time_get_date_field": {
        "code": "class TimeGetDateField:\n    def time_get_date_field(self, size, field):\n        get_date_field(self.i8data, field)\n\n    def setup(self, size, field):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr",
        "min_run_count": 2,
        "name": "tslibs.fields.TimeGetDateField.time_get_date_field",
        "number": 0,
        "param_names": [
            "size",
            "field"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "'Y'",
                "'M'",
                "'D'",
                "'h'",
                "'m'",
                "'s'",
                "'us'",
                "'ns'",
                "'doy'",
                "'dow'",
                "'woy'",
                "'q'",
                "'dim'",
                "'is_leap_year'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "032d05ffd3cddf25687d384f76ac9d5aeacf2e7476a8aeb4baf025aa07fc3887",
        "warmup_time": -1
    },
    "tslibs.fields.TimeGetStartEndField.time_get_start_end_field": {
        "code": "class TimeGetStartEndField:\n    def time_get_start_end_field(self, size, side, period, freqstr, month_kw):\n        get_start_end_field(self.i8data, self.attrname, freqstr, month_kw=month_kw)\n\n    def setup(self, size, side, period, freqstr, month_kw):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr\n    \n        self.attrname = f\"is_{period}_{side}\"",
        "min_run_count": 2,
        "name": "tslibs.fields.TimeGetStartEndField.time_get_start_end_field",
        "number": 0,
        "param_names": [
            "size",
            "side",
            "period",
            "freqstr",
            "month_kw"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "'start'",
                "'end'"
            ],
            [
                "'month'",
                "'quarter'",
                "'year'"
            ],
            [
                "'B'",
                "None",
                "'QS'"
            ],
            [
                "12",
                "3",
                "5"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3457501ae50d04017ceec6b67dce5e99aa99af7ededd796eddbd0c87b01b8d9a",
        "warmup_time": -1
    },
    "tslibs.fields.TimeGetTimedeltaField.time_get_timedelta_field": {
        "code": "class TimeGetTimedeltaField:\n    def time_get_timedelta_field(self, size, field):\n        get_timedelta_field(self.i8data, field)\n\n    def setup(self, size, field):\n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr",
        "min_run_count": 2,
        "name": "tslibs.fields.TimeGetTimedeltaField.time_get_timedelta_field",
        "number": 0,
        "param_names": [
            "size",
            "field"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "'days'",
                "'seconds'",
                "'microseconds'",
                "'nanoseconds'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "83971f7c0e7b0651fbe80cda16bb176f840b200191f86e1207d2de1d30d4a4de",
        "warmup_time": -1
    },
    "tslibs.normalize.Normalize.time_is_date_array_normalized": {
        "code": "class Normalize:\n    def time_is_date_array_normalized(self, size, tz):\n        # TODO: cases with different levels of short-circuiting\n        is_date_array_normalized(self.i8data, tz)\n\n    def setup(self, size, tz):\n        # use an array that will have is_date_array_normalized give True,\n        #  so we do not short-circuit early.\n        dti = pd.date_range(\"2016-01-01\", periods=10, tz=tz).repeat(size // 10)\n        self.i8data = dti.asi8\n    \n        if size == 10 ** 6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "tslibs.normalize.Normalize.time_is_date_array_normalized",
        "number": 0,
        "param_names": [
            "size",
            "tz"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0574d4bba496d093ea911abe134c77dc749228645efad20841134647df99590e",
        "warmup_time": -1
    },
    "tslibs.normalize.Normalize.time_normalize_i8_timestamps": {
        "code": "class Normalize:\n    def time_normalize_i8_timestamps(self, size, tz):\n        normalize_i8_timestamps(self.i8data, tz)\n\n    def setup(self, size, tz):\n        # use an array that will have is_date_array_normalized give True,\n        #  so we do not short-circuit early.\n        dti = pd.date_range(\"2016-01-01\", periods=10, tz=tz).repeat(size // 10)\n        self.i8data = dti.asi8\n    \n        if size == 10 ** 6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError",
        "min_run_count": 2,
        "name": "tslibs.normalize.Normalize.time_normalize_i8_timestamps",
        "number": 0,
        "param_names": [
            "size",
            "tz"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "24a877916406fe27b3a0926d3a41725c56d362d483f82e628515f7acbffdfc68",
        "warmup_time": -1
    },
    "tslibs.offsets.OffestDatetimeArithmetic.time_add": {
        "code": "class OffestDatetimeArithmetic:\n    def time_add(self, offset):\n        self.date + offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")",
        "min_run_count": 2,
        "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bfb2ef7f8d94ebf443a43ab768a426b24846a01bcb9e60873cfca5ac9d84acbb",
        "warmup_time": -1
    },
    "tslibs.offsets.OffestDatetimeArithmetic.time_add_10": {
        "code": "class OffestDatetimeArithmetic:\n    def time_add_10(self, offset):\n        self.date + (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")",
        "min_run_count": 2,
        "name": "tslibs.offsets.OffestDatetimeArithmetic.time_add_10",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "412f51bfc037b5b10f23387d475123e2c8ebd62a69e6a5692a07f7924f5149ac",
        "warmup_time": -1
    },
    "tslibs.offsets.OffestDatetimeArithmetic.time_apply": {
        "code": "class OffestDatetimeArithmetic:\n    def time_apply(self, offset):\n        offset.apply(self.date)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")",
        "min_run_count": 2,
        "name": "tslibs.offsets.OffestDatetimeArithmetic.time_apply",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "af692257767a29f497ae7d9cc6c0be4b43945e05f84879665f39032250403461",
        "warmup_time": -1
    },
    "tslibs.offsets.OffestDatetimeArithmetic.time_apply_np_dt64": {
        "code": "class OffestDatetimeArithmetic:\n    def time_apply_np_dt64(self, offset):\n        offset.apply(self.dt64)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")",
        "min_run_count": 2,
        "name": "tslibs.offsets.OffestDatetimeArithmetic.time_apply_np_dt64",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f194bced40cf0d9aa4959b756652f9c4823ddca885b6bcb420be8afa14e70afa",
        "warmup_time": -1
    },
    "tslibs.offsets.OffestDatetimeArithmetic.time_subtract": {
        "code": "class OffestDatetimeArithmetic:\n    def time_subtract(self, offset):\n        self.date - offset\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")",
        "min_run_count": 2,
        "name": "tslibs.offsets.OffestDatetimeArithmetic.time_subtract",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "775bbe2574e947fdebb23ba6451a8510d68d5dfaf0e0813a6967a39209d770fc",
        "warmup_time": -1
    },
    "tslibs.offsets.OffestDatetimeArithmetic.time_subtract_10": {
        "code": "class OffestDatetimeArithmetic:\n    def time_subtract_10(self, offset):\n        self.date - (10 * offset)\n\n    def setup(self, offset):\n        self.date = datetime(2011, 1, 1)\n        self.dt64 = np.datetime64(\"2011-01-01 09:00Z\")",
        "min_run_count": 2,
        "name": "tslibs.offsets.OffestDatetimeArithmetic.time_subtract_10",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f0a5bf6590a5f4e89c95b4b22ecc27ec52e4cb03e8255cef5009879bb71dbc69",
        "warmup_time": -1
    },
    "tslibs.offsets.OnOffset.time_on_offset": {
        "code": "class OnOffset:\n    def time_on_offset(self, offset):\n        for date in self.dates:\n            offset.is_on_offset(date)\n\n    def setup(self, offset):\n        self.dates = [\n            datetime(2016, m, d)\n            for m in [10, 11, 12]\n            for d in [1, 2, 3, 28, 29, 30, 31]\n            if not (m == 11 and d == 31)\n        ]",
        "min_run_count": 2,
        "name": "tslibs.offsets.OnOffset.time_on_offset",
        "number": 0,
        "param_names": [
            "offset"
        ],
        "params": [
            [
                "<Day>",
                "<BYearEnd: month=12>",
                "<BYearBegin: month=1>",
                "<BusinessQuarterEnd: startingMonth=3>",
                "<BusinessQuarterBegin: startingMonth=3>",
                "<BusinessMonthEnd>",
                "<BusinessMonthBegin>",
                "<CustomBusinessDay> (0)",
                "<CustomBusinessDay> (1)",
                "<CustomBusinessMonthBegin>",
                "<CustomBusinessMonthEnd> (0)",
                "<CustomBusinessMonthEnd> (1)",
                "<YearEnd: month=12>",
                "<YearBegin: month=1>",
                "<QuarterEnd: startingMonth=3>",
                "<QuarterBegin: startingMonth=3>",
                "<MonthEnd>",
                "<MonthBegin>",
                "<DateOffset: days=2, months=2>",
                "<BusinessDay>",
                "<SemiMonthEnd: day_of_month=15>",
                "<SemiMonthBegin: day_of_month=15>"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ae5cbac53a07afd70222f6a228bac6518d5df75e369f5e8450db66831ba8afa2",
        "warmup_time": -1
    },
    "tslibs.period.PeriodConstructor.time_period_constructor": {
        "code": "class PeriodConstructor:\n    def time_period_constructor(self, freq, is_offset):\n        Period(\"2012-06-01\", freq=freq)\n\n    def setup(self, freq, is_offset):\n        if is_offset:\n            self.freq = to_offset(freq)\n        else:\n            self.freq = freq",
        "min_run_count": 2,
        "name": "tslibs.period.PeriodConstructor.time_period_constructor",
        "number": 0,
        "param_names": [
            "freq",
            "is_offset"
        ],
        "params": [
            [
                "'D'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d98fc24ec3bee7645af5de9f3e7af5e28f028c74e4785bda4ceb36f1d46a671d",
        "warmup_time": -1
    },
    "tslibs.period.PeriodProperties.time_property": {
        "code": "class PeriodProperties:\n    def time_property(self, freq, attr):\n        getattr(self.per, attr)\n\n    def setup(self, freq, attr):\n        self.per = Period(\"2012-06-01\", freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.period.PeriodProperties.time_property",
        "number": 0,
        "param_names": [
            "freq",
            "attr"
        ],
        "params": [
            [
                "'M'",
                "'min'"
            ],
            [
                "'year'",
                "'month'",
                "'day'",
                "'hour'",
                "'minute'",
                "'second'",
                "'is_leap_year'",
                "'quarter'",
                "'qyear'",
                "'week'",
                "'daysinmonth'",
                "'dayofweek'",
                "'dayofyear'",
                "'start_time'",
                "'end_time'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6c0fa44f9b9f197537446c79ae6f7ce95ab1d18e2e68b5acb2a96103c097f4c6",
        "warmup_time": -1
    },
    "tslibs.period.PeriodUnaryMethods.time_asfreq": {
        "code": "class PeriodUnaryMethods:\n    def time_asfreq(self, freq):\n        self.per.asfreq(\"A\")\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.period.PeriodUnaryMethods.time_asfreq",
        "number": 0,
        "param_names": [
            "freq"
        ],
        "params": [
            [
                "'M'",
                "'min'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "deedbf5d3c7fd1ba4050791ac771023591ce7ddf98c14082e8627b2b2646cfeb",
        "warmup_time": -1
    },
    "tslibs.period.PeriodUnaryMethods.time_now": {
        "code": "class PeriodUnaryMethods:\n    def time_now(self, freq):\n        self.per.now(freq)\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.period.PeriodUnaryMethods.time_now",
        "number": 0,
        "param_names": [
            "freq"
        ],
        "params": [
            [
                "'M'",
                "'min'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b3c4792b946da369832c7ae6904edf46919fdca2bf03ad4006e36d728c2816bb",
        "warmup_time": -1
    },
    "tslibs.period.PeriodUnaryMethods.time_to_timestamp": {
        "code": "class PeriodUnaryMethods:\n    def time_to_timestamp(self, freq):\n        self.per.to_timestamp()\n\n    def setup(self, freq):\n        self.per = Period(\"2012-06-01\", freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.period.PeriodUnaryMethods.time_to_timestamp",
        "number": 0,
        "param_names": [
            "freq"
        ],
        "params": [
            [
                "'M'",
                "'min'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "27afe42121b54cb80919887f7d10be0869044b9c877bf53c7bfcd1f5f622e713",
        "warmup_time": -1
    },
    "tslibs.period.TimeDT64ArrToPeriodArr.time_dt64arr_to_periodarr": {
        "code": "class TimeDT64ArrToPeriodArr:\n    def time_dt64arr_to_periodarr(self, size, freq, tz):\n        dt64arr_to_periodarr(self.i8values, freq, tz)\n\n    def setup(self, size, freq, tz):\n        if size == 10 ** 6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.arange(10, dtype=\"i8\").repeat(size // 10)\n        self.i8values = arr",
        "min_run_count": 2,
        "name": "tslibs.period.TimeDT64ArrToPeriodArr.time_dt64arr_to_periodarr",
        "number": 0,
        "param_names": [
            "size",
            "freq",
            "tz"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "1000",
                "1011",
                "2000",
                "2011",
                "3000",
                "4000",
                "4006",
                "5000",
                "6000",
                "7000",
                "8000",
                "9000",
                "10000",
                "11000",
                "12000"
            ],
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cff18acb6b3f2606a3c012c8639d739f918cbff06e1157b2abb203345c2f1da5",
        "warmup_time": -1
    },
    "tslibs.period.TimePeriodArrToDT64Arr.time_periodarray_to_dt64arr": {
        "code": "class TimePeriodArrToDT64Arr:\n    def time_periodarray_to_dt64arr(self, size, freq):\n        periodarr_to_dt64arr(self.i8values, freq)\n\n    def setup(self, size, freq):\n        arr = np.arange(10, dtype=\"i8\").repeat(size // 10)\n        self.i8values = arr",
        "min_run_count": 2,
        "name": "tslibs.period.TimePeriodArrToDT64Arr.time_periodarray_to_dt64arr",
        "number": 0,
        "param_names": [
            "size",
            "freq"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "1000",
                "1011",
                "2000",
                "2011",
                "3000",
                "4000",
                "4006",
                "5000",
                "6000",
                "7000",
                "8000",
                "9000",
                "10000",
                "11000",
                "12000"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "780a003a3675ffce34b1163502be5f0eb10d3e9c8e10d3a8f2ce56387e643da2",
        "warmup_time": -1
    },
    "tslibs.resolution.TimeResolution.time_get_resolution": {
        "code": "class TimeResolution:\n    def time_get_resolution(self, unit, size, tz):\n        get_resolution(self.i8data, tz)\n\n    def setup(self, unit, size, tz):\n        if size == 10 ** 6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        arr = arr.view(f\"M8[{unit}]\").astype(\"M8[ns]\").view(\"i8\")\n        self.i8data = arr",
        "min_run_count": 2,
        "name": "tslibs.resolution.TimeResolution.time_get_resolution",
        "number": 0,
        "param_names": [
            "unit",
            "size",
            "tz"
        ],
        "params": [
            [
                "'D'",
                "'h'",
                "'m'",
                "'s'",
                "'us'",
                "'ns'"
            ],
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3feb5e4e6010c6d5e0c18dff8248a03672c54a9e2af9ae454176f00258343cc0",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_components": {
        "code": "class TimedeltaConstructor:\n    def time_from_components(self):\n        Timedelta(\n            days=1,\n            hours=2,\n            minutes=3,\n            seconds=4,\n            milliseconds=5,\n            microseconds=6,\n            nanoseconds=7,\n        )\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_components",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "976de79734124e410aadd9f6fdb589658515fb75c3456c6c5003df04e31495c8",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_datetime_timedelta": {
        "code": "class TimedeltaConstructor:\n    def time_from_datetime_timedelta(self):\n        Timedelta(self.dttimedelta)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_datetime_timedelta",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3326b70bfe99c2a6a044540b5db8b882ec1b999993fff273029767c5717f11db",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_int": {
        "code": "class TimedeltaConstructor:\n    def time_from_int(self):\n        Timedelta(123456789)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_int",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ebc3b0e00ba7cba6a0d3e95134a6f1c56543605b5c4f0337fd76a0b846078e4d",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_iso_format": {
        "code": "class TimedeltaConstructor:\n    def time_from_iso_format(self):\n        Timedelta(\"P4DT12H30M5S\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_iso_format",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a16446c3495768b14e84c7b2e947bdfbb1fb7558e73cd969d79d2fddd94f4961",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_missing": {
        "code": "class TimedeltaConstructor:\n    def time_from_missing(self):\n        Timedelta(\"nat\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_missing",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ee87e86713ff7adca408473446c87ca651516e45b5a7c43b9142fead580aad84",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_np_timedelta": {
        "code": "class TimedeltaConstructor:\n    def time_from_np_timedelta(self):\n        Timedelta(self.nptimedelta64)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_np_timedelta",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a8fe79df54c66d13d34089a76ce37bd86f35e6da129e6de26dd0235934789c8c",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_pd_timedelta": {
        "code": "class TimedeltaConstructor:\n    def time_from_pd_timedelta(self):\n        Timedelta(self.td)\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_pd_timedelta",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "831bac3969b78367fedc8c945ad8667ac98baab3994380c2c72b8a30c1516c50",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_string": {
        "code": "class TimedeltaConstructor:\n    def time_from_string(self):\n        Timedelta(\"1 days\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_string",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8da4af162b193652f720feee641b52568c67cc80c2eef6d146965283fb04bc8d",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaConstructor.time_from_unit": {
        "code": "class TimedeltaConstructor:\n    def time_from_unit(self):\n        Timedelta(1, unit=\"d\")\n\n    def setup(self):\n        self.nptimedelta64 = np.timedelta64(3600)\n        self.dttimedelta = datetime.timedelta(seconds=3600)\n        self.td = Timedelta(3600, unit=\"s\")",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaConstructor.time_from_unit",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3ca91b1679620f3ab96408d006de6a0f62611d7e87e32ad104ff37e9f2538c2d",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaProperties.time_timedelta_days": {
        "code": "class TimedeltaProperties:\n    def time_timedelta_days(self, td):\n        td.days\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_days",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "tslibs.timedelta:55",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "027721dc928a0aac947e4eb804535d4414cc57804449f21a50097455e1eb34cc",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaProperties.time_timedelta_microseconds": {
        "code": "class TimedeltaProperties:\n    def time_timedelta_microseconds(self, td):\n        td.microseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_microseconds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "tslibs.timedelta:55",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1c88f64d84fd4aa67383bda6396ed221e9b5a7fb816a7ff3ab0788a108b0c6c8",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaProperties.time_timedelta_nanoseconds": {
        "code": "class TimedeltaProperties:\n    def time_timedelta_nanoseconds(self, td):\n        td.nanoseconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_nanoseconds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "tslibs.timedelta:55",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "458eb6a15687e81995044a9cf3b9938fdf6724c379b347d74c6fcb101204008b",
        "warmup_time": -1
    },
    "tslibs.timedelta.TimedeltaProperties.time_timedelta_seconds": {
        "code": "class TimedeltaProperties:\n    def time_timedelta_seconds(self, td):\n        td.seconds\n\n    def setup_cache(self):\n        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\n        return td",
        "min_run_count": 2,
        "name": "tslibs.timedelta.TimedeltaProperties.time_timedelta_seconds",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "tslibs.timedelta:55",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "16d230d4bbe759fe887153a89399d0eb5eebbf999155cbe9ec2fdfef09305b0c",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampAcrossDst.time_replace_across_dst": {
        "code": "class TimestampAcrossDst:\n    def time_replace_across_dst(self):\n        self.ts2.replace(tzinfo=self.tzinfo)\n\n    def setup(self):\n        dt = datetime(2016, 3, 27, 1)\n        self.tzinfo = pytz.timezone(\"CET\").localize(dt, is_dst=False).tzinfo\n        self.ts2 = Timestamp(dt)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampAcrossDst.time_replace_across_dst",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4eeaaed494bd6b769b9c4efa262f1f90020591c46849984ea9edfa1d194b3a93",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_from_datetime_aware": {
        "code": "class TimestampConstruction:\n    def time_from_datetime_aware(self):\n        Timestamp(self.dttime_aware)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_from_datetime_aware",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f14b2ba4c97e828628dc7b144124678a24812e53ec495a6f6f7f035d7e76716c",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_from_datetime_unaware": {
        "code": "class TimestampConstruction:\n    def time_from_datetime_unaware(self):\n        Timestamp(self.dttime_unaware)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_from_datetime_unaware",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "deda24fb69c398141fba8624b556966cc947474462ca0932939fad017e750985",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_from_npdatetime64": {
        "code": "class TimestampConstruction:\n    def time_from_npdatetime64(self):\n        Timestamp(self.npdatetime64)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_from_npdatetime64",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e8deeb3f6693261772dcbea71d4d1e8cf5dc268d0ed889ebc2bd1159359fb79b",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_from_pd_timestamp": {
        "code": "class TimestampConstruction:\n    def time_from_pd_timestamp(self):\n        Timestamp(self.ts)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_from_pd_timestamp",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "aa508132de1d66508c66cf0477a1ef90bb0d697088197dbff1e6c1cf83db1d9b",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_fromordinal": {
        "code": "class TimestampConstruction:\n    def time_fromordinal(self):\n        Timestamp.fromordinal(730120)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_fromordinal",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0d2c91d7caeb1e9f18e97e3b3e49b40506419ccf6a747aba57cec220392b56a6",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_fromtimestamp": {
        "code": "class TimestampConstruction:\n    def time_fromtimestamp(self):\n        Timestamp.fromtimestamp(1515448538)\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_fromtimestamp",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "93f47b86a2ac5472723d056641e6cfea7e3fe451f6a8f80aaaa33d9639ffbcd6",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_parse_dateutil": {
        "code": "class TimestampConstruction:\n    def time_parse_dateutil(self):\n        Timestamp(\"2017/08/25 08:16:14 AM\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_parse_dateutil",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c0309203dabb15ebb9716def5049f52ea3e32116f035e7f28935eecb6eac953e",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_no_tz": {
        "code": "class TimestampConstruction:\n    def time_parse_iso8601_no_tz(self):\n        Timestamp(\"2017-08-25 08:16:14\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_no_tz",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "edb87028a17ef2fe442cb82487dbdad5fc4264ab0c37256a5f0f9940a89ec02f",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_tz": {
        "code": "class TimestampConstruction:\n    def time_parse_iso8601_tz(self):\n        Timestamp(\"2017-08-25 08:16:14-0500\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_parse_iso8601_tz",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "48fd2b6c0dfc61e556481168eb66875e3bdcabca2d9e2c6d79908f3b16e7a15d",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_parse_now": {
        "code": "class TimestampConstruction:\n    def time_parse_now(self):\n        Timestamp(\"now\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_parse_now",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4ae560aa20eee0beb52506ca024df933003e399825874b0aa280771feaef7ab9",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampConstruction.time_parse_today": {
        "code": "class TimestampConstruction:\n    def time_parse_today(self):\n        Timestamp(\"today\")\n\n    def setup(self):\n        self.npdatetime64 = np.datetime64(\"2020-01-01 00:00:00\")\n        self.dttime_unaware = datetime(2020, 1, 1, 0, 0, 0)\n        self.dttime_aware = datetime(2020, 1, 1, 0, 0, 0, 0, pytz.UTC)\n        self.ts = Timestamp(\"2020-01-01 00:00:00\")",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampConstruction.time_parse_today",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "92ca8839a0be3afb03e222c0647cc70fb3ed56ce204455637cfde1baeea43845",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_ceil": {
        "code": "class TimestampOps:\n    def time_ceil(self, tz):\n        self.ts.ceil(\"5T\")\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_ceil",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1428582cbad6d3d555950451594e390024aad454751ca9d18540ddf7f7548c4a",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_floor": {
        "code": "class TimestampOps:\n    def time_floor(self, tz):\n        self.ts.floor(\"5T\")\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_floor",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "29681cac2448139b28d8817e024d6d3c08bcd7fe4594fb26564ed03e81c94f31",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_normalize": {
        "code": "class TimestampOps:\n    def time_normalize(self, tz):\n        self.ts.normalize()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_normalize",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f7688ade61af780f34bdb840481260073c8bfb88a7504a06758c91f033fb951d",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_replace_None": {
        "code": "class TimestampOps:\n    def time_replace_None(self, tz):\n        self.ts.replace(tzinfo=None)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_replace_None",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "395164d585e187bf1f2ecd1f965a26fe6f63a204fb26eb6daf8c2544e7895f5f",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_replace_tz": {
        "code": "class TimestampOps:\n    def time_replace_tz(self, tz):\n        self.ts.replace(tzinfo=pytz.timezone(\"US/Eastern\"))\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_replace_tz",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4364c2bc5207c0340c1149b8fb230b76c97f7646891613c57bd11cf528e78d77",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_to_julian_date": {
        "code": "class TimestampOps:\n    def time_to_julian_date(self, tz):\n        self.ts.to_julian_date()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_to_julian_date",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b986ab53361d72e7f0d0ea59b3584f48d6d6fc4994e87be9157f503231f22e70",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_to_pydatetime": {
        "code": "class TimestampOps:\n    def time_to_pydatetime(self, tz):\n        self.ts.to_pydatetime()\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_to_pydatetime",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1db879395196c84d3fd8f358a23b86aaef86f45475d0f83716f8a546e489a627",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_tz_convert": {
        "code": "class TimestampOps:\n    def time_tz_convert(self, tz):\n        if self.ts.tz is not None:\n            self.ts.tz_convert(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_tz_convert",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "43ec3d5f390c7c62a00c06c942395078df2cc729fd8f92a4b0276815f342896d",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampOps.time_tz_localize": {
        "code": "class TimestampOps:\n    def time_tz_localize(self, tz):\n        if self.ts.tz is None:\n            self.ts.tz_localize(tz)\n\n    def setup(self, tz):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tz=tz)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampOps.time_tz_localize",
        "number": 0,
        "param_names": [
            "tz"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0ed9c18cc2666c8a010ac46b26f73181d886d5bad76c5a2e012111741777d94c",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_dayofweek": {
        "code": "class TimestampProperties:\n    def time_dayofweek(self, tz, freq):\n        self.ts.dayofweek\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_dayofweek",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c6daadf9626b1beb421ea24564aa6c857f50b32c4bfdf865a679ff78c075a09c",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_dayofyear": {
        "code": "class TimestampProperties:\n    def time_dayofyear(self, tz, freq):\n        self.ts.dayofyear\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_dayofyear",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1970996700077d3916288f2ebfa66314fd0fa16faa65d298f43d1c452b376c1f",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_days_in_month": {
        "code": "class TimestampProperties:\n    def time_days_in_month(self, tz, freq):\n        self.ts.days_in_month\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_days_in_month",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f1ec12e96719dcfd857c4d2520d3c197e9c5e623eb69bd481bba8d50a3b56c7c",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_freqstr": {
        "code": "class TimestampProperties:\n    def time_freqstr(self, tz, freq):\n        self.ts.freqstr\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_freqstr",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8b7c86fb415025ed9782c86ea08bfa95b66d8c30532a8337935b49a716d37c3b",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_is_leap_year": {
        "code": "class TimestampProperties:\n    def time_is_leap_year(self, tz, freq):\n        self.ts.is_leap_year\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_is_leap_year",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7a94f193c44fde8fc63549fc4515913a4284f65aa3b2cf68e4b099f5e68ecb58",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_is_month_end": {
        "code": "class TimestampProperties:\n    def time_is_month_end(self, tz, freq):\n        self.ts.is_month_end\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_is_month_end",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b5b47e2086d98cadc559128155943e2868f7af254659e927f11302852497f3b8",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_is_month_start": {
        "code": "class TimestampProperties:\n    def time_is_month_start(self, tz, freq):\n        self.ts.is_month_start\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_is_month_start",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9096eeefe2b95da5c24266d715fa7c18a2d5a1ef9e09b034e1231cd6e8295d70",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_is_quarter_end": {
        "code": "class TimestampProperties:\n    def time_is_quarter_end(self, tz, freq):\n        self.ts.is_quarter_end\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_is_quarter_end",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "82a65562c4cca8e68b3c7f8be34145a2bc1d71a34c4544e528038b5808d6a0c1",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_is_quarter_start": {
        "code": "class TimestampProperties:\n    def time_is_quarter_start(self, tz, freq):\n        self.ts.is_quarter_start\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_is_quarter_start",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1088250670cc9f98108690c31465e1f62b79e9ecdad8ebd4fd150e098f5930b7",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_is_year_end": {
        "code": "class TimestampProperties:\n    def time_is_year_end(self, tz, freq):\n        self.ts.is_year_end\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_is_year_end",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e78c5d23cc3ed6005c4779c52acfaca34ed16a1f7d9d100cb88cb153d2e8350f",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_is_year_start": {
        "code": "class TimestampProperties:\n    def time_is_year_start(self, tz, freq):\n        self.ts.is_year_start\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_is_year_start",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c29221e715f65d7b7ad3989a0229500ded6c2ca2d804bfc21943e229df8644ef",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_microsecond": {
        "code": "class TimestampProperties:\n    def time_microsecond(self, tz, freq):\n        self.ts.microsecond\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_microsecond",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4f3bd00c49a4eceb4fd4a85cf81ad8cc0f4807dfb7c10e06be9feb1790502eda",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_month_name": {
        "code": "class TimestampProperties:\n    def time_month_name(self, tz, freq):\n        self.ts.month_name()\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_month_name",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2a9cc7b41015b79534db9bdba3b505bbb41874eee513498664e27e4a087424d4",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_quarter": {
        "code": "class TimestampProperties:\n    def time_quarter(self, tz, freq):\n        self.ts.quarter\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_quarter",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "61276b5e2273989bcd7c633cda4e3036d2eee15ac46f9a9ebfc5e306d3657b54",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_tz": {
        "code": "class TimestampProperties:\n    def time_tz(self, tz, freq):\n        self.ts.tz\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_tz",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5fb6e5c5690352c8be03312a08a681e97bd092c6a523c1d55be5617e7b1ecc65",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_week": {
        "code": "class TimestampProperties:\n    def time_week(self, tz, freq):\n        self.ts.week\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_week",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2b1baa43468ce7c41c65ca461aa4df21820e31dbec8ca816b6619fb5f66ba801",
        "warmup_time": -1
    },
    "tslibs.timestamp.TimestampProperties.time_weekday_name": {
        "code": "class TimestampProperties:\n    def time_weekday_name(self, tz, freq):\n        self.ts.day_name()\n\n    def setup(self, tz, freq):\n        self.ts = Timestamp(\"2017-08-25 08:16:14\", tzinfo=tz, freq=freq)",
        "min_run_count": 2,
        "name": "tslibs.timestamp.TimestampProperties.time_weekday_name",
        "number": 0,
        "param_names": [
            "tz",
            "freq"
        ],
        "params": [
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ],
            [
                "None",
                "'B'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e6a5d1be943d09d499ae81345dd9b91ca62c8d63c6f2ac55e179576ce665f741",
        "warmup_time": -1
    },
    "tslibs.tslib.TimeIntsToPydatetime.time_ints_to_pydatetime": {
        "code": "class TimeIntsToPydatetime:\n    def time_ints_to_pydatetime(self, box, size, tz):\n        ints_to_pydatetime(self.i8data, tz, box=box)\n\n    def setup(self, box, size, tz):\n        if box == \"date\" and tz is not None:\n            # tz is ignored, so avoid running redundant benchmarks\n            raise NotImplementedError  # skip benchmark\n        if size == 10 ** 6 and tz is _tzs[-1]:\n            # This is cumbersomely-slow, so skip to trim runtime\n            raise NotImplementedError  # skip benchmark\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr",
        "min_run_count": 2,
        "name": "tslibs.tslib.TimeIntsToPydatetime.time_ints_to_pydatetime",
        "number": 0,
        "param_names": [
            "box",
            "size",
            "tz"
        ],
        "params": [
            [
                "'time'",
                "'date'",
                "'datetime'",
                "'timestamp'"
            ],
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "None",
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "843b083137fe8f07e07301e3ea3f3d1df98777ff008e725689051c2a45619782",
        "warmup_time": -1
    },
    "tslibs.tz_convert.TimeTZConvert.time_tz_convert_from_utc": {
        "code": "class TimeTZConvert:\n    def time_tz_convert_from_utc(self, size, tz):\n        # effectively:\n        #  dti = DatetimeIndex(self.i8data, tz=tz)\n        #  dti.tz_localize(None)\n        if old_sig:\n            tz_convert_from_utc(self.i8data, UTC, tz)\n        else:\n            tz_convert_from_utc(self.i8data, tz)\n\n    def setup(self, size, tz):\n        if size == 10 ** 6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr",
        "min_run_count": 2,
        "name": "tslibs.tz_convert.TimeTZConvert.time_tz_convert_from_utc",
        "number": 0,
        "param_names": [
            "size",
            "tz"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0a4eed022ec863fae81585d1df6b8a80ef3384d386e13a898f38f5385f890760",
        "warmup_time": -1
    },
    "tslibs.tz_convert.TimeTZConvert.time_tz_localize_to_utc": {
        "code": "class TimeTZConvert:\n    def time_tz_localize_to_utc(self, size, tz):\n        # effectively:\n        #  dti = DatetimeIndex(self.i8data)\n        #  dti.tz_localize(tz, ambiguous=\"NaT\", nonexistent=\"NaT\")\n        tz_localize_to_utc(self.i8data, tz, ambiguous=\"NaT\", nonexistent=\"NaT\")\n\n    def setup(self, size, tz):\n        if size == 10 ** 6 and tz is tzlocal_obj:\n            # tzlocal is cumbersomely slow, so skip to keep runtime in check\n            raise NotImplementedError\n    \n        arr = np.random.randint(0, 10, size=size, dtype=\"i8\")\n        self.i8data = arr",
        "min_run_count": 2,
        "name": "tslibs.tz_convert.TimeTZConvert.time_tz_localize_to_utc",
        "number": 0,
        "param_names": [
            "size",
            "tz"
        ],
        "params": [
            [
                "0",
                "1",
                "100",
                "10000",
                "1000000"
            ],
            [
                "datetime.timezone.utc",
                "datetime.timezone(datetime.timedelta(seconds=3600))",
                "<DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>",
                "tzfile('/usr/share/zoneinfo/Asia/Tokyo')",
                "tzlocal()"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b03b79ec4371eabc74de46fb05ad76a79bae30f14a63e32d10d85d59b3adba9c",
        "warmup_time": -1
    },
    "version": 2
}